{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pursh2002/Machine-learning-with-Siraj-Raval-sept-2019..-Dr-Purshottam/blob/master/Stock_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E71NzMSjaRE1",
        "colab_type": "text"
      },
      "source": [
        "# Homework Assignment: Stock Prediction\n",
        "\n",
        "The homework for this week is to build 3 different types of regression lines to predict stock prices using Python, then print out the prediction for the best performing one.\n",
        "\n",
        "**Step 1** - Go to Yahoo Finance and find a stock price that you want to predict. Click on historical data, then download the CSV of that stocks price history https://finance.yahoo.com/quote/AAPL/history?p=AAPL  \n",
        "\n",
        "**Step 2** - Use Scikit learn to try out 3 different types of regression models to predict the price of that stock for a future date. See this https://towardsdatascience.com/in-12-minutes-stocks-analysis-with-pandas-and-scikit-learn-a8d8a7b50ee7  as an example and the scikit learn docs to see all the different types of regression models you can easily build (i.e quadratic, linear, lasso, ridge, etc.)\n",
        "\n",
        "**Step 3** - Visualize your result using matplotlib or another plotting library of your choice\n",
        "\n",
        "Once your code is complete, upload it to GitHub and send the github link to gradedhomeworkassignments@gmail.com with your full name as the subject line.  Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZpvATAAahZG",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Download stock prices from Yahoo Finance\n",
        "\n",
        "First we'll connect and authenticate Drive.  This will allow us to save our results directly to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIuPS_e4a4at",
        "colab_type": "code",
        "outputId": "9e38f8ab-a56a-44eb-b237-7d3601de1146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# drive to connect with Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlRkji6oa3X4",
        "colab_type": "code",
        "outputId": "f95c99af-7f99-4930-e503-6826749e3704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# change directory to folder you want to save files\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/Make Money with Machine Learning Course\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Make Money with Machine Learning Course\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5kn9GbIcGo-",
        "colab_type": "text"
      },
      "source": [
        "Next, we import some common tools for data processing and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_ZTCuKaPxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy for matrix math & data pre-processing\n",
        "import numpy as np\n",
        "\n",
        "# pandas for data formatting\n",
        "import pandas as pd\n",
        "\n",
        "# matplotlib and seaborn for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNOc32kJbaBn",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll install and import a couple of tools to help us access Yahoo Finance and read them directly into pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U095bIyDasIR",
        "colab_type": "code",
        "outputId": "68c4c9c5-ca78-457b-c121-715249d70564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# yfinance library to access yahoo finance\n",
        "!pip install yfinance --upgrade --no-cache-dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/53/0e/40387099824c98be22cd7e33a620e9d38b61998b031f0b33f0b9959717d2/yfinance-0.1.45.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.45-cp36-none-any.whl size=14652 sha256=caba6ebe397cb827d82ec547ebbc6927a643baef95e3dbab8c848152f0c95105\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vkmov54t/wheels/0c/d1/df/aa9a7744a4ac353cc9a1f2c3aaea7c1f457fc49de4286f2d88\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwC_1xx2bYhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pdr for reading csv files\n",
        "from pandas_datareader import data as pdr\n",
        "# yf for reading into pandas\n",
        "import fix_yahoo_finance as yf\n",
        "\n",
        "# override pandas datareader\n",
        "yf.pdr_override()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fskAlF6dcX-b",
        "colab_type": "text"
      },
      "source": [
        "For this homework assignment I decided to choose the S&P 500 (^GSPC) index.  We will grab data from the beginning of 2018 to now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkBMuo6Ja7Df",
        "colab_type": "code",
        "outputId": "10525975-08c3-4e01-86a6-9a6f2f6100d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# read stock ticker data into a data frame, reset the index\n",
        "ticker = '^GSPC'\n",
        "\n",
        "dataframe = pdr.get_data_yahoo(ticker, start='2010-01-01').reset_index()\n",
        "dataframe.to_csv(ticker + \".csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvj76EKx6T5Y",
        "colab_type": "text"
      },
      "source": [
        "The previous code block may return a `ValueError: zero-size array...` if we reach the query limit of 2,000 calls per hour.  Luckily, we saved the csv to our Drive folder!  Run the following block to retrieve our csv from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l1dUZHL6Sft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_csv(ticker + \".csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiqzCwYyc57Q",
        "colab_type": "text"
      },
      "source": [
        "Let's preview the first 5 lines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gFcp7DvctuT",
        "colab_type": "code",
        "outputId": "ec2f3404-7323-4ac5-f8a5-8efd014ae4fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# display first 5 rows\n",
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-01-04</td>\n",
              "      <td>1116.560059</td>\n",
              "      <td>1133.869995</td>\n",
              "      <td>1116.560059</td>\n",
              "      <td>1132.989990</td>\n",
              "      <td>1132.989990</td>\n",
              "      <td>3991400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-01-05</td>\n",
              "      <td>1132.660034</td>\n",
              "      <td>1136.630005</td>\n",
              "      <td>1129.660034</td>\n",
              "      <td>1136.520020</td>\n",
              "      <td>1136.520020</td>\n",
              "      <td>2491020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-01-06</td>\n",
              "      <td>1135.709961</td>\n",
              "      <td>1139.189941</td>\n",
              "      <td>1133.949951</td>\n",
              "      <td>1137.140015</td>\n",
              "      <td>1137.140015</td>\n",
              "      <td>4972660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-01-07</td>\n",
              "      <td>1136.270020</td>\n",
              "      <td>1142.459961</td>\n",
              "      <td>1131.319946</td>\n",
              "      <td>1141.689941</td>\n",
              "      <td>1141.689941</td>\n",
              "      <td>5270680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-01-08</td>\n",
              "      <td>1140.520020</td>\n",
              "      <td>1145.390015</td>\n",
              "      <td>1136.219971</td>\n",
              "      <td>1144.979980</td>\n",
              "      <td>1144.979980</td>\n",
              "      <td>4389590000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date         Open         High  ...        Close    Adj Close      Volume\n",
              "0  2010-01-04  1116.560059  1133.869995  ...  1132.989990  1132.989990  3991400000\n",
              "1  2010-01-05  1132.660034  1136.630005  ...  1136.520020  1136.520020  2491020000\n",
              "2  2010-01-06  1135.709961  1139.189941  ...  1137.140015  1137.140015  4972660000\n",
              "3  2010-01-07  1136.270020  1142.459961  ...  1141.689941  1141.689941  5270680000\n",
              "4  2010-01-08  1140.520020  1145.390015  ...  1144.979980  1144.979980  4389590000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38p9KlvNjDrR",
        "colab_type": "text"
      },
      "source": [
        "So it looks like we have the `Date`, the price the stock `Open`ed at, the `High` for the day, the `Low` for the day, the price the stock `Close`d at, and the `Volume` of trades for the day.\n",
        "\n",
        "The `Adj Close` is the [closing price after adjustments for applicable splits and dividend distributions.](https://help.yahoo.com/kb/SLN28256.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAJh0n2Hm8FNdMS6st1eDjVCJv2GA1yBEYXtryrFngTRxXWqdFSnjY7Q1dXiLMopqjBRYej1O_4idlnELsxpsPPxVI2OihltyG_scon1Rsw7sjTxcX2SwmHHb1O76tKUd2-8bktaM6qfoXZrdqT-IiLC8cIXnyz2RLuAgxUVBrK-p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnxlNqNLhx5L",
        "colab_type": "text"
      },
      "source": [
        "Let's also check if there is any missing data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STuKjHQ-hxMM",
        "colab_type": "code",
        "outputId": "941f7ee2-6179-401d-a873-593686b6222c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# summary of dataframe\n",
        "dataframe.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2442 entries, 0 to 2441\n",
            "Data columns (total 7 columns):\n",
            "Date         2442 non-null object\n",
            "Open         2442 non-null float64\n",
            "High         2442 non-null float64\n",
            "Low          2442 non-null float64\n",
            "Close        2442 non-null float64\n",
            "Adj Close    2442 non-null float64\n",
            "Volume       2442 non-null int64\n",
            "dtypes: float64(5), int64(1), object(1)\n",
            "memory usage: 133.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lma8O-6aiOFA",
        "colab_type": "text"
      },
      "source": [
        "And get a numerical summary of our columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjQTit5FiNrJ",
        "colab_type": "code",
        "outputId": "2b81169c-0959-473b-808b-2b18c93e142f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# numerical summary of dataframe\n",
        "dataframe.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2442.000000</td>\n",
              "      <td>2442.000000</td>\n",
              "      <td>2442.000000</td>\n",
              "      <td>2442.000000</td>\n",
              "      <td>2442.000000</td>\n",
              "      <td>2.442000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1928.613419</td>\n",
              "      <td>1937.784541</td>\n",
              "      <td>1918.677536</td>\n",
              "      <td>1929.056023</td>\n",
              "      <td>1929.056023</td>\n",
              "      <td>3.720499e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>564.774703</td>\n",
              "      <td>565.977919</td>\n",
              "      <td>563.267171</td>\n",
              "      <td>564.601897</td>\n",
              "      <td>564.601897</td>\n",
              "      <td>8.180540e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1027.650024</td>\n",
              "      <td>1032.949951</td>\n",
              "      <td>1010.909973</td>\n",
              "      <td>1022.580017</td>\n",
              "      <td>1022.580017</td>\n",
              "      <td>3.824615e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1369.574951</td>\n",
              "      <td>1376.255035</td>\n",
              "      <td>1363.842529</td>\n",
              "      <td>1369.787506</td>\n",
              "      <td>1369.787506</td>\n",
              "      <td>3.236955e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1965.145019</td>\n",
              "      <td>1976.800049</td>\n",
              "      <td>1955.695007</td>\n",
              "      <td>1967.269959</td>\n",
              "      <td>1967.269959</td>\n",
              "      <td>3.598105e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2371.212585</td>\n",
              "      <td>2378.690064</td>\n",
              "      <td>2362.930054</td>\n",
              "      <td>2371.887574</td>\n",
              "      <td>2371.887574</td>\n",
              "      <td>4.084508e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3024.469971</td>\n",
              "      <td>3027.979980</td>\n",
              "      <td>3014.300049</td>\n",
              "      <td>3025.860107</td>\n",
              "      <td>3025.860107</td>\n",
              "      <td>1.061781e+10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Open         High  ...    Adj Close        Volume\n",
              "count  2442.000000  2442.000000  ...  2442.000000  2.442000e+03\n",
              "mean   1928.613419  1937.784541  ...  1929.056023  3.720499e+09\n",
              "std     564.774703   565.977919  ...   564.601897  8.180540e+08\n",
              "min    1027.650024  1032.949951  ...  1022.580017  3.824615e+08\n",
              "25%    1369.574951  1376.255035  ...  1369.787506  3.236955e+09\n",
              "50%    1965.145019  1976.800049  ...  1967.269959  3.598105e+09\n",
              "75%    2371.212585  2378.690064  ...  2371.887574  4.084508e+09\n",
              "max    3024.469971  3027.979980  ...  3025.860107  1.061781e+10\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25B-b4kvkEme",
        "colab_type": "text"
      },
      "source": [
        "We will drop all the pricing columns and only leave the Adj Close and Volume columns.\n",
        "\n",
        "Before we visualize our data, let's split our data into it's training and testing data sets in the following section.\n",
        "\n",
        "This is best practice to not prevent unconscious bias to our results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0uuPesUdQkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.drop(['Open', 'High', 'Low', 'Close'], axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feB_LBUma-Ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add technical indicators\n",
        "dataframe['MA 9'] = dataframe['Adj Close'].rolling(9).mean().shift()\n",
        "dataframe['MA 21'] = dataframe['Adj Close'].rolling(21).mean().shift()\n",
        "dataframe['Change'] = np.log( dataframe['Adj Close'] / dataframe['Adj Close'].shift() )\n",
        "dataframe['Volatility'] = dataframe.Change.rolling(21).std().shift()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v294CxbgBPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# backfill missing values from moving averages\n",
        "dataframe.dropna(axis = 0, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHA5ipeXgjA7",
        "colab_type": "code",
        "outputId": "fb441c39-a552-4a19-fcf4-ab2d3c806c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        }
      },
      "source": [
        "# preview\n",
        "dataframe.head(30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MA 9</th>\n",
              "      <th>MA 21</th>\n",
              "      <th>Change</th>\n",
              "      <th>Volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2010-02-04</td>\n",
              "      <td>1063.109985</td>\n",
              "      <td>5859690000</td>\n",
              "      <td>1091.822225</td>\n",
              "      <td>1119.278570</td>\n",
              "      <td>-0.031636</td>\n",
              "      <td>0.010256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>1066.189941</td>\n",
              "      <td>6438900000</td>\n",
              "      <td>1088.638889</td>\n",
              "      <td>1115.782854</td>\n",
              "      <td>0.002893</td>\n",
              "      <td>0.012106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2010-02-08</td>\n",
              "      <td>1056.739990</td>\n",
              "      <td>4089820000</td>\n",
              "      <td>1085.239990</td>\n",
              "      <td>1112.404279</td>\n",
              "      <td>-0.008903</td>\n",
              "      <td>0.012153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2010-02-09</td>\n",
              "      <td>1070.520020</td>\n",
              "      <td>5114260000</td>\n",
              "      <td>1081.303317</td>\n",
              "      <td>1108.359043</td>\n",
              "      <td>0.012956</td>\n",
              "      <td>0.012104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2010-02-10</td>\n",
              "      <td>1068.130005</td>\n",
              "      <td>4251450000</td>\n",
              "      <td>1078.305542</td>\n",
              "      <td>1104.813331</td>\n",
              "      <td>-0.002235</td>\n",
              "      <td>0.012568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2010-02-11</td>\n",
              "      <td>1078.469971</td>\n",
              "      <td>4400870000</td>\n",
              "      <td>1076.483317</td>\n",
              "      <td>1101.058570</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.012520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>1075.510010</td>\n",
              "      <td>4160680000</td>\n",
              "      <td>1076.994425</td>\n",
              "      <td>1098.308570</td>\n",
              "      <td>-0.002748</td>\n",
              "      <td>0.012749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2010-02-16</td>\n",
              "      <td>1094.869995</td>\n",
              "      <td>4080770000</td>\n",
              "      <td>1075.474433</td>\n",
              "      <td>1094.967140</td>\n",
              "      <td>0.017841</td>\n",
              "      <td>0.012508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2010-02-17</td>\n",
              "      <td>1099.510010</td>\n",
              "      <td>4259230000</td>\n",
              "      <td>1074.535550</td>\n",
              "      <td>1092.415237</td>\n",
              "      <td>0.004229</td>\n",
              "      <td>0.013272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2010-02-18</td>\n",
              "      <td>1106.750000</td>\n",
              "      <td>3878620000</td>\n",
              "      <td>1074.783325</td>\n",
              "      <td>1090.676188</td>\n",
              "      <td>0.006563</td>\n",
              "      <td>0.013191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>1109.170044</td>\n",
              "      <td>3944280000</td>\n",
              "      <td>1079.632216</td>\n",
              "      <td>1088.605713</td>\n",
              "      <td>0.002184</td>\n",
              "      <td>0.012941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2010-02-22</td>\n",
              "      <td>1108.010010</td>\n",
              "      <td>3814440000</td>\n",
              "      <td>1084.407783</td>\n",
              "      <td>1087.230951</td>\n",
              "      <td>-0.001046</td>\n",
              "      <td>0.012806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2010-02-23</td>\n",
              "      <td>1094.599976</td>\n",
              "      <td>4521050000</td>\n",
              "      <td>1090.104452</td>\n",
              "      <td>1086.827619</td>\n",
              "      <td>-0.012177</td>\n",
              "      <td>0.012132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2010-02-24</td>\n",
              "      <td>1105.239990</td>\n",
              "      <td>4168360000</td>\n",
              "      <td>1092.780002</td>\n",
              "      <td>1086.962856</td>\n",
              "      <td>0.009674</td>\n",
              "      <td>0.011387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2010-02-25</td>\n",
              "      <td>1102.939941</td>\n",
              "      <td>4521130000</td>\n",
              "      <td>1096.903334</td>\n",
              "      <td>1087.365711</td>\n",
              "      <td>-0.002083</td>\n",
              "      <td>0.011539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>1104.489990</td>\n",
              "      <td>3945190000</td>\n",
              "      <td>1099.622220</td>\n",
              "      <td>1087.878563</td>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.011506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2010-03-01</td>\n",
              "      <td>1115.709961</td>\n",
              "      <td>3847640000</td>\n",
              "      <td>1102.842217</td>\n",
              "      <td>1088.211420</td>\n",
              "      <td>0.010107</td>\n",
              "      <td>0.011465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2010-03-02</td>\n",
              "      <td>1118.310059</td>\n",
              "      <td>4134680000</td>\n",
              "      <td>1105.157769</td>\n",
              "      <td>1089.696179</td>\n",
              "      <td>0.002328</td>\n",
              "      <td>0.011299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2010-03-03</td>\n",
              "      <td>1118.790039</td>\n",
              "      <td>3951320000</td>\n",
              "      <td>1107.246663</td>\n",
              "      <td>1091.812372</td>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.011003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2010-03-04</td>\n",
              "      <td>1122.969971</td>\n",
              "      <td>3945010000</td>\n",
              "      <td>1108.584446</td>\n",
              "      <td>1093.221901</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>0.010641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>1138.699951</td>\n",
              "      <td>4133000000</td>\n",
              "      <td>1110.117771</td>\n",
              "      <td>1094.157616</td>\n",
              "      <td>0.013910</td>\n",
              "      <td>0.010324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2010-03-08</td>\n",
              "      <td>1138.500000</td>\n",
              "      <td>3774680000</td>\n",
              "      <td>1113.527764</td>\n",
              "      <td>1096.129993</td>\n",
              "      <td>-0.000176</td>\n",
              "      <td>0.010594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2010-03-09</td>\n",
              "      <td>1140.449951</td>\n",
              "      <td>5185570000</td>\n",
              "      <td>1118.405545</td>\n",
              "      <td>1099.719994</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.007368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2010-03-10</td>\n",
              "      <td>1145.609985</td>\n",
              "      <td>5469120000</td>\n",
              "      <td>1122.317763</td>\n",
              "      <td>1103.256185</td>\n",
              "      <td>0.004514</td>\n",
              "      <td>0.007376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2010-03-11</td>\n",
              "      <td>1150.239990</td>\n",
              "      <td>4669060000</td>\n",
              "      <td>1127.058879</td>\n",
              "      <td>1107.488089</td>\n",
              "      <td>0.004033</td>\n",
              "      <td>0.006836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2010-03-12</td>\n",
              "      <td>1149.989990</td>\n",
              "      <td>4928160000</td>\n",
              "      <td>1132.142212</td>\n",
              "      <td>1111.284279</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>0.006511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2010-03-15</td>\n",
              "      <td>1150.510010</td>\n",
              "      <td>4164110000</td>\n",
              "      <td>1135.951104</td>\n",
              "      <td>1115.182373</td>\n",
              "      <td>0.000452</td>\n",
              "      <td>0.006437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2010-03-16</td>\n",
              "      <td>1159.459961</td>\n",
              "      <td>4369770000</td>\n",
              "      <td>1139.528876</td>\n",
              "      <td>1118.612851</td>\n",
              "      <td>0.007749</td>\n",
              "      <td>0.006312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>2010-03-17</td>\n",
              "      <td>1166.209961</td>\n",
              "      <td>4963200000</td>\n",
              "      <td>1144.047757</td>\n",
              "      <td>1122.610468</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.006242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>2010-03-18</td>\n",
              "      <td>1165.829956</td>\n",
              "      <td>4234510000</td>\n",
              "      <td>1148.852200</td>\n",
              "      <td>1126.007609</td>\n",
              "      <td>-0.000326</td>\n",
              "      <td>0.005357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date    Adj Close      Volume  ...        MA 21    Change  Volatility\n",
              "22  2010-02-04  1063.109985  5859690000  ...  1119.278570 -0.031636    0.010256\n",
              "23  2010-02-05  1066.189941  6438900000  ...  1115.782854  0.002893    0.012106\n",
              "24  2010-02-08  1056.739990  4089820000  ...  1112.404279 -0.008903    0.012153\n",
              "25  2010-02-09  1070.520020  5114260000  ...  1108.359043  0.012956    0.012104\n",
              "26  2010-02-10  1068.130005  4251450000  ...  1104.813331 -0.002235    0.012568\n",
              "27  2010-02-11  1078.469971  4400870000  ...  1101.058570  0.009634    0.012520\n",
              "28  2010-02-12  1075.510010  4160680000  ...  1098.308570 -0.002748    0.012749\n",
              "29  2010-02-16  1094.869995  4080770000  ...  1094.967140  0.017841    0.012508\n",
              "30  2010-02-17  1099.510010  4259230000  ...  1092.415237  0.004229    0.013272\n",
              "31  2010-02-18  1106.750000  3878620000  ...  1090.676188  0.006563    0.013191\n",
              "32  2010-02-19  1109.170044  3944280000  ...  1088.605713  0.002184    0.012941\n",
              "33  2010-02-22  1108.010010  3814440000  ...  1087.230951 -0.001046    0.012806\n",
              "34  2010-02-23  1094.599976  4521050000  ...  1086.827619 -0.012177    0.012132\n",
              "35  2010-02-24  1105.239990  4168360000  ...  1086.962856  0.009674    0.011387\n",
              "36  2010-02-25  1102.939941  4521130000  ...  1087.365711 -0.002083    0.011539\n",
              "37  2010-02-26  1104.489990  3945190000  ...  1087.878563  0.001404    0.011506\n",
              "38  2010-03-01  1115.709961  3847640000  ...  1088.211420  0.010107    0.011465\n",
              "39  2010-03-02  1118.310059  4134680000  ...  1089.696179  0.002328    0.011299\n",
              "40  2010-03-03  1118.790039  3951320000  ...  1091.812372  0.000429    0.011003\n",
              "41  2010-03-04  1122.969971  3945010000  ...  1093.221901  0.003729    0.010641\n",
              "42  2010-03-05  1138.699951  4133000000  ...  1094.157616  0.013910    0.010324\n",
              "43  2010-03-08  1138.500000  3774680000  ...  1096.129993 -0.000176    0.010594\n",
              "44  2010-03-09  1140.449951  5185570000  ...  1099.719994  0.001711    0.007368\n",
              "45  2010-03-10  1145.609985  5469120000  ...  1103.256185  0.004514    0.007376\n",
              "46  2010-03-11  1150.239990  4669060000  ...  1107.488089  0.004033    0.006836\n",
              "47  2010-03-12  1149.989990  4928160000  ...  1111.284279 -0.000217    0.006511\n",
              "48  2010-03-15  1150.510010  4164110000  ...  1115.182373  0.000452    0.006437\n",
              "49  2010-03-16  1159.459961  4369770000  ...  1118.612851  0.007749    0.006312\n",
              "50  2010-03-17  1166.209961  4963200000  ...  1122.610468  0.005805    0.006242\n",
              "51  2010-03-18  1165.829956  4234510000  ...  1126.007609 -0.000326    0.005357\n",
              "\n",
              "[30 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8dCxahbc3sQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe.to_csv(ticker + \"_prepared.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNXHkDr6dTdT",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Use Linear Regression to predict prices for a future date.\n",
        "\n",
        "### Prepare Data for Machine Learning Algorithms\n",
        "\n",
        "For each Linear Regression model, we'll read in a clean copy of the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPBn9gmic8eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in a copy of csv and convert Date from string to datetime\n",
        "df_full = pd.read_csv(ticker + \"_prepared.csv\", parse_dates=['Date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDc6uvMhxidi",
        "colab_type": "text"
      },
      "source": [
        "To prepare the data for our machine learning algorithm, we'll convert `Date` column from a `datetime` datatype to an integer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy2GOLfxuC8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import datetime to convert date to ordinal\n",
        "import datetime as dt\n",
        "\n",
        "df_full['Date'] = df_full['Date'].apply(lambda x: x.toordinal())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-nt4cpJx1-t",
        "colab_type": "text"
      },
      "source": [
        "We can use the following line of code later if we need to convert the date back into a `datetime`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0dXSIWQvuaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to convert back to datetime\n",
        "# df_full['Date'].apply(dt.datetime.fromordinal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVurGLpGriVf",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll separate our data features (X) from the value we want to predict aka labels (y).  Since the columns for High, Low, and Close are essentially the answers were trying to predict... we will drop those columns.\n",
        "\n",
        "We will only provide the Date and Volume for our model to predict the price of the stock."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSZ-47AjrLwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_full.drop('Adj Close', axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbFPXwszrczz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df_full['Adj Close']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yoSRpIQr81A",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll separate the data into a 90/10 ratio for our training and testing data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhrHuFOdsKFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing ratio of 90%\n",
        "train_ratio = 0.90\n",
        "\n",
        "# training size\n",
        "train_size = int(len(X) * train_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6oa5U4Nxy_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "X_train, X_test = X.loc[:train_size-1], X.loc[train_size:]\n",
        "y_train, y_test = y.loc[:train_size-1], y.loc[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG0FSIDDzv8B",
        "colab_type": "text"
      },
      "source": [
        "Now that our data is separated, let's plot our training and test set.\n",
        "\n",
        "*Note: it is best practice not to peak at your test set; in production you wouldn't be able to peak at your data!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuEb-fsbi16Z",
        "colab_type": "code",
        "outputId": "fb52601c-864d-4ddb-c76c-358b31adcef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "# create plot with dimension 8 x 6\n",
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "\n",
        "# plot the dataframe, Date as x axis, Adj Close as y axis\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_train.values)\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = y_test.values)\n",
        "plt.title(ticker);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
            "\n",
            "To register the converters:\n",
            "\t>>> from pandas.plotting import register_matplotlib_converters\n",
            "\t>>> register_matplotlib_converters()\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAGJCAYAAABmViEbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYoEnIiKyQyzwREREduj/AQ2IJ2rLv/eqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX3wA-N1xRsT",
        "colab_type": "text"
      },
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "First up... we'll use a basic linear regression model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7hLLNctyLph",
        "colab_type": "code",
        "outputId": "19bae108-3bed-49cd-ddb9-4a07b2fec827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# LinearRegression constructor\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# fit the training data and training labels\n",
        "lin_reg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAem0NHuygmT",
        "colab_type": "text"
      },
      "source": [
        "Let's view some of our data and see how the model did:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odYaLvY2yfrX",
        "colab_type": "code",
        "outputId": "4a1ff66e-91bb-4130-dc92-6be8c1c8ed70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# view 5 instances of the training data and labels\n",
        "some_data = X_train.iloc[:5]\n",
        "some_labels = y_train.iloc[:5]\n",
        "\n",
        "# print the results\n",
        "print('Predictions: ', lin_reg.predict(some_data))\n",
        "print('Labels: ', list(some_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions:  [1028.44333277 1071.63220488 1064.71799926 1086.16663998 1066.77310391]\n",
            "Labels:  [1063.109985, 1066.189941, 1056.73999, 1070.52002, 1068.130005]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4emYF490c5t",
        "colab_type": "text"
      },
      "source": [
        "Interesting... the first few rows look ok but it looks like it is diverging.\n",
        "\n",
        "For a more robust look, let's measure the regression model's Root Mean Squared Error (RMSE) for the whole training set using Scikit-Learn's `mean_squared_error` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA0NGHgA0eDS",
        "colab_type": "code",
        "outputId": "39a38706-1fa8-4fa7-dc5c-717a7c853084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# predict the value of the stock using the prepared features\n",
        "y_preds = lin_reg.predict(X_train)\n",
        "\n",
        "# calculate error from training labels and predictions\n",
        "lin_mse = mean_squared_error(y_train, y_preds)\n",
        "\n",
        "# take the square root\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.36635814200372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C1ikeht4mJW",
        "colab_type": "text"
      },
      "source": [
        "Hmmm... thats not bad considering the current price of the S&P is around 3,000.  Let's try and visualize what the model is suggesting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN_Fz5dx2kMW",
        "colab_type": "code",
        "outputId": "1c03ce51-ffcf-4b52-9d53-3b9f2d4b68a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_train, label = 'True')\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_preds, label = 'Linear Regression')\n",
        "plt.title(ticker);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGJCAYAAAAAOqC9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsUggIiIip1gkEBERkVP/H0tj2KaRJztAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPnWb_771b82",
        "colab_type": "text"
      },
      "source": [
        "Well... it looks like our model is just drawing a straight line through the whole dataset!  Let's try another model before moving into more evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3j1N-Dp8otI",
        "colab_type": "code",
        "outputId": "4e27e1d2-d1e8-4193-d962-f5a72692065a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Decision Tree constructor\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "\n",
        "# fit the prepared stock data and prices\n",
        "tree_reg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
              "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "                      min_impurity_split=None, min_samples_leaf=1,\n",
              "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "                      presort=False, random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ort2NbcP83j-",
        "colab_type": "code",
        "outputId": "e84a63e7-26a2-498a-dd71-070aadbe4ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# predict the stock prices using our decision tree model\n",
        "price_preds = tree_reg.predict(X_train)\n",
        "\n",
        "# calculate the error from the price and predictions\n",
        "tree_mse = mean_squared_error(y_train, price_preds)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4G0-HA_9RXl",
        "colab_type": "text"
      },
      "source": [
        "An error of 0!  It looks like our decision tree model is also overfitting our data badly!  To get a better understanding of what's happening, let's use some of Scikit-Learn's cross-validation features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22ypjdS-lBi",
        "colab_type": "code",
        "outputId": "bdd3d193-32cc-4867-d2d4-00da2f5e30c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_train, label = 'True')\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = price_preds, label = 'Decision Tree')\n",
        "plt.title(ticker);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGJCAYAAAAAOqC9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8VNX5+PHPvbMkk30hhISELBr2\nHVSsggq4VRHFYqmKtRbB9Wu1olYQKogWXMtPrAsoailotYCoFamKKO4imyBbSFiSkH1fZ+79/THJ\nJJNMVjIzmeR5v1599d5zzr3zTIiZZ8459xxF13UdIYQQQohGVG8HIIQQQoiuSZIEIYQQQrgkSYIQ\nQgghXJIkQQghhBAuSZIghBBCCJckSRBCCCGES5IkCCHa7N///jdr1qzxdhhCCA8xejsAIYRvWLly\nJW+88QZms5ns7Gzuvfdep/oPPviA1atXc+jQISwWC3FxcVx99dVcf/31KIpCVlYWS5Ys4bvvvsNq\ntRITE8Mtt9zCtGnTOHHiBJMmTSIgIACA8PBwZsyYwezZswHQdZ0333yTt99+mxMnThASEsLIkSO5\n8847GTBggMd/FkL0FJIkCCFatX79etauXcuaNWswm83cfPPNREVFceONNwLw6quvsnLlShYsWMD5\n559PYGAg+/fvZ9WqVUyfPh2z2czcuXMZOHAgn332GWazmYMHD5KTk+P0Ot9//z1Go5GffvqJm2++\nmYEDBzJhwgSWLFnC1q1bWbx4MWPGjMFms7FlyxY+//xzSRKEcCNFVlwUQrRk69atLFu2jFWrVhET\nEwNAXl4et9xyC7fddhvnn38+48ePZ+nSpVx66aXN3mfUqFH861//YtCgQU3q6noSfv75Z4xG+3eX\na6+9ll//+tdMmjSJyy+/nLfeeovhw4e7500KIVySngQhRIsuvPBCLrzwQqeyyMhINm7cCMC2bduo\nrq5m0qRJLd5nxIgRPProo8ycOZNRo0YRGxvrsp2u6+zYsYPDhw8zePBgvv76a/r06SMJghBeIBMX\nhRCnpaCggPDwcEcPAMCMGTMYO3Ysw4cP5/vvvwfg73//O2PHjuWFF15g0qRJTJ06ld27dzvda9y4\ncZx99tnMnz+fP//5z5x77rkUFhYSFRXl0fckhLCTngQhxGkJCwujoKAAq9XqSBTWrVsHwIQJE9A0\nDYDQ0FDuv/9+7r//fvLz81m2bBl33nkn27Ztc9zrm2++cUo26u7feO6CEMIzpCdBCHFaRo0ahdls\n5pNPPmnzNREREdxyyy1kZ2dTWFjYYttzzz2XrKws9uzZc7qhCiHaSZIEIcRpCQkJ4c477+TRRx/l\no48+orS0FE3T2L9/PxUVFY52Tz75JAcPHsRqtVJaWsratWtJSEggPDy8xfsnJiZy/fXX8+c//5lv\nv/2W6upqqqqq+OCDD3j55Zfd/faE6NFkuEEIcdpuvfVWoqOjWblyJQ8++CAWi4X4+Hjuv/9+Ro0a\nBUBlZSV33XUXOTk5+Pn5MWLECP7xj3+06f7z58/njTfeYNGiRY51EsaMGcOdd97pzrclRI8nj0AK\nIYQQwiUZbhBCCCGES5IkCCGEEMIlSRKEEEII4ZIkCUIIIYRwSZIEIYQQQrjksUcg77jjDk6cOIGq\nqgQEBPDII48waNAgjh49ykMPPURhYSFhYWEsXbqUxMREgA7XCSGEEOL0eewRyJKSEoKDgwH43//+\nx4oVK1i/fj033XQT1157LVOnTmXjxo28++67vPHGGwAdrmurgoIyNK1jbz8yMoi8vNIOXettvhq7\nr8Zdx1fj99W4QWL3FondO1qKXVUVwsMD231Pj/Uk1CUIAKWlpSiKQl5eHvv27eO1114D4Morr2Tx\n4sXk5+ej63qH6iIiItock6bpHU4S6q73Vb4au6/GXcdX4/fVuEFi9xaJ3Ts6O3aPrrg4b948tm/f\njq7rrFy5kszMTKKjozEYDAAYDAZ69+5NZmYmuq53qK49SYIQQgghmufRJGHJkiUAbNiwgWXLlnHP\nPfd48uWbiIwMOq3ro6KCW2/URflq7L4adx1fjd9X4waJ3Vskdu/o7Ni9snfD1VdfzYIFC+jTpw+n\nTp3CZrNhMBiw2WxkZ2cTExODrusdqmuPvLzSDnfNREUFk5NT0qFrvc1XY/fVuOv4avy+GjdI7N4i\nsXtHS7GrqtKhL8YeSRLKysooLi52fIh/+umnhIaGEhkZyaBBg3j//feZOnUq77//PoMGDXIMGXS0\nrqNsNisFBTlYrdWtts3OVtE07bRez1t8Nfa2xq2qBiyWIIKCQlEUxQORCSFE9+SRpxtyc3O54447\nqKioQFVVQkNDefDBBxkyZAhHjhzhoYceori4mJCQEJYuXUpycjJAh+vaqnFPQm5uJv7+AQQGhrT6\n4WI0qlitvvdBC74be1vi1nUdm81KSUkhuq4TEdHbQ9G1zle/ofhq3CCxe4vE7h3u6Eno0btANk4S\nsrLSiY7u16Zvn776QQu+G3t74tZ1jVOnTtCnTz83R9V2vvrHx1fjBondWyR273BHkiArLjYi3dPd\ng6KoQI/Nf4UQolN4ZeKiaN2tt/6empoarNYajh8/RlLSGQD07z+Ahx9e6OXohBBC9ASSJHRRr7zy\nOgCZmRnMmjWT1av/5bJd3RMeQgghRGeT4QYf8/333/KHP1zP4sUL+P3vf8d3333D7bf/kW+++crR\npuF5Tk428+bN5dZbb+Kmm37LmjWveyt0IYQQPkZ6ElqwfU8mX+7OdFmnKHA6Uz7PHx7DecPat65D\nnSNHDjN37sMMHjwUgDfeeLXZtosWPcLs2XcwbNgIampquPvuOQwdOpQRI8Z06LWFEEL0HJIk+KCE\nhERHgtCSsrJSdu/eydNPL3WUlZeXcfToUUkShBCii9q9fjVqYChDL7nG26FIktCS84Y1/23fm48R\nWiwBTucGgwFdr4+lutq+GJSm6aiqysqVb2A01v9T++ojkEII0RMk5WyFHNC0qaiqd2cFyJyEbiAu\nLp79+/cB9qGI1NTDgH3nzSFDhrF27ZuOtllZmeTl5XklTiGEEK5VV1ZSUea8zXPuyWNeiqaeJAnd\nwI033syXX37O738/g7feWsOZZ6Y46v7618c5dOggN930W2bOvI5HH51HWVmZF6MVQgjRWMbrD2Jd\ncxc2zeYoK9z8ohcjspPhhi4uJiaWDz74xHF+1lnncNZZ5zi1iYuL59VX17i8vlevXixa9IRTmQw3\nCCFE1xKpFAGw7+MNJNaW6Xh/cT/pSRBCCCG6iMRjmwDIUqLoM/VeL0cjSYIQQgjhVa52t62IHklo\nlPc3qJMkQQghhPCisuKiJmV+UX29EElTkiQIIYQQXlScneV0nhp6NgPOvdA7wTQiSYIQQgjRSMGp\nU+xd/ThlxcVuf62y/Bync0v8ILe/ZltJkiCEEEI0cmzrf0ioPsiRzz9w+2tVFWQDcDTmEk4Y+pF0\n1nluf822kkcghRBCiEYUSwgUgV5e4LbXyDmezqmffyDx+PsAxJ89ifDo6932eh0hSUIX9pvfTMFs\nNmMymamsrCApKZkbbvg9w4aN6PA9N2x4h5qaaqZPb/4XceXKF0lKSmbSpEs6/Dp1jhw5zOLFCwAo\nLi6ivLyMPn1iAZgy5Wquvfa6034NIYTobAZLMABqZdNJhZ0lc+vbJFX87Di3BAW77bU6SpKELu6x\nx5aSnHwmAJ9//ilz597D008/z5AhrW/w5MrVV/+m1cWUZs26rUP3duWMM85k9ep/AfDhh5v46qsv\neOyxZS7b2mw2VFVFUby/gIgQomer2w9H1ao7/d42q429m96gb/kB6tZLSou/kmGBAS1f6AWSJPiQ\nCy6YyL59P7N27Zs89thSampqePnlF9i580eqq2s488wz+fOf/0JAQAClpaUsX/40v/yyD0VRGTFi\nJPfd9yCrVr1EVVUld9xxD3v27OLZZ5ehaTpWq5Xf//4WLr74MpYs+SsDBw7i2mt/S3l5Oc899yT7\n99uz3csuu4Ibbvg9AHfdNZtBg4awd+9ucnNzmThxMrfffne73tPLL7/AiRPHKS4uIjv7FCtXvkF2\ndjbLlz9DUVEhVquVGTNu4PLLrwRg797dvPji81RUVAD2hObcc7vO+J0QonvQsw647d6pP35Ncs7n\nNFxQMSg22W2vdzokSWhBzcHt1BzY5rJOURR0Xe/wvU0DJmDq3/4Pt8GDh7J9uz2mNWteJzAwkFde\neQOAF15YzptvvsacOXeyfPnTWCwWVq9ei6qqFBYWNrnXmjWv87vfzeTiiy9D13VKS0ubtFm9eiWa\npvHGG29RXl7GnDm3kJx8puOD+dSpLFaseIXy8nJ++9upXHnlVOLj+7XrPe3f/zMrV75BaGgYVquV\nRYvm89e/Pk6/fgmUlZXyxz/OZNiwEYSHh/H003/j6af/HxERkeTkZDN79s38859vExgY1N4fpRBC\nNCuxcj8AumLq9HsrxqYfvWaLpdNfpzNIkuBz6hOT7du3UVZWxtatnwJQU1Pt2Nzpq6++YOXKfzq2\nGQ0LC2typ9Gjx/L6669y8uQJzjprnMshjB9++I577rkfRVEIDAxi8uRL+OGH7xxJwkUXTUJVVYKC\ngkhISOLkyRPtThLOPfc8QkPt8aWlHSU9PY0FC/7iqLdaraSlHeXYMYXMzAzuu6++t0JRFDIyTpKS\nMqBdrymEEC0p1IMIU0pRtcpOv7eqNH2w0BwQ2Omv0xkkSWiBqf95zX7b99YmSfv37yMp6QwAdB3+\n/OeHGDPmrA7d67rrrue88ybw/fff8txzyzjrrHHMnn1Hu+5hNvs5jlVVxWaztdDaNYulfhxO13Ui\nIno55jE09NVX2+jffyDLl3t/ZzQhRPelaRqB2Ic0462dv12zZq1pUuZn6XrzEUDWSfApX3yxlQ0b\n3mHGjBsBOP/8Cbz11hqqquyZbnl5GWlpRwH41a/Gs3btG44hEVfDDceOpdO3bxxXX30t06f/zjHv\noKGxY8/mgw82ous65eVlfPLJx012oexMSUnJGAwqW7Z85Cg7ejSV8vJyhg8fQVraUXbu3OGo+/nn\nvW6LRQjRM5UVFmBS2v+Fpy1qqquJ3vlKk3L/LjpkKj0JXdz8+Q86HoFMTEziySf/7hgWuPHGm1m1\n6iVmzbqpdlhB4ZZbbiUxMYm7776P5cufZubM32IwGBg1ajR/+tNcp3u/8846duz4EZPJiMlk5t57\n5zZ5/ZtvnsWzzy7jppt+C8Cll/6aceN+5bb3azQaWbbsWf7+92f45z9XY7NpREZGsnjx34iICOeJ\nJ57mH/9YTklJCTabldjYvixb9pzb4hFC9DzFudmEALmEEaF37iOQeRknaDiwUHLRXwiNjsHs79+p\nr9NZFP10Zt/5uLy8UjSt/u1nZaXTp09Cm6711nBDZ/DV2Nsbd3v+PT0hKiqYnJwSb4fRbr4aN0js\n3uLrsf/vxedIzvuCDDWWWC2DwFmvOuZ3na5d/36Z5IKvHOcBs1ZhUA2dcu+Wfu6qqhAZ2f7eCulJ\nEEIIIRpIzP0SFLAa/EEDTbN1WpJQlyAcM52BHjOYoZ2UILiLzEkQQgghGjhpigfAFpEEgGar78E8\n/steinKy23yv7ONpnDxkX3Oh7v8BhvzhEYZedm1nhOtW0pMghBBC1MrLzKp/oqH2UUXNakMzaWQd\nPUzYtqfsdbNXt+l+lv/+FQtgTXqFiqI8Qjo/ZLeSJKERXddlWeBuwL6kqvw7CiHap6y4wUTF2iEG\nTbOx94O3SMrc7KiyWW0YjC0PFZw8uN+RFKT+8DVaTecv8exuHkkSCgoKeOCBBzh27Bhms5mEhAQW\nLVpEWloajz76qKNdXl4eUVFRrF+/HoABAwbQv39/x1jQsmXLGDDAvmjOp59+yrJly7DZbAwZMoQn\nnngCy2muWGU0mikrKyYwMEQSBR+l6zo2m5WSkgLM5q45W1gI0XVVlZdjAE4a+qIo9iTAZrNhyD3o\n3K6inIDgljdkKtz+jiNJ0H7eTE3sKADS/AcxrLMDdxOPJAmKojBr1izOOcf+fP3SpUt56qmnePzx\nx9m4caOj3R133MGYMWOcrl23bh2Bgc4rUZWVlfHII4+wZs0aEhMTmTdvHqtWreKuu+46rTjDw6Mo\nKMihtLTpmgKNqaqKpvneEwLgu7G3NW5VNWCxBBEUFOqBqIQQ3Ul1ZQUWwDRyCjXZJwDQNRtGW5VT\nu6ryslaTBJtfMNSum9TXdpLUskRsusLgG+93R+hu4ZEkISwszJEgAIwcOZK1a9c6tcnLy2P79u0s\nWrSo1ftt27aNoUOHkpiYCMCMGTN46KGHTjtJMBiM9OoV06a2vv6Ijy/G7qtxCyF8h7XSvtKi0c+C\nUvvkga3GirHRbpBV5WWt3ks3WajRDY6FmZSqEsrxJ6yLP9HQkMefbtA0jbVr1zJx4kSn8g0bNnDe\neefRq1cvp/KZM2cydepUnn76aaqr7f9ImZmZxMbGOtrExsaSmZnp/uCFEEJ0awW77RvoGc1mFIP9\ne7TNVoNRd04SsrdvaP1m1mqs1CcEfhU51ND5G0a5k8cnLi5evJiAgABuvPFGp/L//Oc/3HfffU5l\nW7duJSYmhtLSUubOncuKFSu49957Oy2Wjiws0VBUVMtdTV2Zr8buq3HX8dX4fTVukNi9xVdj71dq\nX+o9ISWJ6vyTAAQHmqjGeb+F6LIDrb5HU00xFYqFnOCB9CvZjb9Wjk01ufVn09n39miSsHTpUtLT\n03nxxRedFqbYuXMnRUVFXHDBBU7tY2LsXf9BQUFMnz6d1157zVH+7bffOtplZGQ42rZH4xUX28OX\nu759NXZfjbuOr8bvq3GDxO4tvhp7dZV93kFqrwmMUPyprLbPgcrPLW7S9lTgQKJbeI9Waw3hFcfJ\nCTiDgJRxsGM3QXoZ+Uqk23427lhx0WPDDc888wx79+5lxYoVmM1mp7p3332Xq666CmODPbaLioqo\nrLRvXGS1Wtm8eTODBg0CYPz48ezZs4e0tDTAPrnx8ssv98wbEUII0S1VlpUCoFrszySoBvvQQO6X\n7xKsVDi1Va2ut5DOPHKIkpdvpuLVWwlSKlF6JeEXaP92b1asWFUZbmji0KFDvPTSSyQmJjJjxgwA\n4uLiWLFiBZWVlXz44Ye8/fbbTtekpqayYMECFEXBarUyatQo7rnnHsDes7Bo0SLmzJmDpmkMGjSI\nefPmeeKtCCGE6KaqysvwBwy1j08rBvt8gsSqX5q0NdgqmpQBBH2yxOlc9bPgF1Q/BNDHmtFJ0XqG\nR5KElJQUDhw44LLO39+fH3/8sUn5qFGj2LRpU7P3nDx5MpMnT+60GIUQQvRs1XVJgn8AAAaj62/9\n1bqRONvxNt3TmnUYy+j6nXONim89fi57NwghhBBAdUU5UJ8kqEbX36PNihWAkkL7mjrFebmUFBa4\nbKugExBUvxhzge5bEzolSRBCCCEAa6U9STD521fvrZuT0Fhq2DgAKorsSYLy7v0Uv+V6yFtHcVq+\nOWjqw50WrydIkiCEEEJQnyT4WexPATTXk2CKTgTsezrUCVHK0TQNTYfUyPMd5fEXTXe6NqJP+5/E\n8ybZ4EkIIUSPZrXWkPbTd1gr7E83+AXWJgmG+h6AHCKIIt9erto/OvVGy8TXVFWhKqAY/RxlwZH2\nBQIzh9+CajTiW4MNkiQIIYTo4fZtWkNSzlbHeUiU/YPdYKx/XL80MI6oMnuSULcBoGazOt2nqqIc\nBVBM/hwNGklS6U4Mtb0R/cdNcOM7cB9JEoQQQvRohsJ05/PavRUMpvqPSF1t8HFZ28Ogazq2BkMO\n1RUV+AGq2Z+BM+7GWlXttHCgL/Lt6IUQQgg3cZq4qNiThNSQsSiK/aNTs9moLK3f6Cn7l53268x+\nGFQDfhaL54J1E+lJEEII0aPFVKeTpUZRFT+OPv0HOuYNGE3OvQfBs1czAjj83XbAvoV05qF9RNc2\niT/yDgBBUb41ObElkiQIIYTosbKPp2FRNProOQRfdq3T/geqqcEWAi6GGwK/eh4/xXleQr4eQsKg\nYW6P21NkuEEIIUSPlf1z0xV/6xgaPAKp+NdvjqTWDjc0ThAAIpSmm0H5MkkShBBC9EgHvvyEhGP2\n5f/T/AY0qTc0eATSaKlPEpQG5d2dJAlCCCF6pNh9bwJQpvsz7Pd/aVLfcOKhKTDUcayqkiQIIYQQ\n3Vqpbt/tMVBxve1zQ35B9UmCIkmCEEII0b0F1SYHeYS20hIsoQ2SBIPiVJehxpAa/qvGl3QL8nSD\nEEKIHs04YU6rbQJCwhzHTYcbFEZMn036nrPxCwz2uaWXWyJJghBCiB6pUjeRETqCEQMHt9rWEtT8\nxEUde89CwrCRnRtgFyDDDUIIIXokAzYwmFtvCE7LK6uKc5Jga+M9fJEkCUIIIXqc1B3fYVI0MHRC\nh3rcqNO/Rxclww1CCCF6jKKcbE7u20H8gXUABPYb2O572Brt/jho0pWdEltXJEmCEEKIHkHTNNT1\nDxBfe27VVc4c2/6nEjRrjdO5r+/02JLu+86EEEKIBvZt2eB0nmFO6tB9IuMTqdC77zyEhiRJEEII\n0e0d2P4pCenvOZVZg3q3el266QysuvNHZUBQEL3nvMwx0xmkhp/bqXF2NTLcIIQQotuL/fmNJmVD\nr5nV6nVD//BIs3VDWqjrLqQnQQghRLemaZrj+Lgx0XFsMPac5ZU7SnoShBBCdGt73n6R5NrjmqBo\nSkb9joLjhxni1ah8gyQJQgghuq19ry4g2XoMgHRzCsmTryM4IpLYlKZbQ4umJEkQQgjRbcXXJgip\nYeMYcd1tXo7G98icBCGEEN3ewCm/93YIPkmSBCGEEN1SUW4uAEdjLsHPYvFyNL5JkgQhhBDdUtaB\nPQCEJra+y6NwzSNzEgoKCnjggQc4duwYZrOZhIQEFi1aREREBAMGDKB///6OZS2XLVvGgAH2CSWf\nfvopy5Ytw2azMWTIEJ544gkstdlgS3VCCCFEZcZBrLpKTEr792cQdh7pSVAUhVmzZrF582Y2bdpE\nfHw8Tz31lKN+3bp1bNy4kY0bNzoShLKyMh555BFefPFFtmzZQmBgIKtWrWq1TgghhKiuqsJYmk2h\nEorZ39/b4fgsjyQJYWFhnHPOOY7zkSNHkpGR0eI127ZtY+jQoSQmJgIwY8YM/vvf/7ZaJ4QQQhSs\nvpt+NUeoMAZ7OxSf5vFHIDVNY+3atUycONFRNnPmTGw2GxMmTODuu+/GbDaTmZlJbGyso01sbCyZ\nmZkALdYJIYTo2XavX02SUg2Arpi8HI1v83iSsHjxYgICArjxxhsB2Lp1KzExMZSWljJ37lxWrFjB\nvffe65FYIiODTuv6qCjfzVB9NXZfjbuOr8bvq3GDxO4t3ow9KWer49gQ07/dscjPvZ5Hk4SlS5eS\nnp7Oiy++6JioGBMTA0BQUBDTp0/ntddec5R/++23jmszMjIcbVuqa4+8vFI0Te/Qe4mKCiYnp6RD\n13qbr8buq3HX8dX4fTVukNi9xduxF+j2D8rQaxeSEhHerli8HfvpaCl2VVU69MXYY49APvPMM+zd\nu5cVK1ZgNtv34S4qKqKyshIAq9XK5s2bGTRoEADjx49nz549pKWlAfbJjZdffnmrdUIIIXqGo7t+\nZNe65zn0ylyqKioAKMzJxo8qCkJSCO3VC4MqmzidDo/0JBw6dIiXXnqJxMREZsyYAUBcXByzZs1i\nwYIFKIqC1Wpl1KhR3HPPPYC9Z2HRokXMmTMHTdMYNGgQ8+bNa7VOCCFE97f7X8+RVLqTXrXnJ/fv\nwWQJIOyLpwhQQAkI92p83YVHkoSUlBQOHDjgsm7Tpk3NXjd58mQmT57c7johhBDdW1LpTqfzqB9e\nIC3u14TVnhtDejW9SLSbrLgohBDCp+RmnAAgS4nm1OjZjnJD1s/1x2Y/j8fVHUmSIIQQoss7/OM3\nHPz6cwBOfmVfF0cfchmR8Wc42sRb0x3HSWPP82yA3ZRsFS2EEKLLi/7xRfvBuRegVJdRolvo/6uL\nKMnPa9LW8Lv/h9lPehI6gyQJQgghuqzj+/dira52TFDc9e4qDNVlVCn2pZZVowmt0TUBwb67zkFX\nI0mCEEKILivsi6eczpPzvqBEt1BisE9RNPv7U9mg/njKb5E9HzuPzEkQQgjRJWla4z4Cu2ClAqNm\nX3bZZDaTM/YOR93gi2TNnM4kSYIQQoguqaaqynGc1vfXTnXVhgDHcdzg4QBkqO1feVe0TJIEIYQQ\nXdIv618GIL3fFIZdcZ1TXd9r/uQ4Nvv7U3PVE5xx8yKPxtcTSJIghBCiS0ou/QkAY2AoAH43veio\nCwpzXlExok8MRqPs+NjZZOKiEEKILsNqreHIt19Sc+grEoDjxgTOPHs8YO8xyLnwQfIO7mS4Kt9x\nPUGSBCGEEB7z85b38I/ozRljxrms3/fh2yRlbXGcqynjndY86Nt/EH37D3J7nMJOkgQhhBAe0+/o\nf+Ao4CJJ2PPfd5wSBIDg6L4eiky4Iv01QgghPK7k5ZvZ8993nMoSj7/fpF1Yn1hPhSRckCRBCCGE\nV7hKCsC+rHIdS5CsnuhNkiQIIYTwiMqy8iZlh3/4ipqaajRNw6qrpIb/Cj9L/RoIqkxQ9Cr56Qsh\nhPCImjV3NCmL3vEy+955kYrSEoyKhmIJxmA0eCE64YpMXBRCCOF2pUWFzdYll+wgdUMFiYAxIMRj\nMYnWSU+CEEIItzv61f8AyDnrToJnr+bEwOud6hMr9wOg1diXYk439+d4ym89G6RoQnoShBBCuF3d\nJMXY/kMAqM7PctTZdAWDogMQ2i8FgKE3P+zhCIUr0pMghBDC7XIIx6qr+AfaJyX2PXuioy49arzj\nOH7QMI/HJponPQlCCCHcTgFO+p1B3Y4LvWLjqJr5D4pyT8GX73kzNNEC6UkQQgjhVpqmEaCXo5kD\nncr9LBZ6xydijEoGIP+8e70RnmiB9CQIIYRwq4KsLAKUKpTwOJf1gyb+msIho0mIkdUVuxrpSRBC\nCOFWeccOAxASf6bLelVViZAEoUuSJEEIIYRb1ZQWARAY3svLkYj2kuEGIYQQblFWXMzRbz7FcHwH\nAIFhYV6OSLSXJAlCCCHc4sjJ5vTBAAAgAElEQVTn75OU+bHjvOGeDMI3yHCDEEIIt1DU+u+hWUpv\n2azJB0lPghBCiE5VWlxMZVkFurXKUWYZf7P3AhIdJkmCEEKI05Z55BCazUpUQjIlL88BIKm2Lo9Q\n+iQkei020XEeSRIKCgp44IEHOHbsGGazmYSEBBYtWkRRURELFiwgJycHo9HIsGHDWLhwIf7+/pw4\ncYJLLrmElJQUx31Wr15NeLh9va63336bV155BV3XmTBhAvPnz5euLCGE8JKgT5YAUOWirt+sZ+Xv\ns4/yyL+aoijMmjWLzZs3s2nTJuLj43nqqacwmUz85S9/4aOPPuK9996joqKCVatWOa4LDg5m48aN\njv/VJQjHjx/n+eef56233uLjjz8mPT2d996TZT2FEMIbSgqb3wYakATBh3nkXy4sLIxzzjnHcT5y\n5EgyMjKIi4tj8ODB9kBUleHDh5ORkdHq/TZv3szkyZOJiIhAVVWmT5/Ohx9+6Lb4hRBCNC/tq4+b\nlGUMuYncs+/EeMPzXohIdBaPp3eaprF27VomTpzoVF5ZWcm7777rVF5WVsa0adOYNm0aK1euRNft\nW4lmZmYSG1u/OldsbCyZmZmeeQNCCCGc6NWVAJTq/o6y0JgEkkaehSUwyFthiU7g8YmLixcvJiAg\ngBtvvNFRZrVauffeexk3bhyTJk0CoHfv3nz++edERkaSl5fH7bffTmhoKNOnT++0WCIjT++XNyoq\nuJMi8Txfjd1X467jq/H7atwgsXuCUa/GqqsMn7+G1CXXAjBw1GBMZrOXI+sYX/m5u9LZsXs0SVi6\ndCnp6em8+OKLjjEqm83G/fffT2hoKPPnz3e0NZvNREZGAhAZGcmUKVPYsWMH06dPJyYmxmlYIiMj\ng5iYmHbHk5dXiqbpHXovUVHB5OSUdOhab/PV2H017jq+Gr+vxg0Su6fUVJRRhYmcnBKK9EBClTIK\ni6pwPY2xa/Oln3tjLcWuqkqHvhh7bLjhmWeeYe/evaxYsQJzbXapaRoPPfQQBoOBJUuWoCiKo31e\nXh41NTUAVFRU8OmnnzJw4EAALr30Uv73v/+Rn5+Ppmn8+9//5vLLL/fUWxFCCNGAYqumGvvf9Ygb\nlhJ5+ytejkh0Fo/0JBw6dIiXXnqJxMREZsyYAUBcXBzTp0/nvffeo3///kybNg2A0aNHs3DhQn78\n8UeWL1+OqqpYrVYuvPBCxxBFfHw8d9xxB9dddx0A5513HldddZUn3ooQQohGVFsVVsUEQEBQEKER\nvvttXDjzSJKQkpLCgQMHXNY1V37JJZdwySWXNHvPGTNmOBIOIYQQ3nHiwD4Mtiqsqm/OPxAtkxUX\nhRBCdEjqju+I+uEFQoHjxn7eDke4gaxwIYQQokPKMtMcxzX+kV6LQ7iPJAlCCCE6RC+qf8pMDe/r\nxUiEu0iSIIQQgoJTp9i7+nGy0lLRNI3yktYnHkaWHHQcW3q1/zF00fXJnAQhhOjhThzYR+jny0gA\n+HgRR5QowrUCqqc9TlhUb5fXHPnxG3or5QCkhp/L4JFneS5g4THSkyCEED1UdWUl6Xt3UfLlOqfy\nPnoOfoqVEzu2s+udV9A0rcm1AT+sBuBowDBGTJ+DySRPN3RH0pMghBA9VNUbtxEBRDRTn5C+EYAj\nqw6ScuuTTnWlaihBeiX9r7ndvUEKr5KeBCGE6IFyjqc3KQuevRqbrjQp76Pn8PNriynOywWgMCeb\nPvopAPwDA9wbqPAqSRKEEKIHytz2rsvykFtXUXLRX5qU96s5QtrmfwJQVpAHQLEe6L4ARZcgSYIQ\nQvRAis2+N07grFfJJZz0hKkAqKqKamh+JHrXWy9QUVwAQOXYme4PVHhVu+YkZGZmcurUKUaOHOmu\neIQQQniAwVpBiW4hWFVJmv2sU51qMLi8Jql0JwBHf6kAwBzY/l0FhW9pU09CRkYGM2bM4PLLL+cP\nf/gDAB999BHz5s1za3BCCCHcw6BVUWTs5bKucZKQ/6t7nc7NlfbhBj9JErq9NiUJCxYs4MILL2TH\njh0YjfbOh/POO4+vvvrKrcEJIYS35RxPZ+/HG1ps4+oRwa7Maq0h1FZAjTnEdQOlfvJiau+JJAwd\n4VTdy5YNgH9gsNtiFF1Dm5KEPXv2MHv2bFRVRan95QkODqakDStyCSGEr9I0Df//LiQhbQMHv9nm\nKPvli/9RXVlJTU01x1+6i/2vL/FypO1zKvUwgUolpvhhrhvouuMw+cKrAMhQ61dU9FOsAFiCJEno\n7tqUJERGRpKe7vy4zOHDh4mJkWU4hRC+R9M0stPTyEo94rI+fc9Ock8c5/C3XzjKYna/CkDZylvo\nu/+f/PLR2xRmZRKmlNKvxvV9ugpN09j1n1fJOmqP01pdBYCpmZ6AXnHxpIaM5ZgpiYAQe5v43z5M\navAYMtRYRzuTWRZQ6u7aNHHxlltu4bbbbmP27NlYrVbef/99XnrpJW699VZ3xyeEEJ1uz1vPk1yy\nw34ye7VTnaZpRHz9HACNvwbtef0JEmuPdc1KeVEB/rXnNqsNg9H1hD9XCnOyCQ6PbNc1HZV9LI3k\n3G3kbtnN7oB4DNEpRACqwdTsNSNm3OV0HhAczIjf3c2B7Z/Bz6+7OWLRVbSpJ+E3v/kNc+fO5aOP\nPiImJob169dzzz33cNVVV7k7PiGE6FSaptUnCNh7DY69dDfZ6WlomsbeNc80e21i1QGn86KdnziO\ny1/9I+l7dlJeWtpqDCWFhRjWP8De9SsdMdk0W3vfSptlb7evnNiLQpLK99Dv6H8AMHRgKWV5oqFn\nafMjkJMnT2by5MnujEUIIdzu6I5vabhlUeW3bxOrlHB0+wayq8tJqj7Y7LUNqaU5oDt/sEd8/Ry2\nr2Ffym8ZfNHlzV5bnJ1JCBCX/z0whz3rXyU570v8b375tLrwf/nif/Td/0+sU/9GeHQfALJSj5BU\ntguAKt3omE8AoKjt78UwBzYz2VF0S23qSXj//fc5csQ+lnX06FFuvPFGZs6c6SgTQoiupqy4iNLi\n4ibl/j++6XQeq2XYD2xWEppJENQZy0kNcd7l0Fxd1Oxrq0e+aLYOoOhkmv0eitXes5H3JQDlRYUt\nXtca4/6P7P+/8SFqaqoByN/6hqO+YYIAYAkNbfdryGTFnqVNScJzzz1HaO0v09KlSxk2bBhnn302\njz76qFuDE0KIjig4lYW27h5+WPVkkzoTVtL8BnJqlPOcqqSKvS7vlZ40jcCQENTgKKdyo1aFuaYE\nTW96TbW/6/UH6sQfestxXPLKLY7jUxubH+poC5Ne7TjOOZZGSWEh8Vb7pPN0c0qT9lFx/dr9GpYQ\n6UnoSdo03JCfn0+vXr2oqqrixx9/ZPny5RiNRsaNG+fu+IQQot1OfL+VRCC6zLlnwKbZ8KMaLSgK\ng9nf5bWN1S0sFBiTCCftZVW6kd5KHmhQSBBhNJqHoLd93QS1wX5KMVoWYF+bwUg00LYYAbKPpxGh\n1PecBH/yOABWXSXL2BdbaCzkHHLUp4aMZUSTu7TOzxKAFThqGcrwDlwvfEubkoSIiAjS09M5ePAg\nw4YNw2w2U1FRga67SKGFEMIL6sbjU3tNwD/f/mFYpgTS8Dt9VVk5qgKKOQDV2Pyfv+MDZhAWm0TV\nZ/8gfvSvAIg+cyBF31vI6X0OhqKTJFTbX8NETZPrVVt1k7I6qTu+I6rZWjj07Rf02bWKDN1M7zkv\nt9CyQbz791BwaDdJQKYSTUztDo0A1RipDuiNKbQ35NRfEzlyYpvu3ZiqqlhueYWhHZjPIHxPm5KE\nO+64g2nTpmEwGHj2Wfsa31999RUDBw50a3BCCNEWqT9+S9/99h0Kk3O32YcAFDDqzmPwBZknCAFU\nPwtmi+sdDLVrljE4qnZqY8pzjvLAkBAst64gVlXZ9+pCR3meuS+BNakAlE1+hLL/vYCiN/+kQtne\nz4gCanQDJsXeLkuJdmy93GfXKgAsSvOJRmNhXzxNWO1xZdRgyK5PEgKUajCaCYs/Ew7XX6Oa2rV1\njxOjsflHJ0X30qbfkmnTpnH55faZuhaLBYCRI0fyzDOnN34mhBCdoWL3ZqdzVbF3s4coZex+80lQ\nFExVRYRbs0EBU2AIMcln4mrN2NCo3i5Ka++r1k3jqu9F1Qx+pIaMxxAUztDkMzikGFpMEjRLGFTC\n8fCxJBd+C4BNMTa8ZbtUV1U5nZsj4yC7USOjmdiUARwpmkPvHS/Zi4yyEJJoXZtTyerqaj777DNO\nnTpFdHQ0F154IZGRke6MTQgh2sRSU9CkrBIzQVSSVPFzfWHt+H9w774u73Pc2I/BbXi9moDeUHzM\ncT7i2j86jrVWkgRsVqp0IyOuu52Sl+1JgqaaoIPbP+SdOEbDlQui+w+lcF8QYUr9PAmlNiGIHzqK\nqtolIk6nJ0H0HG16uuGnn37i4osvZt26dRw4cIB169ZxySWX8NNPP7k7PiGEaFFFWSlRNE0ScoKb\nHw41+vs5nacnTOX4mdMZfMuiNr3mwKl/5KhlKAC64vxnVFfUFpMERauhptH3M1ftq/XWx/z3bnmP\noE+c940wW/wpNYY7x1Rj721QDPWxmjqwkJLoedqUSj7++OMsXLiQK664wlH24Ycf8thjj/Huu++6\nLTghhGjNkS+3kACk+Q/CfMbZxNYtGWwJo/FDB3UCQyOczgdfPLXBUELr/CwWIs+5ArbuJWjwBKc6\nHQMGvaqZKwGbFWujP72JMx7EusZ5GeRyLLTaV3tiV5Mis8VC7NR7OLbpH449JSIG2dd4UJX6xEOV\nJEG0QZv+q0hLS3PMSahz6aWXcuzYsWauEEII9yvKzSUh3b7kcNSE6SiGBh+CAa6f508NHk1g7bP+\nR4NG2tu2I0Go07f/IAJmrSJ5zDlO5ZpqQGlm7KCmupq+5fubPBFhCQxqsm5DIBWtbkGtNpqYWawH\nYjKZCe3ViyF/eITjRvs6CPGD7Ls9Kg2etzTKcINogzb9liQkJPDBBx8wZcoUR9lHH31EfHy82wIT\nQojWpG17j2Qga8QfSUlMJvunbY46U6Dr1QSD+p/tOB464/9O6/UNLh4D1BUDhmaGGw5t/4R4xYaZ\npvWNN1syKTbKiosJDgtr0tbRxlYJ2BOfQdfMpq+/87oKA25aiN4gYWmYDBllB0fRBm1KEh5++GFu\nu+023nzzTWJjYzl58iTp6em8+OKL7o5PCCGaZSjOJF8PIeWc8QCYwvs41gIwBbhePrjhpkYd6UFo\nja4YUJvpSbCVu3qewk4xNP1zXJxzqtkkISstlT76KdL8+jPid66THfsOk67nNhhcvJ4QjbXpt2T0\n6NFs2bKFrVu3kp2dzUUXXcQFF1xAWAsZbkMFBQU88MADHDt2DLPZTEJCAosWLSIiIoKdO3eyYMEC\nqqqq6Nu3L08++aTjqYmO1gkhur/0PTvtCxo1WLEw8azzsR5cB4ChmW/KRr+2r2LYIaoB1UVPQlVF\nBYknP3QqS0+4CtXkx2DqV3YEqNaNmBUrubu/oG/KAJcvc+qb/5IM9Kk82rEw3ZAgie6nzb8loaGh\nTJ06lVtvvZWpU6e2OUEAUBSFWbNmsXnzZjZt2kR8fDxPPfUUmqYxd+5cFixYwObNmxk7dixPPfUU\nQIfrhBDdR0l+HhlHDrJ39ePs3ui8MVNJRmqT9saGvQTNrKgYGObeLxPN9SSk7/recVxx6V8BGHrp\nNAZPvKJJ21OmWADHxk8u1Q5PFIyYeRrRCtGyZnsSrr/+ehRFaa7aYc2aNa22CQsL45xz6if3jBw5\nkrVr17J37178/PwYO3YsADNmzGDSpEk88cQTHa4TQnQPR3ftoNe3ywkGggFOHQTqPxD12l0OC8ff\nT93AgqFBYmBoZvZ+cGSEy/JOoxowuJhzUFNav69C74TEJvXxg4fxy3cJxFvT0eJGQdoxjgaNdLk/\ngqZpBBfsB6D/uAkuWgjROZpNEqZPn+6WF9Q0jbVr1zJx4kQyMzOJjY111EVERKBpGoWFhR2ua08P\nhxCia9I0jV7fLm9Snr53FwlD7dsS6VZ7khCddKajvmEXusFo4ljAYPqV73O6h7uXFNZVo6MnwabZ\nOPLNNs4YNwFbZfPzEcAee8rMeRz68hMGXXAJ2a983Gzbg9s/o6+LtSHaIo9QIml+m2shGmo2Sbjm\nmmvc8oKLFy8mICCAG2+8kS1btrjlNdoqMjKo9UYtiIry3X3VfTV2X427jq/G74m40/btI/aMMzD7\n+fH5yr/j6tkp7evXibroFQCMqg1NV4jpG+mUHNR9FPeKCmPovYtJXXItAFlqH/poWW5/L0azmQCl\nmqKTRyjMPEHM3tc5XJaLsaZ+0YaWYoi97joAMjFgUDSXbfcVHm/TvVwJ+L/lVJaWEunmn4Ov/q6D\nxN5QixMXP/vsMz777DMWLWq6CtmCBQuYNGkSF1xwQZtfbOnSpY6nIlRVJSYmhoyMDEd9fn4+qqoS\nFhbW4br2yMsrRXO1GXwbREUFk5PT8jeDrspXY/fVuOv4avzujHvXv18C1YgxNJp+qe+wPWEqQy+9\nhtisL0CB4ov+Qshn9cOIvfR8RyzxWZ+DAnl5ZU731HQFVdEpKauhD1D560WU5p4iefhodE1z+7+B\nVbMP06ofLKYk8WoigKpTx0kq321v8Jun2xSDpqhoNTUu21oLcx3HHXo/xkC3/hx89Xcdum/sqqp0\n6ItxixMXX331Va666iqXdVdddRWrVq1q8ws988wz7N27lxUrVmCunXU8dOhQKisr+eGHHwBYt24d\nl1122WnVCSF8R3LB1yTnfUG/1HcAHAsjZRn7kkM4fVMGkDViFtV6/feZ1hYYstb+WaubkxAV14+k\nkWdhUA2e2b2wwdoJurV20aQGPR3BEW2bOGnDgKJZXdapthZWdBSiE7XYk3DkyBHH5MDGxowZw+HD\nh13WNXbo0CFeeuklEhMTmTFjBgBxcXGsWLGCZcuWsXDhQqdHGcE+PteROiGEb2i8e2Edm2YjwFpE\nkSUOgJRzzqdy6Ghq1twBwJHvvyLlnPPJJZxyUwRDGl1frATTi0LvPeKn1v9ZDT5hfzqhbn+HTCWa\ntnYGa4oRRXedJNSVF1/4YJvvJ0RHtJgkVFZWUlpaSlBQ0y6KsrIyKisr2/QiKSkpHDhwwGXd6NGj\n2bRpU6fWCSG6ttKiQlK/+C9JLuoyDx0glFIKAns5yox+9QsZ99m1ksOqQjQFnNCa/m0KnfIAx/Z+\nz5AQ18syu1vDpaHrJggml9i3XqyIdL3mgSst7SapalYy1BgG9B90GpEK0boWU+3BgwezefNml3Vb\ntmxh0CD5BRVCtN+Rj9aSlOH6b0txRjqqomMMjXaUGY0mThrqt3eu+GU7ACZbRZPrI2JiGXLx1E6O\nuB3U5r97qX5tHxPWFAOq1kySoFvRlNZ3iRTidLWYJMyZM4fHH3+c1157jZMnT1JdXc3Jkyd57bXX\nePzxx7n99ts9FacQohvQNI09H/6b6MKdjjLTzBc4bkwiNWycvU36jwBYIqOdL+5/keNQsdn7FYzj\nrndzxO3nannlOgZLYJvvo6vGJhs4AeRmnCBWy0SXJEF4QIvDDePHj2fJkiUsXbqUZcuWOcpjYmJ4\n7LHHOP/8890eoBCi+0jfvYPEEx84llI+Gjic4ZYABt+ykPSfd8H2bzBZ7U8rxNXuXFivfnE3VbPP\nZwju1ccTYbeL2kKSYPQPaPN97ElC054Ev/fnAxBRc6r9wQnRTq3u3XDZZZdx2WWXkZqa6lisKDk5\n2ROxCSG6mYqCHMdxurk/Q3/3J8e5yWzfUyFWywTA3GhHw/gRZ6Htty/NHG+1b1NvDrC4Nd6OUBrt\nDFmm+xOo2OdvqWa/Nt9HVwxEk0t+ZgbHt76DYq1i+My5jvq6ewrhTm3eBkwSAyHE6Wq4C6Ie3d95\n62L/lj9AA0NCyNFN+Cs1jjI//66XJNBoz4jSUTMJ3GlfAMrQjkcw/arsKyrmfPD/SK5NnGxW13MU\nhHAX2QZMCOExgSe/cRwPnOy8BovRWL/XwjGTq+ceoHSc8zwoYzM7PXqTqjonAr3PqH+iQW1mPwmX\n96nd/8HQYK2E9D07HMfHz3TP0vlCNCRJghDCI06lHyWKfPL1ELjuWUyNPjCDwus3XjIPnujyHgFh\n4U7nXXG748a7T1qC6x/FNLdjTkKFn33RpWjqh2iivl/hOHa1e6QQna3r/RcmhOiWsn+2r5CqjbuZ\n4EYf9mCfg5CN/YPRWlHWpB7AYKr/ln5SjXXZxtsaTlws1gMwNejtCI2OafN9UqbNabYuNcT1IndC\ndLZm5yScOHGCuDj7imfHjx9vrhkmk4levXphbGbvdiGEAOxPNQCR8QnNtimLHgmnPsEU6HodQWOD\n3oeu+ghgwyQhaNpfnepM7Rge6ZOQQFozdSNm3NX+wITogGY/2adMmcJPP/0EwMUXX4yiKOi6682Q\n/P39mTt3LjfccIN7ohRC+CxN08jPykDVDRQrQSS2sHfBkCuuJ23nmZw59lyX9WZ/C3VT97QWFi3y\nJqV2cmKGGsOAqN5OdYZ2fJlqbiilWu+ayZHonpr9ja1LEAB++eWXZm+g6zoHDhzg5ptvliRBiB6u\nurKS6qpKgkLrd2Td+8FbJGVuBgXKklzPNahjMBo4o5kEAcA/MJAiXcWoaFj9I5pt502qwf7hruhN\nN6LqjDkUNiRJEJ5z2r+xiqIwcOBAl9tJCyF6lkNrn0R/60+OnRorK8rpk/GZo94ccnof7KqqomDv\n0VRDoltp7R1K7TBIXZydrQL/1hsJ0Uma7Um4/vrrURSluWqHNWvWAHDJJZd0XlRCCJ9RlJuLnyUA\n/8AA+tUcAcBmtbLvsw9ISN+IpcGfEf/QphMW28ug2D98zaFt23LZ01SjPUlQXfQktFep7k9Qo0WT\nKgyy76PwnGaThOnT65/BPXbsGO+++y7XXHMNsbGxZGRksGHDBq699lqPBCmE6JoKTmVh3PgQ+bqF\nspE3ULdIcsaBfSSkb2zS3hIS1qSsowzmrvmNWlXrehLqFz46OWgm1rJChrbzXjlB/Qkq2+1UVmP2\nzu6WomdqNkm45pprHMfXXXcdq1atIiUlxVE2ZcoUHn74Yf7v//7PvREKIbqszJ9/JB4IVioI3rXS\nUR7x9XMu2weHd963//YsTORJdeskqA2GGwaOn9She8VedB28b08S8gglkiI0S+clWkK0pk1zEo4c\nOUK/fv2cyuLi4khNTXVLUEII31CTd7LVNpW6iWNJ12C84Xn8LKe/jHKan30FwzaMhnpFRExfivRA\nqodPO+17mf3svSXVupEaxZ4UqQGnP2QjRFu16Xmcs846i4ceeoh77rmHPn36kJmZyfPPP8/YsbKg\nhxA9WXLBV83WVelG8ofdQP9fXURUJ75m1PjrOPr1e/RPGdKJd+08Zn9/4uasaL1hW+4VEEANcCJk\nBKaKXLC2b5MoIU5Xm3oS/va3vwFw5ZVXMmrUKKZMmYKmaTz++ONuDU4I4V15GRl89dabZKUeYe/H\n6x1PLQCUFBa2eG2mfzL9f3VRp8fUJ/kMht9wL/6BbV/i2Ff5WwLgN08zdPodWE32CYu28mIvRyV6\nkjb1JISFhfHss8/aF0XJzyciIgJVVZ3+YAghuhebZsP8/sP2yYiHNxAIHFu5lcTZf6emuhre/lOT\na9LNKSRUHwJAN3X/D3FPCK5bfCqoF1SAXl3h3YBEj9KudRJUVaVXr14cOnSIpUuXMmHCBHfFJYTw\nsqwjh5uURVIEwC9v1U9MzD3bvkTwsaRrGHrzPHKwr4WgmwM9EGUPUrfNtC7bRQvPafMaofn5+Wza\ntIkNGzbwyy+/MGbMGObNm+fO2IQQXlSYfojGD9vZdPtswcCKLEdZ0sixMHI1dTMESgPiiCrPR/EL\n8kygPYVS+51Oc88iTUK40mKSUFNTw6effsr69ev58ssv6devH1dccQUZGRn8/e9/JzKyay5mIoQ4\nfbbsw1TqJvyVGkeZQdGxWW2Y9GpQ4NiZ02k8fdBYbe9tMId15nRFETf2Qko2biN63GXeDkX0IC0m\nCeeddx6KojBt2jTuvvtuhgyx/zlYu3atR4ITQnhPYOkJckwxjJq9kNwX/ugorywvJUwp5ZgpiSET\nr2h6XU0BKBAS269Jnei4iD4xMOcf3g5D9DAtzkkYMGAAJSUl7Nq1iz179lBUVOSpuIQQXlBeUkJF\nWSkHv9lGb3KxGQMJCQ+j5KK/cDRwBAClBfkAWEPiXN6jrP/l1OgqUfGJngpbCOEmLfYkvPnmm5w8\neZINGzbw6quv8thjj3H++edTXl6O1Wr1VIxCCA84uvMHen33PAAxjepiUwaQd2gXlO2iqrSUAMAY\n3qfJPQAGX3Q5XHS5e4MVQnhEq0839O3blzvvvJOPP/6Y1atXExUVhaqqXHXVVSxbtswTMQoh3Cwr\nLdWRIDRkShrjOFYM9u8Uhan2ZYKNfvKIoxDdXZufbgAYO3YsY8eOZf78+WzZsoUNGza4Ky4hhAdl\nb99AkotyxdjgT4RqP07K3EKNrpIw8hzPBCeE8Jp2JQl1/Pz8uPLKK7nyyis7Ox4hhBfo5kAoa1qu\n1VQ7js3B9RsLlWMhogeseChET9euxZSEEN2TUlO/il96vyku28QNHe041uRPhxA9Qod6EoQQ3UPa\n7h0U7/6MpPI9AFin/o2h0X3Ieekj/JUaBpw/2dE2ICiIktpjA7LqnxA9gceShKVLl7J582ZOnjzJ\npk2b6N+/PydOnODOO+90tCkpKaG0tJTvvvsOgIkTJ2I2m/Hzs+96dv/99zN+/HgAdu7cyYIFC6iq\nqqJv3748+eSTsriTEO0U+c1yGv5XEx5tf2LBMHUR+Pujqs49Bqm9JpCcu02SBCF6CI8lCZMmTeKm\nm27ihhtucJTFxcWxceNGx/mSJUuw2Zz/+Cxfvpz+/fs7lWmaxty5c3niiScYO3YsL7zwAk899RRP\nPPGEe9+EEN2I1VrjdHBY5JoAACAASURBVH4s+VrH6okRfRo/BGkX0DcFcrdhQh6BFqIn8NjA4tix\nY4mJcf2HB6C6uppNmzZx7bXXtnqvvXv34ufnx9ixYwGYMWMGH330UafFKkRP8PO7rzidB8cktnqN\nOcC+XbFZkZ4EIXqCLjMn4dNPPyU6Otqx9HOd+++/H13XGTNmDPfddx8hISFkZmYSGxvraBMREYGm\naRQWFhIWFtb41s2KjDy9DWiiooJP63pv8tXYfTXuOl0p/uSi75zOQ8MDm42vrrykd3iTsq7OV+J0\nRWL3Dom9XpdJEt59990mvQhr1qwhJiaG6upqlixZwqJFi3jqqac67TXz8krROrijWlRUMDk5Ja03\n7IJ8NXZfjbtOV4pf0zTHceXlj5L54+cM7ZPoMr6GcVfVqPgB6eb+BHeR99KSrvQzby+J3Tu6a+yq\nqnToi3GXeI7p1KlTfP/990yZ4vzoVd3whNls5vrrr2fHjh2O8oyMDEe7/Px8VFVtVy+CED1ZRWkp\nAEdjLiYqPoHhV9/UZJKiK73i4skcfgvJv/k/d4cohOgCukSSsH79ei644ALCw+u7MsvLyykpsWdE\nuq7z4YcfMmjQIACGDh1KZWUlP/zwAwDr1q3jsstk+1QhWnJ05w+cPHQAgMraJMHg3/5vFv3HTSAg\n6PSG6oQQvsFjww2PPfYYH3/8Mbm5ufzhD38gLCyMDz74ALAnCfPmzXNqn5eXx913343NZkPTNM44\n4wwWLlwIgKqqLFu2jIULFzo9AimEaJ5jb4aU1VRXlmMGVD+LN0MSQnRxHksS5s+fz/z5813Wbd68\nuUlZfHx8i3tDjB49mk2bNnVafEJ0F5qmtTp0UF1hX4PZYPb3REhCCB/VJYYbhBCd58BrC9i7+nGn\nyYkN2TQbtu2vA2A0+XkyNCGEj+kyTzcIIU6fzWojznYCbFBWXExw7WTehgnD0R+/IZr82nJZFEkI\n0TzpSRCimzh5cD8nV/2pvuDtPzmSg+K8XEdx9E/1iygFRvT2WHxCCN8jSYIQ3UTF1lcJV5yfkS6p\nTQ6yNzzdpP1xYxIxZ6R4JDYhhG+SJEGIbiArLZVocpqUlxUWABCjnwLsiUGdmuA+nglOCOGzJEkQ\nohvI3boWgCI9kJKL/kL26DkAVJWXOdqU62aiL7u1/iKb7L8ghGiZJAlC+IjD328n9eX7KCksbFKn\nq/Y5yOZfzyU2ZQAmi32xI2tlGTbNhlVXyYoYS2RsLKm9JgCgWCs9F7wQwidJkiCEj4j+6RWiyCf1\nw9eb1Km2Sk7Ri97xiQCYAwIA6LNrFYe/3oZR0TCE2icpGoIiaq/q2L4lQoieQ5IEIXyA1VrjOE4u\n/Ynj+/c41ZtsFVgN9Wse+AXUL5sc+7M9qQjs3RcAxWiqrZEkQQjRMkkShPAB5cXFTue2L1by82uL\nyXrpNgCibNnYVLOjPiginMZ6J/cHIGbwaDKVaHqde5UbIxZCdAeymJIQPqCipJiABueRFBFZUwQK\n1NRUY1Q0rIH1ax6YTGb+f3t3Hh9Vfe9//DUzyWRfSQghCSFhCQFEWSxVqljwqiiF1qVSf1p/Wter\n1p9LveACgtoa6+1DvfIrble9lR/W4kKhCtaFurSKiOxIQCBAEkNWsk6WmfP7Y8gkwwzZmMnMkPfz\nr5nv95wz7wkh85lzvuf77TzioNqIY1h8AgDJQ9JJvrGgf4KLSEjTmQSREFBf/j0ApeOv9eirKXP2\nWRLS3NpLxv3S9bjZrDUaRKT3VCSIhIDBm54DICbFc26Dsp1fA5Ay+nS39rxpM1yPG1PG+TGdiJyq\nVCSIBLnWlhbX4/SReR799poyWg0zg7NzPPqK86/msCWL8XOv8WtGETk1qUgQCXIVhw8CsC91Omaz\nmf3R4936o4/uowWr1+Whx5xzPvm/egSL2dIvWUXk1KIiQSTIHfn6IwCGTDrP2WC437o4xDiCXf+V\nRcQP9JdFJMiZmus4asSQduxyQkTuZI9takbM6u9YIjIAqEgQCXI5jdtIMHWswZA3bQaR1z3P/vQL\nXW1jZlwciGgicopTkSAShPZ+/QWVz/2KisOHvPaHh1sxmutdzzXmQET8QUWCSBBq2fIuVpOdmnef\nPuE2YXUl/ZhIRAYiFQkiQcgwOc8MpFEBOJd5Pl7m7Fv7NZOIDDwqEkSCTPGe3SS2lLm1JV37jMd2\ncYNS+iuSiAxQWrtBJEgcOXSA+opyUr9aCqaO9n1xkzg90nNaZbPZTFH2HKIHZxHXjzlFZOBQkSAS\nBOxtdqLee5gob53hXlsBGH/hpX7LJCKiyw0iQWD7G8+esC8uZ0I/JhER6aAiQSQIpNQVnrBvUPaI\nfkwiItJBRYJIgLXYbFhpocg6CoCyiTcSd9MrVBvOkQZRsbGBjCciA5jGJIgEUFVpCfVVlSSZWrHk\nTCFu+gOuQYjRP/kPDu3azFgvgxZFRPqDigSRAGmx2QhffT8WIxpMEB7jfo9CytBMUoZmBiidiEg/\nXm4oKChgxowZ5OXlUVjYcf11xowZXHTRRcydO5e5c+fy6aefuvo2b97MnDlzuPDCC7n++uuprKzs\nUZ9IsLM77Ox/bTEA8aZGAKLikwIZSUTEQ78VCTNnzmT58uVkZGR49D3zzDOsWrWKVatWcc455wDg\ncDj4zW9+w8KFC1m3bh1TpkzhySef7LZPJNi1tbWy76X7GeoodWtPH5kXoEQiIt71W5EwZcoU0tPT\ne7z99u3biYiIYMqUKQDMmzePtWvXdtsnEuy+fe33DDHcZ1RsNsIwmzWOWESCS1CMSbj33nsxDIPJ\nkydz9913Ex8fT2lpKUOHDnVtk5ycjMPhoKampsu+xMTEQLwFkR6pP1pDdovn7Y4lcePRJMsiEmwC\nXiQsX76c9PR0WlpaeOyxx1iyZEm/XToYNOjkbi1LTQ3dyXBDNXuo5m5nqygmotPzgzHjGNawA4uj\nNajfWzBn646yB4ayB4avswe8SGi/BGG1Wrnqqqu49dZbXe0lJR1L4VZVVWE2m0lMTOyyrzcqK+tx\nOIw+5U5NjaO8vK5P+wZaqGYP1dztUlPjKPnnuwwzTJSED8N6+ixMtdWwZwcOe1vQvrdQ/rkre2Ao\ne2B0ld1sNvXpi3FAL4I2NjZSV+d8Q4Zh8O6775Kfnw/A+PHjsdlsbNy4EYDXX3+diy66qNs+kWBV\nW1VFduMOihLPZOz1ixk5+YdkTjiTOiOKxKk/CXQ8EREP/XYm4dFHH+X999+noqKC6667jsTERJYt\nW8Ydd9yB3W7H4XAwYsQIFi1aBDhXuHviiSdYtGgRzc3NZGRk8Pvf/77bPpFgdejbXUSZIDKj4y6G\n+EEpxN/8xwCmEhE5MZNhGH07334K0OWG0BIMuZsa6omK6f0pu7Ki/USvc86LUPfjBQwdFTq3OwbD\nz72vlD0wlD0w/HG5IeBjEkRCxeHdO0n4xxNsif8BaVMvpOloFeawcFKzRxAdd+LBQg6Hw1UglJjT\nGTViVH9FFhE5KSoSRHqo/kgJCUBu7Qb4+wZijrUf/lcao28sOOF+5YeKiG5/kn+B5kMQkZChv1Yi\nPWRvbfbann7cxEid1dVU02prApwTJuVMPssv2URE/EFnEkR6yNHc5LXdbpi8ttsaGuGNu0g49rz1\nnFuxakVHEQkhOpMg0gO2pkaGH1rjtc9i8j741dZY7/Y8PCrK57lERPxJRYJID5Tt29Nl/6Fd2yku\n3OXWVr7PffrliOhoRERCiS43iPSAYbcD0GaYabvkYextbZjXPU6UqQWAxE+dU4k3DHmamHjnBYYh\nW150O4Y1SkWCiIQWFQlyymlqqGfPW8sIa60n75cPYQmz9PlYW995FeoriRr1AwBqp/2a7MxhALT9\naikHNn9F2qbnXdu3NjdTV1XJvvdfJ/e4YyWmpNDU0ucoIiL9TkWCnFJaW1uoee1eckw2AKq+Lyb1\n2Id6X+Qc+dj5YMtWAMI7nQ0ICwsnKj7J/fWbbVS++zS5VHocKzYhgaYQnaRFRAYmjUmQU8rOv/6J\n2GMFAoCt7ij2NjuFL85n6zv/06tjbVn5gkebNdL9kkF0QrLb87IdGxncqUAon3xrr15TRCSYqEiQ\nU0pqxUa35401lRR+9nfSHd+Tc+SjHh+npvwIuVWfe7THJrsXBUlpabTNLaBk3C8BsNd0zJlQN/N+\ncidPpdUw02rov5qIhB5dbpBTRktzM3GmjrkMHAY0792Ipa2ho83h6NGMhyXbvyYLODLpZuJS0yn9\n8j1yL/gFkV4GHyalpVF5cC8AlqYqAA5kXMxpI0YDEHX1M5hUj4tICFKRIKeM5qZGwDm5UeXkm4j9\n+mVymra7bdPa3ExEN/MV7PvmK7L2/BmArNMmYY2IYHB215cNLOFWAJKbD9OIlXGzLnf19WVBKBGR\nYKCvN3LKaGt2Tpt8OGcOI6acRSStHtu0NHufWrldU0M9rV+/5XpujYjo2YubnHdQxJmaqLBman0G\nETkl6EyCnBJ2vPwIw1q/A8Ac5vxW34SVGNyLguaGeuISEz323/7+2ziO7COmsYShXu5M6E5CWrrr\ncVuk5/FFREKRvu5Ij1WWlNDaEnw3+h+tqHAVCABRg4YA0Eq4x7bFn/3V6zGyD6wip3Gb250JvZE8\nJJ19iT8EwBQZ36djiIgEGxUJ0iP1R2uwrrmf4lfu42j5kUDHcakoPoz5rXvd2nJOnwyAgXPhpf1R\n4ziYexkA8Ufdp0purK/n208/9HrsIuvI3oWxOwsoU4RmVhSRU4OKBOmR7/d+C8AgajC/fZ/XbVpb\nW9iy8gXqamr6JVNrawt1f3vyhP11Iy4AYPTltzHu/J8AkEINdofdtc2eNa+QsetPXvcf/78f7FUe\nc5tzfgZLZEyv9hMRCVYqEgRw3hrYleaj7qfhq8u+59CubW5nFfZt/Ce5VZ9z4K/PsXfD524fxv7w\n3auLScFZkDTNetijf9z5PyHupldcty0WWUc5s5eWuraJq93nszxDfjyPQ2HZZE0622fHFBEJJBUJ\nQmNdHQ0vXs/299854TZtVSVuz8NWzSfx0/+k8u3HXW3N330NwHDbLtI2v8Duj9/zT2DA1tBIhqPY\n9Tw5PQOAGuPEtxvGTJwFQNWhjsIglSqfZUrNHMbY6xcTl5jU/cYiIiFARYJQ9M2/AIjf/yF1VR1n\nDMqK9nPguTvZ8cFqr7MPAsQbta7HOY3bjjvwRvzF1lgPQL0RSfnkWwkLC6f2vP8g8YrFJ9wnJdu5\n5JKtvJg9X36GraHxhNseiMjzbWARkRCkWyAHOIfDQea3/w+AJFMdrLyHI7MeZnDWcKLXLSbaBIP2\nvQnAEQZRHz+C3NoNrv2rzINIwTk+4HgRbfV+y3zwiw/IAapHz2Xs5KkAZIzO73K/uMREyo1w4kq/\nJKV0Hft2ZJPVqX9fyrlgOMideRkjwz3vjBARGWh0JmGA2/Xhao+26nXPe9kS7KfN4fR5/07R8J+6\n2pqtCQDYGho8tjfhnzEJ3331OTml7wMQHh3Xq33rTHGucQxZbUVufXmz5nH6ZTcQl5ikWRJFRFCR\nMOA5SnYAUGt03LY31FFCceEuAErMQ13t7R/IY8+f42ozHxuc2FzvedYg3PCc8dAXIjf/2fU4MaPv\ny0B7HNfLugwiIgOZioQBrLW1heHNhZSYh1IZk+vW1/CPVwCwJY1wtUXFOc8amM1mSsZdi80IJ7rV\nOfCvudGzSIjA9xMvtba2kGjqeK24pJRe7d95DEW7w5YsijsVQyIi4qQiYQDbtfYvAETa64kccaZb\nX7TD+UE88t8udw3ii08d7OrPm/ZjSmPziTCccwO0NDovNxTnX+3axkprt7dW9lbjsTkYDmTNxrjs\nSSJjevftP8LU5va81ogm77rFjLnhtz7LKCJyqlCRMADVVtew9Z1XySn9OwAtZ/yc0WdNh58/5dom\nweT80I+JTyDvyruon/kA0XHu1/+NyHiisVF/tAbLl686t08ZgnH5f7Iv6WwsJsPrWIWTUfT+awCE\nxyYSP6h3ZxG8qR93mRZjEhE5Af11HIA2rVhGzpGPXc+jkwYBztH/ZWfc6GpvMJwrIFojI0kfMcrj\nOBGDh2MxGRh//j/OOyMAa3QM8cmDsA7OBqD8wHce+/VV9ZFychq2AhCTOqRPxyjOv4YDEaNdz01h\nuotBROREVCQMQMOqv3J7bo3umEZ45A+muR63nnt7l8dJyfGcSyDy2LGyJ51Nm2Gm5tsNHtt4s+3V\n37HrpYe63KZ9jYVyksgaM75Hxz3emHNmctq197ueW8KtfTqOiMhAoCJhgNn5j7UebclDM7xum5DW\n9WA+b/tFxjovSUTHxdFKmGvRo+4Mb95Npv0QW1a+gK3Jc5Ije5udtG+PjaGYeWuPjtmVBiPSmbOX\nAx9FRAaSfptMqaCggHXr1lFcXMzq1asZPXo01dXV3HfffRw8eBCr1Up2djZLliwhOTkZgLy8PEaP\nHu26ZvzEE0+Ql+f89vrRRx/xxBNPYLfbGTduHL/73e+Iiorqr7cTkhwOB1m7Xwdgf8wESEjHZLJw\nmtnidfuYxMQuj2c2m2kxLFhNHfMhRHT6N7Bjhl6u35Bb9TmF6yKY8NNfurVXFB8kGvjelMqoEaO9\n79wLTVNvoLx4H+OG53a/sYjIANVvZxJmzpzJ8uXLycjo+PZpMpm44YYbWLduHatXryYrK4snn3Rf\n1e/1119n1apVrFq1ylUgNDQ08NBDD7Fs2TL+/ve/ExMTw0svvdRfbyVkdV6MKWnSvzFh9i847ZKf\nn3B7ywmKh85qp97ierw/apxbnxkHlpbez7oYc2QLALamRkq+K2T35x8Tvc453XLkj37Z1a49lnPG\nFE675OcatCgi0oV++ws5ZcoU0tPT3doSExOZOnWq6/kZZ5xBSUnJ8bt6+OSTTxg/fjzDhw8HYN68\nebz3nv8WEzoV7PzHWsJWzQeg6cd3k5V/mk+Om3PGmZSMuxb7z55gwjW/ceuLNrWQ3bKn18ccTCW2\nhkaK//QQcR/+Ftv3HYMfU4blnHRmERHpmaBZu8HhcLBixQpmzJjh1n7NNddgt9s599xzueOOO7Ba\nrZSWljJ0aMf18qFDh1Laaflf8RRe6Bz0V2vEkD9xErX1bSfctmj4XByNtUzo4bHzpv34pLIVbd9C\n8nFth7ZvYgjOxaZyKz9ztWu6ZBGR/hM0RcIjjzxCdHQ0V1/dMRnP+vXrSU9Pp76+nt/85jcsXbqU\nu+66y2evOWjQyX3gpKb2bt2AQPm+6CBDjHJKLBn8aP4zAKR2MXzjx//LN6f0Cy0ZRLcdJbebn9O3\nh7/1aGs5sMmj7WDSmZwXIj/zEwmV35njhWpuUPZAUfbA8HX2oCgSCgoKKCoqYtmyZW7XiNsvT8TG\nxnLFFVfw8ssvu9q//PJL13YlJSUelzJ6orKyHofD6FPm1NQ4ysvr+rRvf2puaqLlNWdhZc/9EeXl\ndf2WvTkshnB7Y7ev1Vxd5tEWVud+ZuhQWDbn/fv8kPiZn0io/M4cL1Rzg7IHirIHRlfZzWZTn74Y\nB3zU1h/+8Ae2b9/O0qVLsVo77lk/evQoNptzyt+2tjbWrVtHfr5zKeBzzjmHbdu2ceDAAcA5uHHW\nrFn9nj0UVBw+6Ho8ZMzp/fzqZkxG99Mym9qaPdoMk/uvpj1Miy+JiPS3fjuT8Oijj/L+++9TUVHB\nddddR2JiIk899RTPPfccw4cPZ968eQBkZmaydOlS9u3bx8KFCzGZTLS1tTFx4kTuvPNOwHlmYcmS\nJdx88804HA7y8/N54IEH+uutBLXdn3+Mffc/GH7FPUTHxXH00xXEA0cm38KI9H5exMhsxkzXRcKR\nQwfIadrh0R523PwKhjkoTnqJiAwo/faX98EHH+TBBx/0aN+9e7fX7SdOnMjq1atPeLzzzz+f888/\n32f5+kPRts3YW1vInfQDv72Gffc/yGo7wHdv/19GXHobWW0HAMgc299nEcDAjAnn5ZzWlhZ2/flp\nBk+7FHtbC6nDcrBGRlL73lI6D484asSQYGogwmgCk3Nq6BhTM6YeTsokIiK+o69n/WTHR39j2F7n\njIG2vPG9Xr2wpwyTc26D4bZd2OrrCAeKhv2E8YGYaMpkxnysSDi07RtymnZQ+mEF6UYZe8JzGHfd\nIkydzjQcCssh7qzLcHzypGs56BiT81JEsu1w/+cXERngAj4mYaBoLxAACt/+ox9fyfmhXGvE0Nrs\nHNNhjgjQ9XyzGTN2tq99E1ttFQAWw3nr5bDW/YBzToR2Y69fRFb+eKpMHTM9FmXPASAGz6maRUTE\nv3QmoR84HO7X5XMat2FraiQyyvcf3mF2Z2EQb2qAY7MUWqyRPn+dnjBMZmJNNmIPrqbFCAOTe1HQ\n2WHLMPKPPW4KS4C2GuyGifEXXsrW1/YRnXcWnutQioiIP6lI6AfbVy/n+HkCWxr9UyRYHZ7fuC0R\nET5/nZ4wRSfBsbtxrCbvkze1jznI+Nmdrra2yCSoL8Jx7ETXhKvv9XtWERHxpCLBz1qam8kp+9BL\nu82nr7N/yybqtq8nhxqKzUPJcHRMb20O0J0B5siu78ltsdmIMTWzb9A5nJ48qKMjOhnqoZXu144Q\nERH/0ZgEP9u/8XPX46ppHbNFtjV7zg3QVzXlR0j58hlyGrYC0DzIfZXEthbfFiQ9ZQ4L77K/vto5\nTsEcFe/WboqMAaCNrvcXERH/UpHgR9veW8nQHf8DgG3WYrLHnc7BnEsBKNu03mOsQl81v/WQ63Fx\n/jWMOv8ymgznxFT7Y88gZ/IPffI6vWUKt3bZH776fgAske6XXcwWZ3HQYup6fxER8S9dbvCT8kNF\nDD+0xvU8NSsbgIikFNgPuZWfUvj5cMacM/OkXsfhcBBt6jgr0X686JufB+jxIk3+YOnmTEK7sCj3\nyxLmY8VFqzkwYylERMRJZxL85MgH/+N6XH7mba7HlvCOOw1aG2pO+nV2fvBX1+Mi68iTPp4vmbs5\nk9DOZHYfe9B+mcKhMQkiIgGlMwl+Et7mnAyo4YKF5A7PdbWHRXR8cJp88Dqm4i0A1Jx7L+PHjPfB\nEX3HclyR0GpYCDfZPbYzh7n/Gg4eNR52gjHyHL/mExGRrqlI8IPDu3eSbpTxvSmNUZ0KBICwTnMW\nnOwkR4Uv/AfDDOcKillBViCA55mE0lGX0lZZjMlWS07Tdld7zkT3aaqT0tKwX/8S+WE6kyAiEki6\n3OAHlV//HYCwMy/36Au3dlxnd5zEXQeF//oH6YbnEsvBJOy4IsEcFs7pV9yEJT3Pvd3s+WtoUYEg\nIhJwKhJ8rMVmI7f+GwCyJ0z26A+P7FhDIbtoVZ9fJ2brn/u8b38xW9xPVLWfWbA31QYijoiI9JKK\nBB9rqnN+AO5Lne71G3J4L2c/LNq2mQPP38n+zRvd2mOPrWXQbIRRc05wzkhosrifDXDd7WAEIIyI\niPSaigQfa2pwDlgMTxjstT88stPlBsOE3dExkM/bvAnJ/3qKQRwlZcOzrrbiwl2Yj416LIkZS1Z+\n8I1HALAcXyQcG4+R92+XciAiz9suIiISRFQk+FjF7s0AxKYN89of3uk6vdlk0FTnXNxg538vovSF\nO2isr3f1f/f1F67HDUbHgMfKXc6zCvszZjHm8n/3XXgfi05Icj3en34BmfmnARARFUXmRdcHKpaI\niPSQ7m7woW3vvsHww+9SZ0SRmT+uR/s0NzQSm5BIVlsRmODA158xdvpFAAz+eplruyZTx1gGU81h\nqo04JlxypW/fgI/FxMfTeNWzRERHMeG4uRBiEhPx3cTUIiLiDzqT4CMOh4Phh98FwEqr1/EI7com\n3sj+1POcT1YvZMuKZ1x99kbnmYTOlyEAwo0WALb85XmGN++mzpriw/T+Ex0bi8XseaeCNUArU4qI\nSM+pSPCR2soK1+Pi+K4nQx555jTCkocAziWUc+s2ufqM5gbqj9aw978fdLWVkUKCqYGS7wrJrf4n\nAA5LJKeCeuPUeB8iIqciXW7wkcqi72gfqjj0nJ92u/2Jlm82Who5sOETsh2lABzM+RltNd9DdQVx\nH/4Wu2HCYjJwWON8FT1gmmc/Smx0TKBjiIjICahI8JHG74sAMC7/T1KTB3W7fUtVqdd2U0sTRluL\n67k5PAJTWMep+XJzKkOMI4z+yS9PMnHgpQzNDHQEERHpgi43+MjwkrUAxPegQADA4bmGAUBO41Yi\nD29wPW+rr8ES1zH+wGK0UmQdRVRMrLfdRUREfEZFgg+0tbX2ficvg/naDTGOuB6bwsIZOW0mFThv\nJ4wz6nFYera6ooiIyMlQkeADe195GMD1Qd4TYy68wqOtdILn3AEZE6cRERWF9bybAIg0tWKoSBAR\nkX6gIsEHMhzFADRk93xpY2tkJNHXv0Tpade52mJTh7ge1xlRVJ19F0lpzrYhI0e7+kwnuFQhIiLi\nSyoSfKDxwkVUksDQ08/q1X6WMAvp+R23S4ZHdJpVMWM62eNP79i20+WJ8Oaak0grIiLSM7q7wQfS\nsnPgpqf7tG9cYhI7w4ZjGnk26Z2KBJP1xJMN2bMm9um1REREekNFQhAYe/3DADTU1tK+xJM53HOS\nodaf/JaGmirG5o3tv3AiIjJgqUgIItbISGzHHlvCPQcnJqcPJTl9aP+GEhGRAUtjEoKIJayjZguL\njA5gEhERkX4qEgoKCpgxYwZ5eXkUFha62vfv38+VV17JhRdeyJVXXsmBAwdOui+Umc1mvjelApB1\n2qQApxERkYGuX4qEmTNnsnz5cjIyMtzaFy1axFVXXcW6deu46qqrWLhw4Un3hbqhVz6E6cqntEqi\niIgEXL8UCVOmTCE9Pd2trbKykp07dzJ79mwAZs+ezc6dO6mqqupz36kgJj6e2ITEQMcQEREJ3MDF\n0tJS0tLSsFic9/9bLBYGDx5MaWkphmH0qS85OTlQb0dEROSUM6Dvbhg06OQWSUpNDd3lmkM1e6jm\nbheq+UM1Nyh74uyptgAACwlJREFUoCh7YPg6e8CKhPT0dMrKyrDb7VgsFux2O0eOHCE9PR3DMPrU\n11uVlfU4HEaf8qemxlFeXtenfQMtVLOHau52oZo/VHODsgeKsgdGV9nNZlOfvhgH7BbIQYMGkZ+f\nz5o1awBYs2YN+fn5JCcn97lPREREfMdkGEbfvkr3wqOPPsr7779PRUUFSUlJJCYm8re//Y3vvvuO\n+fPnU1tbS3x8PAUFBeTm5gL0ua83dCYhtIRq7nahmj9Uc4OyB4qyB4Y/ziT0S5EQrFQkhJZQzd0u\nVPOHam5Q9kBR9sA4pS43iIiISHBTkSAiIiJeqUgQERERr1QkiIiIiFcqEkRERMSrAT3jotlsCuj+\ngRSq2UM1d7tQzR+quUHZA0XZA+NE2fv6ngb0LZAiIiJyYrrcICIiIl6pSBARERGvVCSIiIiIVyoS\nRERExCsVCSIiIuKVigQRERHxSkWCiIiIeKUiQURERLxSkSAiIiJeDehpmQGqq6u57777OHjwIFar\nlezsbJYsWUJycjKbN29m4cKFNDc3k5GRwe9//3sGDRoEwD333MOXX35JeXk5mzZtIiYmxnXMrvYL\n9uxd9QVz9v3797Nw4ULKy8sJCwvjtNNOY9GiRURGRgZ9dofDwS9+8QuampoASE1NZfHixWRmZgZ9\n9s4WLFjAW2+95bffG39kz8vLY/To0ZjNzu9LTzzxBHl5eSGRvaamhiVLlrBjxw7CwsKYNWsWt99+\ne9Bn37RpE4sXL3Ydv7KyktTUVN5+++2gzw6wcuVKXn31VcxmMxaLhfvvv58pU6aERPY333yTV155\nBYfDQVZWFo8//jiJiYldBzEGuOrqauOLL75wPX/88ceNBQsWGHa73Tj//PONr776yjAMw1i6dKkx\nf/5813b//Oc/jYqKCmP06NFGfX29q727/YI5e3d9wZz90KFDxo4dOwzDcP4b3Hnnncazzz4bEtkN\nwzBqa2tdj1955RXjtttuC5nshmEYH374obFgwQK//t74I7u/f8/9mf3mm282Xn75ZdfzI0eOhEz2\nzm699VbjxRdfDInsVVVVxsSJE43y8nLDMAzjgw8+MGbNmhUS2ffu3Wv86Ec/MiorK137PfTQQ93m\nGPCXGxITE5k6darr+RlnnEFJSQnbt28nIiLCVSHOmzePtWvXurY766yzvJ4d6G6/YM7eXZ8v+Tp7\nZmYmY8eOBcBsNjNhwgRKSkpCIjtAXFyc63F9fb3rm20oZK+urubZZ59lwYIFfsnsz+z9xdfZDxw4\nQGFhIddee62rLTU1NSSyd1ZZWcnnn3/O3LlzQyK7YRgYhkFDQwMAdXV1DBkyJCSyFxYWkp+fT3Jy\nMgDTp09n9erV3eYY8JcbOnM4HKxYsYIZM2ZQWlrK0KFDXX3Jyck4HA5qamq6PD3T1/2CIXug+Dq7\nzWbjzTff5O677/ZXZBdfZr/xxhvZuXMnSUlJvPTSS/6MDfgu+5IlS/j1r3/tVuj4my9/7tdccw12\nu51zzz2XO+64A6vV6s/oPsm+d+9e0tLSeOCBB9i1axcpKSncd999jBo1Kuizd/bOO+8wbdo0UlJS\n/BXZxRfZk5OTWbJkCT/72c+Ij4/H4XDwpz/9KSSyjxkzhm3btnHo0CEyMzNZs2YNjY2N3e434M8k\ndPbII48QHR3N1VdfHegovabsTm1tbdx111388Ic/ZObMmT5I1zVfZn/hhRf49NNPueSSS/jjH//o\ng3Rd80X2d999l/DwcM477zzfBesBX/3c169fz1tvvcXy5cvZu3cvS5cu9VHCE/NFdofDwZYtW7j0\n0kt5++23ueKKK7j11lt9mNI7X/+deeutt7jssst8cqzu+CJ7fX09y5cvZ+XKlaxfv5758+dz++23\nY/h5MWVfZM/JyeHBBx/krrvu4uc//zkJCQkAhIV1fa5ARcIxBQUFFBUV8dRTT2E2m0lPT3c7XV1V\nVYXZbO62Qu7rfsGQPRB8md1ut3PvvfeSkJDAgw8+6M/YgH9+7mazmcsvv5xVq1b5I7KLr7Jv2LCB\nL774ghkzZjBjxgwAZs+ezd69e4M+Ozj/vwLExsZyxRVXsGnTJr/lBt/+nUlPT3edcr7gggsoLy+n\nqqoq6LO327x5M0ePHmX69On+iuziq+yfffYZcXFx5ObmAnDxxRdz8OBBqqurgz47wCWXXMLKlSv5\ny1/+wtlnn01aWhqxsbFd7qMiAfjDH/7A9u3bWbp0qetU4/jx47HZbGzcuBGA119/nYsuuqjbY/V1\nv2DI3t98md3hcDB//nwsFguPPfYYJpMpZLJXVVW5/XFfu3atX0bYt/Nl9ocffphPPvmEjz76iI8+\n+giANWvWMHLkyKDPfvToUWw2G+A8A7Vu3Try8/P9ktvX2cePH090dDR79uwB4KuvviIhIYGkpKSg\nz97uzTffZM6cOd1+kz1ZvsyemZnJzp07qaysBOCLL74gNjY2ZH7u5eXlADQ3N/PMM89w/fXXd7uP\nyfD3eZIgt2fPHmbPns3w4cNdt8tlZmaydOlSNm3axKJFi9xuM2m/dnb77bezdetWysrKGDx4MKNH\nj3ZdR+5qv2DP3lVfMGdfv349N998s9vtbJMmTWLRokVBn3337t0sWLCA1tZWADIyMnjggQfIysoK\n+uzHy8vL89stkL7O/s0337Bw4UJMJhNtbW1MnDiR+++/PySyA2zbto3FixfT0tJCVFQUDzzwABMm\nTAiJ7DabjWnTpvHGG28wYsQIn2f2Z/aXX36ZN954g/DwcKxWK/Pnz/fLLZD+yH7DDTdQUlJCa2sr\nF198MXfeeWe3g6QHfJEgIiIi3ulyg4iIiHilIkFERES8UpEgIiIiXqlIEBEREa9UJIiIiIhXKhJE\nRETEK63dICJ9NmPGDCoqKrBYLFgsFkaOHMncuXO58soru73/+vDhw8ycOdO11LGIBB/9zxSRk7Js\n2TLOPvts6urq2LBhA4899hhbt27ld7/7XaCjichJ0uUGEfGJuLg4Zs6cyVNPPcXbb79NYWEh69ev\n56c//SmTJk1i+vTp/Nd//Zdr+/bFas4880wmTpzIN998A8DKlSuZNWsWZ555Jr/61a8oLi4OyPsR\nERUJIuJjEyZMYMiQIWzcuJGoqCgKCgrYuHEjzz33HCtWrOCDDz4A4LXXXgOc6w588803TJw4kQ8+\n+IDnnnuOZ599ln/9619MnjyZe+65J5BvR2RAU5EgIj43ePBgjh49ytSpU8nLy8NsNjNmzBguueQS\nNmzYcML9Xn/9dW666SZGjBhBWFgYt9xyC7t27dLZBJEA0ZgEEfG5srIyEhIS2LJlC08++SR79uyh\ntbWVlpaWLlesKykp4be//S0FBQWuNsMwKCsrIyMjoz+ii0gnKhJExKfaV6CbPHkyt912G1dffTUv\nvvgiERERPPbYY1RXVwN4Xc47PT2dW265hTlz5vR3bBHxQpcbRMQn6uvr+fjjj7n77ruZM2cOeXl5\nNDQ0kJCQQEREBFu3bmXNmjWu7ZOTkzGbzRw6dMjVNm/ePJ5//nn27NkDQF1dHe+9916/vxcRcdJS\n0SLSZ53nSTCbzYwcOZI5c+Ywb948LBYLa9eupaCggJqaGn7wgx+QkZFBbW0tTz75JABPP/00K1as\noK2tjRdffJEzzjiDd955h5deeoni4mLi4uI4++yzdTulSICoSBARERGvdLlBREREvFKRICIiIl6p\nSBARERGvVCSIiIiIVyoSRERExCsVCSIiIuKVigQRERHxSkWCiIiIeKUiQURERLz6/+rguuF9LHbF\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrcEfHzZ-8G-",
        "colab_type": "text"
      },
      "source": [
        "Indeed it is completely overlapping our training data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hnpawr5nAJq",
        "colab_type": "text"
      },
      "source": [
        "## Cross Validation\n",
        "Since classical cross-validation techniques will choose random testing and validation sets, we will need to consider the time series effects on our data.\n",
        "\n",
        "Luckily, Scikit-Learn has the `TimeSeriesSplit` tool to help us do exactly that.  It is a varation on the *k-fold* cross-validation technique that uses subsequent folds as testing sets.\n",
        "\n",
        "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0101.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BrXQDw5nsko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
        "\n",
        "# create 10 sequential splits from the training data\n",
        "tscv = TimeSeriesSplit(n_splits = 5)\n",
        "\n",
        "# calculate MSE scores\n",
        "lin_scores = cross_val_score(lin_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = tscv)\n",
        "\n",
        "# take square root\n",
        "lin_reg_rmse_scores = np.sqrt(-lin_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZSnHcHf5vh8",
        "colab_type": "code",
        "outputId": "ed0b4375-388b-426d-d623-e5c2dcea0a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# function to display scores\n",
        "def display_scores(scores):\n",
        "  print('Scores: ', scores)\n",
        "  print('Mean: ', scores.mean())\n",
        "  print('Standard Deviation: ', scores.std())\n",
        "\n",
        "# show linear regression scores\n",
        "display_scores(lin_reg_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:  [22.30242125 27.64273297 26.25267352 22.22916496 29.17474237]\n",
            "Mean:  25.520347013420327\n",
            "Standard Deviation:  2.813622405613907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_5smLOg-4yM",
        "colab_type": "text"
      },
      "source": [
        "Let's see how our decision tree compares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtnpTVPf8TDa",
        "colab_type": "code",
        "outputId": "dfd4abf4-33fb-4024-dc3e-81f2fc4df46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# calculate MSE scores\n",
        "tree_scores = cross_val_score(tree_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = tscv)\n",
        "\n",
        "# take square root\n",
        "tree_reg_rmse_scores = np.sqrt(-tree_scores)\n",
        "\n",
        "# show decision tree scores\n",
        "display_scores(tree_reg_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:  [ 81.11633284 300.52622073 125.95239762 125.42437031 321.9258436 ]\n",
            "Mean:  190.98903301924398\n",
            "Standard Deviation:  99.74301282894476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGBbRZX2_DzJ",
        "colab_type": "text"
      },
      "source": [
        "Our decision tree is actually performing worse than our Linear Regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3iRoT62AxGI",
        "colab_type": "text"
      },
      "source": [
        "Lastly, let's try an Elastic Net model to introduce regularization and better generalization to our predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F92D4Yb9-Qzv",
        "colab_type": "code",
        "outputId": "44d7ee17-99a4-42a0-b702-11b0dd946c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# training elastic net model\n",
        "elastic_net = ElasticNet(alpha = .11, l1_ratio = .5)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "\n",
        "# evaluate scores\n",
        "elastic_scores = cross_val_score(elastic_net, X_train, y_train, scoring = 'neg_mean_squared_error', cv = tscv)\n",
        "elastic_rmse_scores = np.sqrt(-elastic_scores)\n",
        "\n",
        "training_preds = elastic_net.predict(X_train)\n",
        "\n",
        "# display scores\n",
        "display_scores(elastic_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores:  [25.95408083 28.27506099 30.05244534 25.73888743 33.46755609]\n",
            "Mean:  28.697606137358605\n",
            "Standard Deviation:  2.865222636196036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 730888.1000163552, tolerance: 55401.22002628373\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 260386.65991920166, tolerance: 6120.2883475959625\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 421177.1300754072, tolerance: 16770.80757398765\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 541107.2862050593, tolerance: 26975.362718629607\n",
            "  positive)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3ebXvAM_rny",
        "colab_type": "code",
        "outputId": "0fc13684-a2a8-4ba8-bcf9-d4858bb28b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "# plot\n",
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_train, label = 'True')\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = training_preds, label = 'Elastic Net')\n",
        "plt.title(ticker);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAGJCAYAAAAAOqC9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl8FPX5wPHPzOxukt3cJwkJCfd9\no4AgIuCBVbFYLCIqtaAWa60HaouigheI/KotrVZRq0XQ1gPBKqKAiIoil1wSQAhHArmvTfac+f2x\nsBASQgjJJhue9+vVV3fn+52ZZ5LIPvs9FcMwDIQQQgghTqE2dQBCCCGEaJ4kSRBCCCFEjSRJEEII\nIUSNJEkQQgghRI0kSRBCCCFEjSRJEEIIIUSNJEkQQtTZf/7zHxYuXNjUYQghAsTU1AEIIYLDq6++\nyptvvonFYiE3N5d77723SvnHH3/MG2+8we7duwkLCyM1NZXrrruOCRMmoCgKR44c4amnnuL777/H\n4/GQnJzMbbfdxtixYzl06BAjR47EarUCEBMTw/jx47n99tsBMAyDt956i3fffZdDhw4RGRlJnz59\nuOuuu+jcuXPAfxZCnC8kSRBCnNEHH3zAokWLWLhwIRaLhUmTJpGQkMDEiRMBeO2113j11VeZMWMG\nQ4cOxWazsXPnThYsWMC4ceOwWCxMmzaNLl26sGrVKiwWC5mZmeTl5VW5z/r16zGZTGzatIlJkybR\npUsXhg0bxlNPPcXq1auZNWsW/fv3x+v1smLFCr788ktJEoRoRIqsuCiEqM3q1auZM2cOCxYsIDk5\nGYCCggJuu+027rzzToYOHcrFF1/M7NmzueKKK057nb59+/L222/TtWvXamXHWxK2b9+OyeT77nL9\n9ddz1VVXMXLkSEaPHs0777xDr169GuchhRA1kpYEIUSthg8fzvDhw6sci4uLY8mSJQCsWbMGl8vF\nyJEja71O7969eeKJJ7j55pvp27cvKSkpNdYzDIONGzeyZ88eunXrxrfffkurVq0kQRCiCcjARSHE\nOSkqKiImJsbfAgAwfvx4BgwYQK9evVi/fj0AL7zwAgMGDODvf/87I0eOZMyYMfz4449VrjVo0CAu\nvPBCHnnkEe6//34GDx5McXExCQkJAX0mIYSPtCQIIc5JdHQ0RUVFeDwef6KwePFiAIYNG4au6wBE\nRUXxwAMP8MADD1BYWMicOXO46667WLNmjf9a69atq5JsHL/+qWMXhBCBIS0JQohz0rdvXywWC198\n8UWdz4mNjeW2224jNzeX4uLiWusOHjyYI0eOsHXr1nMNVQhxliRJEEKck8jISO666y6eeOIJPv30\nU8rLy9F1nZ07d1JZWemv99xzz5GZmYnH46G8vJxFixaRnp5OTExMrdfPyMhgwoQJ3H///Xz33Xe4\nXC6cTicff/wx//znPxv78YQ4r0l3gxDinE2ZMoWkpCReffVVHnroIcLCwkhLS+OBBx6gb9++ADgc\nDn7/+9+Tl5dHSEgIvXv35h//+Eedrv/II4/w5ptvMnPmTP86Cf379+euu+5qzMcS4rwnUyCFEEII\nUSPpbhBCCCFEjSRJEEIIIUSNJEkQQgghRI0kSRBCCCFEjSRJEEIIIUSNAjYFcurUqRw6dAhVVbFa\nrTz66KN07dqVffv28fDDD1NcXEx0dDSzZ88mIyMDoN5lQgghhDh3AZsCWVZWRkREBACff/458+fP\n54MPPuCWW27h+uuvZ8yYMSxZsoT33nuPN998E6DeZXVVVGRH1+v3+HFx4RQUlNfr3KYWrLEHa9zH\nBWv8wRo3SOxNRWJvGrXFrqoKMTG2s75mwFoSjicIAOXl5SiKQkFBATt27OD1118H4Oqrr2bWrFkU\nFhZiGEa9ymJjY+sck64b9U4Sjp8frII19mCN+7hgjT9Y4waJvalI7E2joWMP6IqL06dP5+uvv8Yw\nDF599VVycnJISkpC0zQANE0jMTGRnJwcDMOoV9nZJAlCCCGEOL2AJglPPfUUAB9++CFz5szhnnvu\nCeTtq4mLCz+n8xMSIs5cqZkK1tiDNe7jgjX+YI0bJPamIrE3jYaOvUn2brjuuuuYMWMGrVq14ujR\no3i9XjRNw+v1kpubS3JyMoZh1KvsbBQUlNe7aSYhIYK8vLJ6ndvUgjX2YI37uGCNP1jjBom9qUjs\nTaO22FVVqdcX44AkCXa7ndLSUv+H+MqVK4mKiiIuLo6uXbuybNkyxowZw7Jly+jatau/y6C+ZfXl\n9XooKsrD43GdsW5uroqu6+d0v6bS3GM3mSzExCSgabL/mBBCNKWAzG7Iz89n6tSpVFZWoqoqUVFR\nPPTQQ3Tv3p29e/fy8MMPU1paSmRkJLNnz6Zdu3YA9S6rq1NbEvLzcwgNtWKzRaIoSq3nmkwqHk/z\n/aCtTXOO3TAM7PZSHI4K4uOrtgwFc4YPwRt/sMYNEntTkdibRmO0JJzXu0CemiQcOZJFUlKbMyYI\n0Lw/aM+kucfu6046QKtW6VWOB/N/vBC88Qdr3CCxNxWJvWk0RpIgKy6eoi4Jgmhc8jsQQojmQTp9\nm6kpU27F7Xbj8bg5ePAAbdu2B6BTp878+c+PNXF0QgghzgeSJDRTr7zyLwBycrKZPPlm3njj7Rrr\nHZ/hIYQQQjQ06W4IMuvXf8dvfjOBWbNmcOutN/L99+v43e9+y7p13/jrnPw+Ly+X6dOnMWXKLdxy\ny69ZuPBfTRW6EEKIICMtCbX4emsOa3/MqbFMUeBchnwO7ZXMkJ5nt67DcXv37mHatD/TrVsPAN58\n87XT1p0581Fuv30qPXv2xu12c/fdd9CjRw969+5fr3sLIYQ4f0iSEITS0zP8CUJt7PZyfvxxM88/\nP9t/rKLCzr59+yRJEEKIZuqjtfuIDLcwvE/rpg5FkoTaDOl5+m/7TTmNMCzMWuW9pmkYxolYXC7f\nYlC6bqCqKq+++iYm04lfdXOfAimEEOezD9fuA+CS3ilNPttLxiS0AKmpaezcuQPwdUX8/PMewLfz\nZvfuPVm06C1/3SNHcigoKGiSOIUQQtTM7fHicHn8722Kg9zCpt+yWpKEFmDixEmsXfslt946nnfe\nWUiHDh39ZY8//jS7d2dyyy2/5uabb+CJJ6Zjt9ubMFohhBCnmrHge6bOW4NuGJjx8OeoJWxYsqip\nw5LuhuYuOTmFjz/+wv/+ggsGcsEFA6vUSU1N47XXFtZ4fnx8PDNnPlPlmHQ3CCFE83K0qBIFg+/X\nrqeNqYBw1UmJem77ETUESRKEEEKIZuDS0O1037kRU1grAK66/IImjki6G4QQQogmdXwLpW7mwwB0\nNh8BIDKxftPkG5IkCUIIIUQTsjs8dDJl09F8tMpxxWRpoohOkCRBCCGEaEKFpQ7amvIAmFZ4Iy41\nDLSmTxBAkgQhhBCimqIyJ3//YCsVDs+ZKzfAvaLVCkr1UFyYOTB0BuGT5jf6fetCkgQhhBDiFMu/\nP8APu/JYsyW70e+VX+IgWq1AtcXSPSOGnh2TUDRzo9+3LiRJEEIIIU4RZfM19xeXOxvtHrlFFaza\neIiFKzKJVu1YYxO4f3xfTFrz+WhuPpGIan71q2uYMOF6Jk2a4P9fTo4vqx06dAAVFRX1um5m5i6+\n+GJFlWOTJk3A6XTU+Ro5OdkMHTqAuXOfqXLsF78YecZzy8rKZDdKIUSzFh7m+ybfmEnCR1/v563P\nMrEpDuK1MkyRCY12r/qSdRKauSefnE27dh0a9JqZmbtYu3YNI0de5j/2xhtvn/V1wsKsfPXVam68\n8WZat06t83nl5WW8/fab3HTTrWd9TyGECAT92LREp8vb8NfWDZZ+s58Nu/JIUEt5JPpDAEK7D2/w\ne50rSRJagL/97S9s3rwRt9tNdHQ0f/rTDFq1SqaoqJDHH3+EoiLfXg0DBlzIrbf+lldeeQm7vZxJ\nkybQp09f/vjHaQwdOoDPPluD1Wpl//59vPDCXAoLCzAMgxtvvJnRo6+udl+Lxcz48Tfzz3/+nSee\neLpa+fbt23jppb/6l4GePPlOLrpoKPPmzaa83Hf/0NBQXnrp9FtdCyFEU9h1sNj3Dd+TA/Ru0Gtv\n21fIkrX7AINHYj/0H9di6/5lK1AkSaiFO/Nr3LvW1FimKIp/AYz6MHcehrnTkDPWe+SRh7BYQgDf\nbo8LFrxVrc7EiZP4/e//CMDSpR/yj3+8yBNPPMNnn31C69ateeGFvwNQWlpKZGQkU6bcydq1a3jy\nyTnVruXxeHj44fu5/fapjBgxCoCSkuLTxjd27DgmTLie3bt3ER4e4T9eVlbG3LlP89xzLxIfH09+\nfj5TptzCm2++w333PcTkyTfXq/VCCCECYd32o/whYjXty3IxnBejhNga7Nqa5tvZsb3Jty7CNlcq\nra/7AxG1ndREJElo5urS3bBu3de8//5/qKyswOs90TTWvXtP3nnnbebPf4E+ffoxcODgM97vwIEs\nvF6vP0EAiIqKPm39kJAQJk2azMsvz+f++x/2H9+2bQs5Odk88MAf/McUReHw4YO1Xk8IIZqDuMgQ\n2ptyAdCLc9CSGq7bV1UUQnAzzvoddt3CG+XDmBXeHFMESRJqZe405LTf9pvLJklHjuTw17/O45VX\n3iQlpTVbt27hiSceAaBHj168/vpC1q//juXL/8e///0G//jHggaP4aqrrmHRorfYsmWT/5hhQPv2\nHZk//5Vq9Y8PvhRCiObIMAzCHHkQ7nuvlxxp0CTB49WZE+vb4XG1oytuTISatQa7fkOS2Q1Bzm63\nYzKZiYuLQ9d1PvzwPX9ZdvZhbLZwRo26grvvvpddu35C13VsNhvl5TXvU96mTTqaprFy5ef+Y7V1\nN4CvG2TKlN+xYMHL/mM9evTi0KEDbNz4g//Yzp3bMQwDm82Gw+HA42n8RUqEEOJslVe6SaTA/14v\nL6il9tnxeHXmv3vi38VvHB0BCAtpnkmCtCQ0cyePSQB4+OFH6NKlm/99+/YduPTSUUyceANRUdEM\nHjzE/41+06YNvPPOQlRVwzB0pk37E6qqcsEFF7Jw4VvceuuN9O3bjz/+cZr/eiaTiWeffZ7/+785\nvPHGKyiKyo03TuTKK39Ra5yXXjqKhQvfpKLCN0gxMjKSZ5+dx/z5L/DCC8/j8bhJSWnN7Nn/R2Rk\nFJdfPppbbx1PRESkDFwUQjQrRWVOIpSTpoR73A127bziSq63rQfgv/YLuWvS5cRGhmI2Nc8kQTHO\nZfRdkCsoKEfXTzz+kSNZtGqVXqdzm0t3Q30EQ+w1/S4SEiLIyytroojOXbDGH6xxg8TeVII99n++\ntwVj0/uMCNuBx1AJ7zmC0IsmNMj1/7t6L8N3PUOI4uFPRb/mxQevRFWUBrl2bT93VVWIiws/62tK\nd4MQQghxkmXf7idcceBUwnAbGoa34VoS/rcuC6+hsjOkN9df1rPBEoTGIkmCEEIIcZJuGbFEqA70\nkAhfkuBx+cv2Hyml5CxWYTxaVMHBXN8YsIO55ZjxYFVd9O7Znkv7Nb91EU4lSYIQQghxTFGpg+37\nColQK3GbbLjRMDxuDMPgUF45M9/4gXv/9nWdr/enl9ex9u0FVH7/X0rsTiLVSgBUa3BMBZck4RTn\n8RCNZkN+B0KIplJe6caMh2StmMrQBDzHWhKWf3+QGQu+99c7eTzb6Rw4WoaCztXWTXg2L6PS4fEn\nCYotOJKEgMxuKCoq4sEHH+TAgQNYLBbS09OZOXMm+/fv54knnvDXKygoICEhgQ8++ACAzp0706lT\nJ1TVl8vMmTOHzp07A7By5UrmzJmD1+ule/fuPPPMM4SFhZ1TnCaTBbu9FJstEqWZ9xO1VIZhYLeX\nYjJZmjoUIcR5yOHykKIVYVG8lEW0I+TIHgyvm58OFFWp53R7CQup/SP0w6/2cVHIbv/78L2fEaf6\nZk0otpiGD74RBCRJUBSFyZMnM3DgQABmz57N3Llzefrpp1myZIm/3tSpU+nfv3+VcxcvXozNVnU5\nTLvdzqOPPsrChQvJyMhg+vTpLFiwgN///vfnFGdMTAJFRXmUl9e+LgCAqqroevOeIXA6zT12k8lC\nTEzz2w1NCNHyOVxewlXfmANPSCSa4etucDg91eqdKUmIDrfwS9t3/vfxR7+jk7kVhNhQo1s3fPCN\nICBJQnR0tD9BAOjTpw+LFi2qUqegoICvv/6amTNnnvF6a9asoUePHmRkZAAwfvx4Hn744XNOEjTN\nRHx8cp3qBvsUn2CNXQghGpPT5cV2bI0E3WzDbWjgdeE4aTfIbuZDeH9cBkOur/VaoSEm9nha0cF0\nBIAicxKtzGVosWkoanD09gd8MSVd11m0aBEjRoyocvzDDz9kyJAhxMfHVzl+88034/V6GTZsGHff\nfTcWi4WcnBxSUlL8dVJSUsjJyQlI/EIIIVquNZsOYTvWkmCEnBi4eHKScEfEStgOeu9LUcNjT3st\nt1vHg4mDnlgchhmbWoFNcaKENc99GmoS8CRh1qxZWK1WJk6cWOX4+++/z3333Vfl2OrVq0lOTqa8\nvJxp06Yxf/587r333gaLpT4LS5wsISF4ftGnCtbYgzXu44I1/mCNGyT2phKssa/acIirw5ygakTF\nxZBvaGi4cHl9XbTWk1ZijFRKCUs4/QJ8dpeHOJMdrzWO3CIP8XohoYoTa0wc8Y3082non3tAk4TZ\ns2eTlZXFSy+95B+MCLB582ZKSkq45JJLqtRPTvY1/YeHhzNu3Dhef/11//HvvjvRz5Odne2vezZO\nXXHxbARzk32wxh6scR8XrPEHa9wgsTeVYI3dfWwl2t4JbhQjiooKFx40vC6X/7OirSnPX78or5By\nW83P6XHYObpvLwkhRRSmDqOsMJMYSgFwGCGN8vMJ6hUX582bx7Zt25g/fz4WS9WR6++99x7XXnst\nJtOJnKWkpASHw5exeTweli9fTteuXQG4+OKL2bp1K/v37wd8gxtHjx4dmAcRQgjRIlW6PIQpLhLK\nd2NqfyEmTcVtaLgcDkrtLlR0JoevOnGCp/qiSofzyrl39jLs/7qLsdpqANTEdmx1pfnrKKHB08oS\nkJaE3bt38/LLL5ORkcH48eMBSE1NZf78+TgcDv73v//x7rvvVjnn559/ZsaMGSiKgsfjoW/fvtxz\nzz2Ar2Vh5syZ3HHHHei6TteuXZk+fXogHkUIIUQL5XB5iVbtKOhoie3RdAU3GuhuwOD2iC9QT5od\nbzjt1a7x6ILvGR66H1WBNibf7pGWmFbs8ZzYSVIJPbeu7kAKSJLQsWNHdu3aVWNZaGgoGzZsqHa8\nb9++LF269LTXHDVqFKNGjWqwGIUQQpzfHE4PUWoFAEpYJCaHitswYcZLhOKgq9k3QP7p8ut50PYB\nlvLCGq/T2ZTtf11sTiQm2je48YvKbowM24Eal1bjec2RbBUthBBC4GtJiFF9rQNqRDwmt0KJHoam\nGCRrvsWU1jo6cdRlozjMiqkknxDwdUWoCuFhZgDSTfmsc7ZnnyeRsM4XcdOx9RQ+qhzAtyFDmR0T\nHGskgCzLLIQQQgC+1Rbj1HIMRUWxxqCpKnneSAAyTPkAbHG14coL21Cs2/Aea0n441/XMmOBbzC9\nhheb6qLAG8E6Z0fQLKgn9VE8NKFfgJ/q3EiSIIQQQgCVTi9tTPno4QkoqoqmKeTrvkGG6ceSBLsR\nSptW4VQYFnBV+M8tLndhGIZ/b4ZSw7dNwC8GV50iGRsZGohHaTDS3SCEEOK85tV1du7NpcvX01HN\nXvTUKwHQVIUKIwSAthZfkpDvjUBTVeyGGcVTdeCi26MTqfiShDLdlwxE2nyz+e75VS80Lfj2BJIk\nQQghxHnt42+ycG14n/Qw36qKobGJAJg0FYfh+5i04aDIa8WJGVUBh2EGt2+avorOr23rcBxJ87ck\ndOyYzvYdOtqxrobeHeJPvW1QkCRBCCHEeW1fTilXWQ5Q6LVxwBvHkLa+jQZNmoKBSqVuJkx1U6z7\nNhtUVQWnYUbxOPDqOmlaAYNC9sAnT5Gg+cYcXDWiF1eOjgr6HYVlTIIQQojzXoRSyQ53a14vH45q\njQJAO7YysMPwzVpwYWJk/1RURcFhmFEMHUeFg1it3H+d0WFbcIdEodlisJi1wD9IA5MkQQghxHlt\n9/5cbKqLjPbpPHvXUP9x07ExBJWGb1xB9w6tuOmyTqiq4k8cDhzOI1Et9Z9jUbzoce2CvgXhOEkS\nhBBCnLeOFlUQdWxPhQ6d29O9XZy/TNN8H5HOYz3zx3dvPDlJeGPJJhK1Ugq9Nv/4hfDYhIDF39gk\nSRBCCHHe2rGvkAGWnwFQI6t+uB8fdBiv+roTtJRuvnqKQr7uWz8hRSsiUSslV4+kRLcCoFijAxJ7\nIEiSIIQQ4ry0YVcu//7sJ0aFbQdACa86A+F4khCh+mYxaKnd/ccPemJxGRodzEdopRWT441mh7s1\nlboZU1qPAD5F45LZDUIIIc5L8z/YRg/zIf97JSyySvnxgYcLyoZzfQ+FiGO7N6qKgheNI95oupqz\nsShecjwxfOfqwIcVA3gtrk3gHqKRSUuCEEKI81KE1UxX84nNmE432PBHdxvcPX/pf398mWW7YSFB\nKwMgx3u8i6FlDFg8TpIEIYQQ56WyCjcdzUcoIRzrmEdqrRtuNftfH5sZif3YqooG0Lt/z8YKs0lJ\nd4MQQojzlEGMasfb/hK0pA611gwPPSlJUI63JPiWbFaAX47oSs9OKVhDW9bHast6GiGEEKKOoi1e\nLIqXkITEM9YNCzmxMNLx7oZwxVGlTofUqIYNsBmQ7gYhhBDnpXTlCABqTOsz1j15vMLxloQfXO0A\ncCohjRBd8yBJghBCiPNO5k97uc22EgPQWnet1zV2uFN5oHACPw2Y3rDBNSPS3SCEEOK8UVLuZOeB\nIjwr/0WyxTeeQFHP7qPQqxv+125MDOmT1sBRNh+SJAghhDgvGIbB/X/7inHWdVwUeqDe1/F49Srv\nW8o+DTWR7gYhhBDnhdWbs+lqzuai0D3+Y2FXP3zW12kVayUs5Pz4ji1JghBCiBZvw6483lq+i/6W\nn/EYKk8Vj2Fl23swpXSp9by+HeP9yzMfFxZiYv69w+jbMZ7RA1vO6oo1OT9SISGEEOe1f3ywhf6W\n/fQP2c+Xji7k6lFcM7LPGc+7+/pe9SprKSRJEEII0aLpHhf/F/tvwDddcXml78NdVVvuWIKGIkmC\nEEKIFm3t0o/pe+z196m38NCY3mQdLWvSmIKFJAlCCCFarOff2cyA3C2UmkP5MGEqt1zShQirhdTE\n8KYOLSjIwEUhhBAt1s59+XQxH6YkqjN3Xd+LCKulqUMKKtKSIIQQosVqZ8rFqrqJvGBoU4cSlKQl\nQQghRItUYnfRw3wIXdEITW+ZWzk3NkkShBBCtEh7D5eQZsrHE90GxRza1OEEpYB0NxQVFfHggw9y\n4MABLBYL6enpzJw5k9jYWDp37kynTp1QVV++MmfOHDp37gzAypUrmTNnDl6vl+7du/PMM88QFhZ2\nxjIhhBBi76FiLtZKCEvo3NShBK2AtCQoisLkyZNZvnw5S5cuJS0tjblz5/rLFy9ezJIlS1iyZIk/\nQbDb7Tz66KO89NJLrFixApvNxoIFC85YJoQQQjgP7+LKPU9hU52Ykzs1dThBKyBJQnR0NAMHDvS/\n79OnD9nZ2bWes2bNGnr06EFGRgYA48eP55NPPjljmRBCCPHtkv/6X5vaXdCEkQS3gI9J0HWdRYsW\nMWLECP+xm2++mTFjxvD888/jcrkAyMnJISUlxV8nJSWFnJycM5YJIYQ4v320dh9RRgnlegiLo++Q\n8QjnIOBTIGfNmoXVamXixIkArF69muTkZMrLy5k2bRrz58/n3nvvDUgscXHntphGQkJEA0USeMEa\ne7DGfVywxh+scYPE3lSaMvYP1+7jqegSfnSl0blr27OORX7uJwQ0SZg9ezZZWVm89NJL/oGKycnJ\nAISHhzNu3Dhef/11//HvvvvOf252dra/bm1lZ6OgoBxdN+r1LAkJEeTlBeeynsEae7DGfVywxh+s\ncYPE3lQCGbteXog35ydMHQajKL69GNpFeQhXnQy6qC8RPZLOKpaW+nNXVaVeX4wD1t0wb948tm3b\nxvz587FYfCtelZSU4HA4APB4PCxfvpyuXbsCcPHFF7N161b2798P+AY3jh49+oxlQgghzg8Hv/kE\n+9v34Vj1Txz7NgNQXO7kLnUxALaE1qiKbOJ0LgLSkrB7925efvllMjIyGD9+PACpqalMnjyZGTNm\noCgKHo+Hvn37cs899wC+loWZM2dyxx13oOs6Xbt2Zfr06WcsE0II0fL969OfGPzzcqKPfYq5Vr3E\nUe1xZi7ayQuxOgBKVGITRtgyBCRJ6NixI7t27aqxbOnSpac9b9SoUYwaNeqsy4QQQrRsP/6Yydjo\nYra7WrPC0ZM/Rn5K0U8/EIIZl6GhWKxo0SlnvpColay4KIQQIqjkl1RyaegOAFr1GsQBTxxeQ8F8\neBODQ/dgUbwc7fLrJo6yZZAkQQghRLO3fX8hm3fnA/Dl5mxiVDtOaxJRfS/Hi8Z6VzvSPT/zS+sP\nlOhhtB8wuIkjbhlkF0ghhBDN3vOLNxOrltF1lIKpJJIEUwXWuNZ4Nd/AxG8cnRgUsheAmGETsJi1\npgy3xZAkQQghRLO1L6cU8n/mhdg3AXD9ACMAXVXQ4i+CY9Pps7wJvFZ2CbdFfElYhuz42FCku0EI\nIUSzNetfP5D95XvVjqsYmLuPxGI+8TG2xZ3OtsHPoFqjAxliiyZJghBCiGbJMAxi1XJ6WQ76jzkM\nMwDlWFGt0Zg0lWk39vWXD+559gvridOT7gYhhBDNktuj08ey3/faZGNHRRwLy4dgU52kpyVw97F6\nHVpHHvv/qKYJtAWTJEEIIUSztHjlHjqbjlAZmkDiLc/x2rMrAXDqZmaM6e+vZzZpzJ16EVHhlqYK\ntcWS7gYhhBDN0upNh0kzFeKMzgDg5Qcu8ZdFhJmr1I2NDEVT5SOtoUlLghBCiGbDq+vs++oTYjM/\nZGhIXyJUB1pSEuBrMXj8NxewM6vIv5mTaFySJAghhAiYr7ZkExcVSreM2BrLv/7ye/ru/g8A42zf\nA6BUFvnL2yRF0CYpeLdyDjZkmxjlAAAgAElEQVTSNiOEECJgXv/kJ+Yu3lxj2RcbDpH/41oA7PqJ\n8QWKKSQgsYnqJEkQQggRMLFqGS/EvknJy5P4YeUXVcoWrsjEpjgo1UN5suQ6/lE2EqXPGEIG3tBE\n0QpJEoQQQgTMxSG+HYFVBTrveQtv4cGTSg06mI8S1bodFUYoP7lbY7vgOhRzaNMEKyRJEEIIERhO\nl5dErZRCr81/rHTpczgPbsOdtZlkUymJWhnmtiemN8oAxaYlSYIQQoiAmDpvNWmmArK9Mf5jJmcp\nrk/m4lj+Fy4w7wbA3KZXU4UoTiGzG4QQQjQ6u8NNO1MuUWolqz2JfOfsQLxWyhjrRn+dkWE7AFDC\nY053GRFg0pIghBCi0a3bfpRO5hwMFG6aOoWLrhrNSkd3Dnp8UyG/d7YDQFdUFNXEgM4JTLmmW1OG\nLJCWBCGEEAGwcEUmN9nKUWwxKJYwjhYdBRTmll6NqigkKEX0thxAbzsEgKm/lO2emwNpSRBCCNHo\nWsfbiNXsaBHxAAzunuQvu/qidI7q0TxYNIHEy37TVCGKGkhLghBCiEanGF5am8tQwtsCEB8Vxkv3\nX0JRuZMV6w+e4WzRVKQlQQghRKMyDINURyZhRgXm9oP8xy1mjaQYKxmtfFs9T7+l/+kuIZqItCQI\nIYRoVIWlTqK8vv0XtNQe1cqH9GxFt4wYYiNl0aTmRloShBBCNKpDeeVEqRXolnAUrfp3U0VRJEFo\npiRJEEII0ahKK1zEa2Vgi2vqUMRZkiRBCCFEo6hwePhy82Fytqyjs/kIWlxqU4ckzpIkCUIIIRrF\nmi3ZvPXpTkZXfgRASKeLmjgicbYkSRBCCNEg9IoSXD99ibeyHACTovNY9HsAHFESMbXu2pThiXqQ\n2Q1CCCEahGv9f3Hv+or8inxcGRczcPPj/q+ilqseRlHke2mwkSRBCCHEOTucV44tew8akLluLSHf\nrSJe85W9zS+YlBjVpPGJ+glIklBUVMSDDz7IgQMHsFgspKenM3PmTEpKSpgxYwZ5eXmYTCZ69uzJ\nY489RmhoKIcOHeLyyy+nY8eO/uu88cYbxMT4dgd79913eeWVVzAMg2HDhvHII4+gqpKlCiFEU3h0\nwXc8F5OLpkBrk29NhCxPHJtd6Uz5w/Xy73OQCshvTVEUJk+ezPLly1m6dClpaWnMnTsXs9nMn/70\nJz799FM++ugjKisrWbBggf+8iIgIlixZ4v/f8QTh4MGD/O1vf+Odd97hs88+Iysri48++igQjyKE\nEOIU5ZVurIoTi+Lli8oTOze+ax/ESkcPSRCCWEBaEqKjoxk4cKD/fZ8+fVi0aBGpqSemw6iqSq9e\nvdi7d+8Zr7d8+XJGjRpFbKxvi9Fx48bx/vvvc9111zV88EIIIWr17fYjRKsVAGR5Eni6+Fpu+MUA\nboqIIL1VRBNHJ85FwNM7XddZtGgRI0aMqHLc4XDw3nvvVTlut9sZO3YsY8eO5dVXX8UwDABycnJI\nSUnx10tJSSEnJycwDyCEEKIKp8tLzLEkoVi3clSPJikpjs5tYgi1yNC3YBbw396sWbOwWq1MnDjR\nf8zj8XDvvfcyaNAgRo4cCUBiYiJffvklcXFxFBQU8Lvf/Y6oqCjGjRvXYLHExYWf0/kJCcGbIQdr\n7MEa93HBGn+wxg0SeyAomsrtESsBKNZtAHTvlIhJC85uhmD5udekoWMPaJIwe/ZssrKyeOmll/x9\nVF6vlwceeICoqCgeeeQRf12LxUJcnG8Jz7i4OK655ho2btzIuHHjSE5OJjs72183Ozub5OTks46n\noKAcXTfq9SwJCRHk5ZXV69ymFqyxB2vcxwVr/MEaN0jsgVJYXOl/rYVHQZmbokJ7E0ZUf8H0cz9V\nbbGrqlKvL8YBS/PmzZvHtm3bmD9/PhaLBfB1PTz88MNomsZTTz2Foij++gUFBbjdbgAqKytZuXIl\nXbp0AeCKK67g888/p7CwEF3X+c9//sPo0aMD9ShCCCFO4nB5KTAiMaX3Zdbkwbw9S/49bikC0pKw\ne/duXn75ZTIyMhg/fjwAqampjBs3jo8++ohOnToxduxYAPr168djjz3Ghg0bePHFF1FVFY/Hw/Dh\nw/1dFGlpaUydOpUbbrgBgCFDhnDttdcG4lGEEEKcwu1yEaXYUaKSCA0xEWG14LA7mzos0QACkiR0\n7NiRXbt21Vh2uuOXX345l19++WmvOX78eH/CIYQQomkcyMom0Z6JCS+mFFl2uaWRYadCCCHqZfe2\nHbT6Zg5XHHuvpXZv0nhEwwvOoadCCCGaXEnOoSrvFVW+d7Y0kiQIIYQAwJu3j4pP/4K38HCd6ttL\nivyvt/S4r7HCEk1I0j4hhBAUlTrQP3wWi+Gk4sBmtAl/wxpe+5S5otxcMMFGZwZxrVoHKFIRSNKS\nIIQQ5zHPwa0cytzF9288j8U4MSOhbOF9FBeffr2AHfsLCfGUUaFbyO0xkS7pMYEIVwSYJAlCCHGe\nch7aSeUnzxO1+hkuCt1NsW7loaLxHPVGYlVcHP7uM977ci+GYWDonirn/vOjbXQ0H6E8tBXjLu0Q\ntKsritrJb1UIIc5T7/33syrvXy4bicOw8HTJGPZ74gn9eTUff7ufzFf/RPmrk3HvWeevmx7pJUkr\nJbnv0ABHLQJJkgQhhDgP5RZVEKPasesW7iu8iUeKxvHktOvRVAVQWOfsQKJWRm/zAVKMIwBUbvkU\ngOJyJ/l5hQCYI6SboSWTgYtCCHEe+t+6LDqpFRTrNrxolBlhAPxz2nAO59l5+y3fDIfbIr70n6MU\n7Mebu5dSI5EwxeU7ZrEGPngRMNKSIIQQ5yGnWydGtdOmbRtS4m3cckVnABRFQVUVdOPEXjo/uxOY\nXXI1AD989S2lFa4TSUKIJAkt2Vm1JOTk5HD06FH69OnTWPEIIYQIAEelkwStHDUijicnD6xSpqkK\nez1J/vfvVVxItjeWPG8E3Qo+5+evc7EpvumR0pLQstWpJSE7O5vx48czevRofvOb3wDw6aefMn36\n9EYNTgghROOIrjxIiOLGlNazWpmqKnjRmFPyC35wtuXW8SMBeL/iAgDaVfxIR7NvnALSktCi1SlJ\nmDFjBsOHD2fjxo2YTL7GhyFDhvDNN980anBCCNHUcosqWPftZpzr38PwuGqsYxhGgKM6N15dx13u\nWy1RjWpVrfx4R8Nhbxzl/W+lfVosADvcqcw51u3Qw3zQV9cS1vgBiyZTpyRh69at3H777aiqiqL4\n/nwiIiIoKzv9QhtCCBHsDMPgr69+TPetf8G1aSnOr/+NYRj88FMubo8Xj1dn2t+/4W/vb23qUM/K\n4Tw7qrvC9ybEVq385JTn0r6+lRQ7tI7yneuNpVgPw6q6wRQi+zW0cHVKEuLi4sjKyqpybM+ePSQn\nJzdKUEII0ZgMw+DokXzyvllSYyvAnkMl5BVXsmVPARmmfP9xz/6N/Hb2Kv7+4TaWf3+QwlIHRaUV\nxB1chV6aG8hHOCuGYfD1x/+j4MtFGIaOy6NjrWXgYUJ0GCP7p9KrfRzWUF8ScO8NvRnZL5VOqVHs\ncKWe9lzRstQpBbztttu48847uf322/F4PCxbtoyXX36ZKVOmNHZ8QgjR4BYv387VB+YC4M3ohCml\nq7/MMAye/vcGLrDsJVErJV714jI0PqvsxdVsorv5EP0tP5OW9T2lbe6gnSmXa6ybsH+QScSt8+sc\nQ3G5k0irBVVVzlz5HB0psNPr8LsA/LcojVZt22FVXOia5bQtATdd1qnK+7AQEzdd3omNmXls+DiO\ni9iNlti+0WMXTatOScKvfvUroqOjeeedd0hOTuaDDz7gnnvuYdSoUY0dnxBCNCjDMDiwbTNE+t4X\nbvyc5z8q4r4b+pAYE8ZrH+9kVOhWrrFu8p9zwBPHKkc3rrZu4vaIlb6DZfDF+o0kaKW+9047+37K\npFXbdoSF1P5Pa3mlm/v+9jXX97Vx1WUDQFExAFVpnIRhzbc7uOrY66y9P/PJTy5utDkxzGffEmAL\nPfFs0pLQ8tW5M2nUqFGSFAghgt6O/UUkHvtgP+qNRM3JIq+4O8u/P0B5pZuDu3fz5+hNVc5ZWtEP\nD1q1a6WVbQH1xJ4G8Wue5t1PLqDzyDEM6pV62hgKSx20Nx1hWNZnuLf+mmUlnVj2TRb/nDb8nPZA\n+OGnXDb+7wPGpx8h4poHUSxhZOfbycrcBRG+OlPCV3Fv0USsiqteSYI11Eyx7hvHoMam1TtWERzq\n9Ne4bNky9u7dC8C+ffuYOHEiN998s/+YEEI0NxUONxUOd7XjCz7eQbJWTKVuZre7FVZvKSa8hFXm\n8sOuPEZbt+AyND6q6Meyir58Xtmdu+8ax6gBqTxfclWVa6U7M0kxFZHtifYfG2tbT+WGJbXGdjjP\nzhjrBgC8BQf5dt02OpuysVdWj/dsLPt2PzeGf4tSsA/7R08DsPiL3fQ0H8Rl+JIcVTFIVEsJU1wo\nodUHLZ6JLdTETncKL5Zegbm7fHFs6eqUJPzlL38hKso3snX27Nn07NmTCy+8kCeeeKJRgxNCiPoo\nKnMy48VP2Dz/T+gVxVXKnG4vfaw5GEldKNJt2FQXE8PXcmXeawwJ2UVfSxbbXal84ejBCkdP4obf\nhC3MQkJUGAe88eR6I/AaCl+qgwkxHHQ155DpSeYd+yD/PdpzoNb4Xlm2g2jVN7vg0K7tzIj+gKmR\nn5O1+Olzem7NdWLGmVF4kPJKN9v2FdJKK6bQnMwah29VxdamQiJUByG2yLO+h28go2+xJaWRukdE\n81Gn7obCwkLi4+NxOp1s2LCBF198EZPJxKBBg858shBCBNj6nUcZEbqdVo59uH/6kpB+YwDQDQPN\nZceml1Ea156ifb6ZC93Mvn0KbrB9B0CE6vBfy6T5PghTE30rDD5XcjVhZpVeaiYc+yK+153Ij+50\nvnF2ZJJtDe2Pj1M4DQWDcMWBwzDRSivxH2+rZ2G4KsmzG1jCLGf1zEeLKvCWFkAU7HEn0cF8lD+9\nuAKTFkaCxYnDmsCKvK4MC91FlFJJK60ENfrsZ6iFmH0tEkN6VF9fQbQ8dUoSYmNjycrKIjMzk549\ne2KxWKisrAy6BUSEEC3XDz/l8s5H33LpBW3ZcthNn2Oz/fWiHH8dp8tL/LEPcD0ikcNeHYAQxVPl\nWsagm5mZlsE/lmyjV/t4ANKTIoiyWbi0X1sO5pZzcG+Bv3629/hOiAoVRggW3cHp7MwqIka1oykG\nO1yt6Gk5VKU8c+s2Zq8owxZm5q/3XFynZ9+XU8pPWUXEab6WhI2uDDqYjzI4ZDeH1NZEGSW4bd3x\nHGs8/qXtB1+09ehuUBSFVx4c3miDLEXzUqfuhqlTpzJ27FimT5/Ob3/7WwC++eYbunTp0qjBCSFE\nXezcX8hPny5mRvQHDMmcx75Dhf51AAx7ob9eXnElqZrvvRbbmiPeE2MJPqv0LU9sdBhGv/49SE0M\n56kpgwgPMwO+ZvZ5vx/CtUPa4nR5yfIk+M8t0H2jAp+cPBAtzIbFcJ72S9RXW7LpaPIlLhtcbf3H\n3y6/CIAvvtwMcFbjE2b96wdC17/BpPCvcJoiWOfsQJ43gmusm/hd6DIAIi3gMaoOvqzvmALtpIX1\nRMtWp5aEsWPHMnr0aADCwnxLcPbp04d58+Y1XmRCCFFHn68/wCTrRgBUBTJMeVhVX5LgPZLJgo93\nUFjq5GBuObdYDuIKSyC5TRvgxODrXG8kDxWNZ/7w039wHv9gNAADhdkl1zA4XeXqLm2JjgghJd7G\nJjUU1auDxwnm0GrXiI4IIcqUj0sNY5Mrg0l8BcA2dyoVupl2plzSTfmEKW5gxBmf3e3Rud76HQNC\n9gFQljIQb67GRxX9+W3E6hP37TOCuztEwReLAHD1uxFFM5/x+uL8VucpkC6Xi1WrVnH06FGSkpIY\nPnw4cXFxjRmbEELUiaM4r8r7NqZ8YrUK//t9O3aQ7fXtP9A6uhAjaUC1b8IVRgjtM1rVaZnh5Fgr\n2/cVku2N4XBYErcPa+cvc6th4AXDaUepIUnweHViTRWExiZCvsKzJdeQlpaMvdBBtjeGC0P2YlZ8\n3SDeo3vQkjrUGkv+/kyGhe4CoFQPJbrPSOJ+/pkfS9uwtKIv11g3kRvTm/ZJHegY68EJVOpm1HaD\nz/icQtSpu2HTpk1cdtllLF68mF27drF48WIuv/xyNm3adOaThRCiETlcHu40FgLwYunl5HvDuSJs\nK4lqsX80f2+Lb7aBhpdw1Ylii/Gf/8+ySwEYOmIw9/+6T53u+avh7f0D907tm/dovsTAcFZUOw/A\n49GJVitQrL4YcrwxlBm+FtoO5lx/ggBQseTJWuNYsyWb8JXPAvC1oyOPFt9ASHQ8SbG+9Q8+d/Tk\noaLxbEu6xherqnJP4S08XHwjZktInZ5VnN/qlCQ8/fTTPPbYYyxevJh58+axePFiHn/8cZ58svY/\nYCGEaGw7167yvx59zSh2uVMIVXz9+f+r7EOJHkak4vvADld8AwpDIk4kCdvdaYRPeZ2BfTvW+Z4W\ns8ZlF/gWEjp1lL9bPZ4klNd4ruGqJFEpRos7sRDR3df7xkM4jaqtGEpEArXZsiefct33Yb+kor8/\ntinXdKdPB9+AS4dhoVfHRKBqQqOdw6JN4vxRp7+S/fv3+8ckHHfFFVdw4EDtc4GFEKIxldhdGDs/\np9Bro/zqZ9E0lTLjRBO/wzBTpocSoTow4yFSrQQgNNLX9XBJnxSAeg3Ca5MUwasPXUrXjNgqxz2a\nr1WgppYEj1fH/vMWVMVAS+7sPx5qMXHfDb35j32g/1imJwUlLKLWGDweN1bFySeVvXBiISYiBJOm\nEmWz8Idf9aJ7W19sbZMjjz3niXOPT+0UojZ1GpOQnp7Oxx9/zDXXXOM/9umnn5KWJktyCiGazqqN\nhxikFeFN609ySivWr91HhX6iGd1ApUwPI1ErZW7s2/7jaoxvfYBbrujMLVd0rnbduqppGqDH5EsS\ncNqrla3fmcvN1tUAx8YanNg5UtNUolXfOTmeaMq8FvTKmlsj/CpLURVolZrCy2MuwWyqOnvh3nG9\nMU7a+PnkZOhcln8W5486JQl//vOfufPOO3nrrbdISUnh8OHDZGVl8dJLLzV2fEIIcVr5R/OwqS5C\n0toAkBgTxiGjal97mRFKVy27yjE1ytdF0BjT+LzHWxJc1ZMEu73S//rUQY2aqvCjqw2XhW3j1fLh\nXBy6C6MiG8Mwaowzp8BOaV4uRMFFF3TBZKq+t4Rvh8man1ELwO6TIvjVKUno168fK1asYPXq1eTm\n5nLppZdyySWXEB0dfeaTgaKiIh588EEOHDiAxWIhPT2dmTNnEhsby+bNm5kxYwZOp5PWrVvz3HPP\n+WdN1LdMCNFynO5Dcs+hEoqyMiEC1PgMAPp0jGftp76VCg3F9025UA/3n/Ni6eVMnHAVtTfin2O8\nphB0Q6nW3eBye9m4di0DI+D1smH8Abj5is6EmH1xaqrCUT2aB4smYDGr5HojUbwuDHsRSnhstfus\n2nTYPyDz+CDIsyHrHIi6qHN7U1RUFGPGjGHKlCmMGTOmzgkC+P4YJ0+ezPLly1m6dClpaWnMnTsX\nXdeZNm0aM2bMYPny5QwYMIC5c317vNe3TAjRMhgeF2Ufz6P8ld/w4eIlfPzt/irlB/PKSdV8qx5q\nCb5FiUyaiv1Yd4Oh+ZKFrx2dWFbRl1nF17HX04rIiLBGjVszaTiwYJzS3bAzq4hWqm8J5l/f5Ou6\nvbRvay7qUX1p5I6p0eR6feMI9JIjNd4nTPEwMmw7QJXZGkI0pNO2JEyYMKFOmebChQvPWCc6OpqB\nA08MyOnTpw+LFi1i27ZthISEMGDAAADGjx/PyJEjeeaZZ+pdJoRoGbK/Xkbk4R8BGFn6Af9Zdxjj\nwin+BYDcbi/RagW62epvutdUhUrj2J4HJl+yUGpYWeHo6b9upK1xFxAyqQqVRgiRp7QklFW4iVAr\n8RgqiUnx1c5rlxJJj7axbNtXSP/OCaw4cHyWRPVuC8MwOPLzbv97JbQx20bE+ey0ScK4ceMa5Ya6\nrrNo0SJGjBhBTk4OKSkp/rLY2Fh0Xae4uLjeZWfTwiGEaJ4Mw2Dnj9sZGAKL7YMYb1vHONv3lL6x\nmcjbXkJRVFwenRi1Es124r95RVH8sxs87S5mWFJr1mw6XOXamtq4A/Y0TaXCsGC47OiGwZbd+fTu\nGI/d4SZCdVCmhxJTwxcwRVH4w696sX5nLgO7J7FmrW+tA9zV94HYsCsPtewIhIOa2P6sug6SYq0c\nLax5DQchTnXaJOGXv/xlo9xw1qxZWK1WJk6cyIoVKxrlHnUVFxd+5kq1SEgI3uw9WGMP1riPC9b4\nAxH3/uwSUhLCsZg13vzfDpLUcva6E/nW2YnxtnUAqF4XsWFeTBFRmCwmotRKQmJSqsRXaYTwYOF4\n5g+7imlxNn+S0Dk9hl1ZRY3+LBHhIZTrZjyV5ezOKeOv72/lt9d2x61DtFJJmRFWawzXtooCQD/W\nEmILVYg6pX7BhkOkmIpxGyqdfvsMilp90OLp/PWBS3E4PcREVl8NsiEF6986SOwnq3Xg4qpVq1i1\nahUzZ86sVjZjxgxGjhzJJZdcUuebzZ492z8rQlVVkpOTyc4+Meq4sLAQVVWJjo6ud9nZKCgoR9fr\nt5NlQkIEeXllZ67YDAVr7MEa93HBGn9jxv3uqj2YVIVWkSaS1z1HSVQcKROe4L2Ve5gRWYYtowds\nAY+hYjq2EmF+VhZakpl3P8/kiWg7XktUlfgUBZyGhdLSSpLibDx752CKSh10TIvGMIxG/x24XR6K\nvTbsuQc5ctS342Tm/kK++jGHaZGVpKan1S0G1ddtUlZUiuuU+odyShmg5ZPtjSG2oH6tAnl5dd9A\n6mwF6986tNzYVVWp1xfjWtvdXnvtNa699toay6699loWLFhQ5xvNmzePbdu2MX/+fCwW3x9/jx49\ncDgc/PCDb9vSxYsXc+WVV55TmRAieOzbsI7Lds2i5/rHiNfKiSjPQi/NpXdrM9FaBeFJqfxxXG9m\nlv+a/yv1/TfuLfXt06CiE6lUotiqjvw3H5v/f3wdgMToMDq3iUFVlEbvagDfuIjD3ljf8s+VxVwR\nuoVfHZqNTXH4FnWKqNuXGcNk8a1w4Kne3eBwe7GpTgq859YaKsSZ1NqSsHfvXv/gwFP179+fPXv2\n1Okmu3fv5uWXXyYjI4Px48cDkJqayvz585kzZw6PPfZYlamM4FtjvD5lQojg4PboTI38vNpxx9f/\nJro8FkUFU3ofesXF8ezdo/jDvC/wGCqVm1eS2HEwHeMUVKP6yP64qFByCipqXOgoEDRNJe/Y1tE/\nbtvDrdYtAHQy5xChOlDCoup0HbNZw+MxY3E7q5W5PTo2xUm3zrKgnWhctSYJDoeD8vJywsOrZ6t2\nux2Ho3qGW5OOHTuya9euGsv69evH0qVLG7RMCNG82R1uvtuQyQXH3j9ZfB15egTToz4kPu8AqsME\nVlAjfXsOmEwKbkysc3bgosJMtu0+grMkHyJBPaUl4f5f92HbvkKsoXXe5LZBmTSFSt3XWlpZVkau\nNYJErYwOpqOoGCjWOiYJmopbMfu2nD6F1+3GqroIja2+foIQDanWtrdu3bqxfPnyGstWrFhB165d\nGyUoIUTLtvTr/Vyw3df692Lp5eTpkYDCRldbFEcJUWoFumr2T2PUVJUubaLJ9sagKrBl+z6ijm3a\npIRXbUmIjQxlWO8Umoqmqv5pmAlqKYmar494UIiv5bWuLQkmk4obE0YNLQk2TyEqBmp09TUWhGhI\ntSYJd9xxB08//TSvv/46hw8fxuVycfjwYV5//XWefvppfve73wUqTiFEC2AYBqvX/cTle571H7v/\nd9fSq30cV17YhiLdhoJBG1M+emhUlal9l/ZLRcM3eDG+Yh8RxzZrUkIjA/sQZ2DSFByGby2G623r\nTxw/NvCyzi0JJhU31VsS8ksq0fOzAFBjUhsiZCFOq9Yk4eKLL+app57izTffZNSoUfTu3ZtRo0bx\n1ltv8eSTTzJ06NBAxSmEaAEyDxZT+f37mBUvAIWWZEJt4fxxXG/6d0mgyGsDoK0pH3Nk1aZ0Bdji\n8u3RoHoqCVNcvuMhtsA9QB2YtBMtCccd8Z5IDJTQug02NJtUXDW0JDz4j29JN+XjMMyoMa3PPWAh\nanHGTrsrr7ySK6+8kp9//tm/WFG7du0CEZsQooUpLHOSrBX736dNfML/OsSkkaufaBXQThmQ2C0j\nlhLDxmFPDPFlmVQqcaBZULSmGXtwOpqq4ObEugX/cl5OpKeQX9p8s7HqujqiSVMpcym4HZW89dku\nnC4vk6/uBkCcWk6+N5yEAMzWEOe3Ov+FtWvXjn79+kmCIISot8rSUtJMBXzp6ML3/Z9ENZ34xm02\nqxSdtBmTKa1nlXOtoSbCQjSyvTHEqHbCVCc0s1YEAE2ruvPi8Csu8a8CCaCE1K0lIbeoggo9hPLC\nPFZtPMQ3246g6wYKOukm3xoJQjQ2SUOFEAFzcPsmLIqXza50LulTdXDh8fUN3rEPolKxYmo/qNr5\n9/yqN3YjBKvixKq4UEOsAYn7bJiOfbt/vHgs0wpvpE3rBMr0k5KEOk7NdHt09niSiDTKSFB9gx8z\nDxbTRisgXHXSqueFDR+8EKeQJEEIERBHCitQyn0LId3z2yv8ix0dF2H1Dfb7xtmJIyNm1tiNEGmz\nUKFbCFPdhCuOZjceAU4s4lSkh+PCjDXURP6xbhRPTEadr5MSb2OvJwmAVJNvt8s5izYRq5UD0KV3\nrwaMWoiaSZIghAiIbT8XkKHl4QmLISKm+vx+s0kjNcHXFF/h8NR4DZOmYDd80yKTLPZmmST4uht8\nosItmDSVQj2c50uuIuTSO+p8nd9e28M/ADJUObGEcrjiG8hY1wGQQpyL0474OXToEKmpvuk1Bw8e\nPO0FzGYz8fHxmEzNa5A6d2wAACAASURBVPCQEKJ5efvz3TwelYeW2P20dQZ2S+TQl+WEh9W8nbNJ\nU/1Jgs2oaJZjEkzqiSTh8UkX+F8f8MZjiUmq83WSYq3+qZShipu7I5Zz0BOHAxOgNMsESbQ8p/1k\nv+aaa9i0aRMAl112GYqiYBg1b4YUGhrKtGnTuOmmmxonSiFE0DIMg4JSB11DjhKjVRCS0vG0dUcP\nTCejVSTd29a8kmCIWaP8pP59LbF9g8d7rrRj3Q0dWkcRFR5StUyt+1LRiqLgNHz/RCf+f3v3HRh1\nff9x/Pn9fm9lJ5dFBhsSEGQGHAgquFDEVQSp2tqlFi0/LfpDQWhRiiha9VdabaXan6VQF/ADlYBV\n3IiUDbJHIAkhe9/+/v64cCHNJFxyd/B+/JV8170uYvK+z1Qr6GMsoI+xgO+daWAOP6udH4Vor2aL\nhNMFAsDevXubfYCu6+zbt48f//jHUiQIcYFzutw4XB4iLPUtAdnfHqNk4yoeiPD+TtFSMpq9X1WV\nZgsEAItJo1CvH9WvJQXfbCu1rhBo6kNVWwctnqajYtcNdDMU+Y6laSUolrYtyCTEuTrnMQmKotCv\nX78mt5MWQlxY/rRyNw+/9IXvD2Rt3kFG7fgNN4d7CwRbTE/U+G7tfr6iKFTqYRxyevd0aOuaA53p\n9MZSnmZaXs+WWXGRbij1fR+t1sp4BNFpmm1JmDp1apuq3qVLlwJw3XXX+S+VECJklFc7sBg1TEaV\nbQe9n3jdHp0vd+QxcNOzmOt+jayoyWLMxHtJVM7ts4nbo7O0ehS/GKnSJyL41go43aXgdp97kRAd\nbqTaYyJCdTQ4roa3bbtpIc5Vs0XCpEmTfF/n5OTw3nvvcdttt5GamkpeXh4rV67kjjvu6JSQQojg\nVFppZ+GfPmRW7CrKY3sTrmQx1HSU4/vT+N/sEyyK8+5X8Gz5zeS747ixmQGJZ6vYE4Wt2+Czbr7v\nDL4iwVNfJPzy1oFU1jiau6VZQ/omsHDHRObFvdvguLHvqHMLKUQbNVsk3Hbbbb6v77zzTpYsWULf\nvvUDjm6++WaefPJJfvWrX3VsQiFE0Pr+WAkT6roSwsoOsSDukPfEF9+Spt2EUfHwbvUI8utWB4wO\nNzX3qLNm1IJzBvfpKZBnFglZ/ZLa9awJl/fg8+15ABQQz87aLlwTtrvFcR1C+FOb5i0eOnSIbt0a\n9iOmp6dz+PDhDgklhAgN+acqGG3Ip9wTRkzdroynPR7zAQDlWhw/Ht+Pkf2TMBnPfUT+iH5JfLf3\nFEHYiABAQoyFuCgzk8f2OednmQwaoPBM1SRi42I4WGInduRErpbpj6KTtKkUHzFiBDNnzuTo0aPY\nbDaOHDnCrFmzyMrK6uh8Qogg9v2WLYSpTnY6uvqOPVl6Jw69vhiY/ssfMGZwKhaTf9ZSueWKnowZ\nnEqPLsG1RfRpRoPGC9NGMbhPwjk/y2zy/hwHDeyLOSISHQUtPPgGa4rzV5uKhGef9e79PmHCBIYO\nHcrNN9+Mx+Phd7/7XYeGE0IEVnG5jQ++PExeYRUbtuU2mNZXVetkenQ2APuc3n0Y3qwaTbVuwVS3\nFbRpyAQUg/+6GMC7XPGPx/fz/QE9n5mNGi//6gruuqYvMXVdNe0Z2yBEe7WptI+NjeX3v/89Ho+H\nkpISrFYrqqri8Xg6Op8QIkA8us6sP33Gb2LfI0J1MBzYsGkAV//iMVxuDzNf+ZgFdZMLdji78l8l\ndzMsMxn2FfL3qlEMS1O5ZOQPAvoezgdRdcVBYmwYADX2ppesFqIjnNXIH1VVSUhI4MCBAyxcuJAx\nY8Z0VC4hRIDlFlYzwHSiwfS7LHaju5288eH3pGslABQP/wWg8KPxFzHttotJT4zgO0dvTnS5KjDB\nz1NGo/fXtcfjn/UXhGiLNncSlpSUsHr1alauXMnevXsZPnw4s2bN6shsQogAOnaykh6GIpy6yp8r\nx/HjyM+IUB04Nq8g51R3bg/bAUC3zEz+Ojzed1/PlGhOFFY3WHVRnDvfIk3SgCs6UYstCU6nk+zs\nbB544AHGjBnDP//5T6655hqio6N5+eWXGT9+fGflFEJ0ssN55QwyHeeQK5n9rhSeLJtMgTsaV9Ex\nbHY3UWotNZHpqJHxDe4rrfLuUpgQY2nqsaKdRvRLIjrCxFVDUwMdRVxAWmxJGDVqFIqicPvtt/Pw\nww8zYIB397Zly5Z1SjghROdy5X2PO38/5uG3kJ97EqtaRdcxN8P/ASgUuGNIri6juMJGbLydyG6N\n5+ufKvVOhewSH9654c9z1mgLLz18RaBjiAtMiy0JmZmZVFZWsn37dnbu3El5eXln5RJCBEDtmoU4\n/r2Cg1+tJ7r8AADR3TOZ95ORjBmcSoUnDL2mDBUPZt2OEtZ4GuIto3pi0FS6WKVIECLUtdiS8NZb\nb5Gbm8vKlSv561//yjPPPMMVV1xBTU0NLpeMsBXifLIvp5TTDdnJu5cy1uLdH8CU1IP0akhLjKB4\nXziKo5o4tRpoeoOlywZ24bKBXTorthCiA7U6uyEtLY1p06axbt063nzzTRITE1FVlYkTJ/Lcc891\nRkYhRAfLL67mpX98i12v/9yQaigDQDV7p94ZNJXcuuWVR5q9yy+rUee+YJAQInid1RJoWVlZZGVl\nMXv2bNavX8/KlSs7KpcQohNlb8rhCst+zIqLF8pvJEUrY2rk1wAomvfXhKYq5Li8RcENYTvAYEZL\n7R+wzEKIjteudVLNZjMTJkxgwoQJ/s4jhAiACIuRnsY8TrjiyHEnoCqN59lFR5io1C3YdQNmxYWW\n0N3vqykKIYJLcG6jJoToVKmFX5FpPMkBVxfuuS6Do65EAIrTRvuuyewaCyiUuL2bCylRiYGIKoTo\nRFIkCHEBO3CijO+W/YlBZZ8CMHrS3Vw9LJ0ws4HpJffS/caf+K4NM3sbHi2KEwBFPf/3ThDiQuef\nbdnaYOHChWRnZ5Obm8vq1avJyMjgxIkTTJs2zXdNZWUlVVVVbNq0CYCxY8diMpkwm80AzJgxg9Gj\nvZ9stm3bxpw5c7Db7aSlpfH8888THx/f+IWFEM16eek3LIj7FoAaj4nklDQAnv7pJZiMGsp/7Mc8\ncVQP8rfHEafVYMgc3eh5QojzS6cVCePGjePee+/lhz/8oe9Yeno6q1at8n0/f/583G53g/teeeUV\nMjIaLtji8Xh47LHHWLBgAVlZWfzxj39k0aJFLFiwoGPfhBDnEbfHwzDTEQC+sfUh7MofkVx3zhrd\n9GqJvVKjee3rK7A67DzdpW8nJRVCBEqndTdkZWWRkpLS7HmHw8Hq1au54447Wn3Wrl27MJvNZGVl\nATBlyhTWrl3rt6xCXAje+fQQyVo5NR4jy2suIy0xptV7ws1GanUzuY7GiygJIc4/ndaS0JpPPvmE\n5ORk39LPp82YMQNd1xk+fDiPPvoo0dHR5Ofnk5pav3651WrF4/FQVlZGbGxsm18zPj7ynDInJjZe\nSCZUhGr2UM19WjDlX/9dDrNi8shzWwGF+PiIZvOdPl7l9DQ6FuxCJWdTJHtgSPZ6QVMkvPfee41a\nEZYuXUpKSgoOh4P58+czb948Fi1a5LfXLC6uave2q4mJURQWVvotS2cK1eyhmvu0YMqv6zrRSi2J\nWiUxWTdyu7MX0Sa1yXxn5q6t9m7elJWZGDTvpSXB9DM/W5I9MM7X7KqqtOuDcVDMbigoKOC7777j\n5ptvbnD8dPeEyWRi6tSpbNmyxXc8Ly/Pd11JSQmqqp5VK4IQF7Jau5tI1bsRU3RiEhMu79FokGJT\nEmPDmP6DQdx3oyyiJMSFICiKhBUrVnDllVcSFxfnO1ZTU0Nlpbci0nWdDz/8kP79vb+YBg4ciM1m\nY/PmzQAsX76cG264ofODCxFC9uWUcvxUFQC1dhdRqg0AxXJ24wsG90nwTYcUQpzfOu3/9GeeeYZ1\n69ZRVFTEfffdR2xsLB988AHgLRJmzZrV4Pri4mIefvhh3G43Ho+H3r17M3fuXABUVeW5555j7ty5\nDaZACiGat/AfW7nIeILpdwzAFtmPSMXbdaCGhW7/qxCiY3VakTB79mxmz57d5Lns7OxGx7p27dri\n3hDDhg1j9erVfssnxPlC1/Umuw4UPPw88lNs6z7BefVTRKs13uNNbPcshBAQRAMXhRD+8do/PuOH\n1W8CEPmjxShm7zLKiWolquIdqLtlwwa6aOW4TVEopvBARRVCBLmgGJMghPCP2s/e8BUIAO6TBwBv\n60KKVuY7fq3+BT0MhTgim1+7RAghpEgQ4jyRc+IUrn2fNTjmKjgIQHm1gx9GfgXAVzbvCqbJWgWq\nNb1zQwohQooUCUKcJz7P9m7SdNCZzPPlN/G9MwXHgW8AWPz+TsyKC4Cv7fXLKUcndun8oEKIkCFF\nghDngfziauKrD2HTjfyx8hpOuOM57ExGqS5Gd9o4klff1VDorh+oaOx7eSDiCiFChBQJQpwH3v/8\nMMlaOad0K3N/chm/njyEfLd3cTF34RH6GE4C4Lrkx9gx8lz5BNb2mIFiObelyYUQ5zcpEoQIEbsO\nF7P1z3OpXPsKusfV4JxRU4lTq0nt0Y30pEjCzAaOuhLRFRXHrvVkmE6hoxA7cBQTR/Ug122lyqUF\n6J0IIUKFFAlChIgX395OH45Bzhac+79qcK7G5iROqyHcmgRAmFmjUg9jhz2d2oLjRFCDyxiBohmJ\nizID0L5dS4QQFxIpEoQIAW6Ph2S1flxB9bZsdL1+R0ZDbREaHpRob5FgMXmXQClyR2GoKaKroQTq\nll82aN7/7XVdygQhRMukSBAiBFTbXIyx7AVgv7MLhoo83nrnc3718hfeC0qOA6Al9AAgKtwIwG5n\nOqqi09VQgrHSuyla/+5x9EqN5vqR3Tr3TQghQo4UCUKEgBqbi26GYg44k1lRMwKAG0v/TlWtE5fb\nQ6pajAcVNS4NqG8tOOxK8j3DfMlkAKzRFmbfm0V6ogxaFEK0TIoEIUJAcbmNeLWSpO49yXfHAGBW\nXEyLWkdJpZ0YtQanKRpFq19pfdptF6OjMK/sNpYY78Y0eHyg4gshQpQUCUKEgD++vYkI1YExNhkd\nldU1QwHIMJ7k+8OnsKrVGCLjGtwzPDMRgGJPFL0yend6ZiFE6JMiQYgg53J7uNiYA4C1u3e1xE9s\nAzjl9m7xXFZUglWrwhzfeB+GX946kP7d45hweY9OyyuEOH9IkSBEkCsorWWQKYcakxVD+gBGXdwF\nDypraoYBkHHsbWKUmia3fM7ql8Rjdw1FbWLraCGEaI0UCUIEuW92nSRercJkTUVRFDx1Mx9PebxF\nQbqej6boKGYZiCiE8C8pEoQIctWVVXTRyglP9Y4rGJbhHWuQ747jy7odHQEMPYYGJJ8Q4vwlRYIQ\nQe7Evt2oio6W5C0Shmcm8ufHruLOq/uQ40oAwHTFvWh10x+FEMJfpEgQIgjtPlrCA4s2UFhWSw9D\nEQBaUi/feYOmUm1z8q2jN0+W3on5orGBiiqEOI9JkSBEEFr7bQ4Ol4fFK3aSqpVS4o5otGPjiVNV\ngEK1bglMSCHEeU+KBCGCkFFxc71lOxNr3iPLfASD4ml0zY/H9wtAMiHEhcTQ+iVCiM6iu+zkHTvO\nPaWLMYTXFwbRRmeja6MjTJ0ZTQhxAZIiQYggcer4McI+mks0wH8saxBx1wuNrlcUhXuuzyTFGt4p\n+YQQFx4pEoQIAh6PTvWa5wnT6o8tKJ9IrcfE+CGxXBce0+R9Vw+VGQ1CiI4jRYIQQWDp+v3cqlUB\n8F8l92DEhQPvds9dMy8KZDQhxAVMBi4KEQQOHszxfa2j+AoEgFTZ0lkIESBSJAgRYE6Xm3hXAQAH\nnMk8eudg/jpzLAkx3qmN4WatpduFEKLDSHeDEAFUUmGjrMpBou5dMGnoz3+DYgoD4PGpQ9mXU4bR\nIEWCECIwpEgQIkAcThev/+UdMsLKSDOU4gyL9xUIAAkxYSRcHNbCE4QQomN1WpGwcOFCsrOzyc3N\nZfXq1WRkeDemGTt2LCaTCbPZDMCMGTMYPXo0ANu2bWPOnDnY7XbS0tJ4/vnniY+Pb/WcEMHOXVuJ\n/a2HeTCq/pgjbkjgAgkhRBM6bUzCuHHjWLp0KWlpjadsvfLKK6xatYpVq1b5CgSPx8Njjz3GnDlz\nyM7OJisri0WLFrV6Tohg5/Z4+PIfrzc6HhGfHIA0QgjRvE4rErKyskhJSWnz9bt27cJsNpOVlQXA\nlClTWLt2bavnhAh2f1m5nWHu7QA8WvJDXqscy35XKuZhEwOcTAghGgqKMQkzZsxA13WGDx/Oo48+\nSnR0NPn5+aSmpvqusVqteDweysrKWjwXGxsbiLcgRJtU25zYj2yDKHi/Ogs3Gnuc6SQOGMlwc0Sg\n4wkhRAMBLxKWLl1KSkoKDoeD+fPnM2/evE7rOoiPP7f554mJUa1fFKRCNXuo5j6t2u7mJ1GfAfCF\nvR9XDUtnw5YToKhB/d6COVtrJHtgSPbA8Hf2gBcJp7sgTCYTU6dO5cEHH/Qdz8vL811XUlKCqqrE\nxsa2eO5sFBdX4fHo7cqdmBhFYWFlu+4NtFDNHqq5T0tMjOLrjz9nHHDQmMkjU4ZRUeVgwxaotTmC\n9r2F8s9dsgeGZA+MlrKrqtKuD8YBXUyppqaGykrvG9J1nQ8//JD+/fsDMHDgQGw2G5s3bwZg+fLl\n3HDDDa2eEyJYVVZUEZP3DQCDp0xjQA8rA3paiY4wccMl3QKcTgghGuu0loRnnnmGdevWUVRUxH33\n3UdsbCyvvvoqDz/8MG63G4/HQ+/evZk7dy4Aqqry3HPPMXfu3AbTHFs7J0Swyt3wPlnmI9TE9CIq\nLBrwbvf80sNXBDiZEEI0TdF1vX3t7ecB6W4ILcGQ2+Zw4Xr3v9FS+hF29c/bfN/Jkhpy/vEM/U15\nVIxfQFrXts/0CbRg+Lm3l2QPDMkeGOddd4MQoeTYyUpmv/QBelUxrgNfkZ+9hEOHc6m1u1q8T9d1\nnvzzRlIMpezVMklN79JJiYUQ4txIkSBEG50qq2V2zErf95HHviDp41m88M9tzd7jqSyk4p9PEq9W\nEqvWkti1G4qidEZcIYQ4Z1IkCNFGDqcbTWncPfXTmr+gO2qavKd6zxeoFflMjvAOWEzuktihGYUQ\nwp+kSBCijWwON8ddVqo8ZmaVTuLF8vFUeixEqnYcuz5udL3d4ebdr/MByDSeBMCU1q9TMwshxLmQ\nIkGINrA73Sxdv594tYptju5U6WEccycyu2wSB5zJOLauxlNxqsE9tQ4Xg0zHfd974rqixctURyFE\n6JAiQYhWeKpLKdz2OeGKjXDVQZHnzBXNFN6uvhTcTor+vb7Bfaf2biejrgUBQE3o3kmJhRDCP6RI\nEKIF7uLjVC99hJitf+PR6I8AGH9tFvN/fgnhZu8yI4V1RUPYgfVU1zq89xUcJGXLH33PeatqFOZR\nP+zk9EIIcW6kSBDnHZvDxZLVu/nX/76OI2fHOT2rYsXTvq8TNe/847i07qTER/Dy9Ct4dPJgdFT+\nbe8BgHvVU1TWOKha9TsAyj1hvFJxHZsdvYmLjzunLEII0dmkSBDnFZfbw9OvfsLNuS8x0vYl9rUv\ntvtZur0ag8fBVkd3Ntl7AeBMHYwW692BVFNVosNNAGxz9ABAqSjghWVbUPEAMKdsEodc3nURwi3G\ndmcRQohAkCJBnFf+76ujXKt8TZjq9B1zu1zMf2sza74+elbP2rPqTQC+tGWSXTuIPFcsnuF3Nbgm\nqq5I2OHsxrf23ugouEtO1N2XwWNThrT/zQghRIBJkSDOK59vz6W/MY9v7b15u/oSAHZv2sSJ3GK6\nbV2Mc/9XbXpOWZUdS/FeTrjiOOjqQpEnmoUVE4lKaLjOQVyUmRemjWLabRdzzJWAgs5Ao3dGw+AJ\nk+nfw4pBUzFo8r+aECL0BHyraCH8xeny4KqpIjzOQZ4rjn/be3JHxGY8+z5jamQtPY2FOHZ8hDFj\nVKvP+v5oCZlqNbU9rmTBiEvZsC2Xmy7rgdmoNbo2LsqM2ahS6QkD4Mbw7QCk9OgJwCvTr0BBVlkU\nQoQe+Xgjzht2p5totRaA0Zf2R7OEs8nWk97OfQwx5QDe6Yyt2XuslL9/sA2j4sGanEyyNZzJY/sS\nGdb8mAKjQaW8rkg4TVG9/3tZTAbMpsbFhRBCBDspEsR5Qdd1nNWVxCje5ZG7dk+jxu4i110/o2CH\noyvYq3EXHmn2OTaHixVfHCZJrQDAEJPQptdXFIV8d6zv+4i7ZOtyIUTok+4GcV7I/sc/GFW9nl9G\ne79X41KJsBRyyJHsu+bd6ksYZDqO68RutMSeDe7fsC2Xw3kV5OaXcrywmhes3jURtC4ZbXr9hBgL\nDoy8XHE9l/eyMDZK9mgQQoQ+KRJEmxWX24iJNAXdILzyKhujqhuudqiGRWM2quTVWplecg/UjQlw\nKSaMtsb7rf/v2n0MMB7nv6I+BWvD57SFNdrCDSO7sXYTDErq2foNQggRAoLrt70IWtU2J4/96Wvm\nLNlEeZU90HF8ispq2frGsw2OGfpcCuDbkvmyASncd6N3Y6VK3YJeW+G7ttbuYvPeU6RpJfwi6tMG\nz/k68tqzymJ3uQEIs0jtLYQ4P0iRIABwl5zAdXxns+ePnqwkVq3mCV5FX/oAur260TUut4f3PjtE\nVa2ziSf4n8vtYfnb6xhuPgrAb8tuY3rJvYSNfQCAm0f1AODeGzIZPci7AFK5y4TnjCLh/c8P88eV\nu3g8Zk2DZ39ly+D6qWe3jLLN7gIgQooEIcR5Qn6bCXSXnZp3ZwNgufKnGDNHN7qmrNLOSNMhADRF\np+LblZT0ugFrbCQxkWYAdh4u5oNvjlFcbuOygV0Y0NOKqnTc1L8Xlm9jsG0XHrOCbeICSv62p8H5\n0YNSfcUBwPCMRCrzLLiqy33H9uWUcmf4N77vHyu5CzcqbjRuOMs8t4zuRWWNk0G92zbYUQghgp20\nJAhqS4t9X9s+W4Ku6w3O67qHkyU1xKg1vmPq3vXsff81XvjnNt+xrfuLANi4p4Dfv72db3adpKPY\nHW5yThQwwnyYb+x9SEhOAiA+2tLsPdeO6EqVx4JeXep7j0VFpYyyHADgqCsBB0bctG+6YlJsGI9O\nHtLiVEkhhAglUiQIDh4+0fCAx9u3frKkhvdf+zNVf/kJ2zZt5QrLfnY70vjS5h3xf4VlP4VlNt9t\nX+7Mp7ehgEeiP6SrVsSe3Qc7LHOtw8UA4wlMipuMy69CU1V+c98I5vw4q9l7UhMiOOZOQHNWc/C7\nr7E73Fxh3uc7/7Wtr+/rEf2SOiy7EEKECuluuMDpus76L7/nF1H1x04Vl5OcFM+Tf97Iy9avAXx9\n9s60obyzz8oVlv0ATIrdAVyJy+3d0Ogayy56GIqYEfMhVAA07rrwR+aNuwu4yJgLQI+BgwDolhzV\n0m1EhhnZSy9gI4c2fsbqoxH0UbyDMD+pvYjkEdcyQde5bkQ3DJqskCiEENKScIH7Ykc+3QzFDY4t\nz/b27St4cOgNm94vG9GPH92QyZLKqwAY4f437pJcbA43Gm76GBt2Meguh98z7zxcjP7t3xluPorT\nYkW1tFwcnCk8OgaAUZb95B09hlWrotAdxara4Yy/tDu3j+lNZJgRi0nqZyGEkCLhArfrSAldtDI8\nOvyz2jt18Ce1Szh+/CSJaiUmxc1RV/1APC2pF2MGp7LD2Y2t9u4AuHK2Umt3YVWrMSnuBs937vnE\n75nfyt7na8kg8+qzulcBNtu96xjMjV3BYFNO3UqJSpP7MgghxIVMioQLmMvtYfPeU2SaTpETPoB9\nzhTfuQPr3mGUZT86Cv+oupwPaoZQefMiFFM4iqLw0O0X80/X1bjQcB31FglxahUAb1WN8vXvu4uO\n+T3zRXbvYMnPbZlEDL3xrO4vLLPxVnXDLhB7ZBoZXWObuUMIIS5cUiRcwNZvPk6aVkwYNiK6ZlDs\niWJp1eUAGJ0VZBjyUdIG0j0zg3W2QcRZ6/+QDstIZES/ZPI9VnDUUGt3Ea95i4TDriT+WXMZua44\n9NryJl+7vaprnVxs8m7FPHryj8564yS709vS8fsK7wTHPE88V93zc2b+cJhfcwohxPlAioQLUFWt\nk9VfHeGdTw9xjWUXOgo9Rl7FK9NHs8nRB4Ah6gGsWhXG2CR+elN/nv7pSMLMDfvpoyNM7LKn4Sk7\nyT8+3MYgYw5uSwxzfnk94y/tRpqhFHfunqYitNuaDbtJ10ooSx5BdHJq6zc046grif8quZuqq/8b\nVZNuBiGEaIoUCRegpR99z4ovjtDXkM8w8zEc6Vmo4TFEhhl55M7BvussigstuS9Gg0ZaYmSj53RL\niuKAMxnQianOIcN4Ek/6cKIjLXRLavtgwrYqr7LT8+j7hCkOtK4Xt+sZv7x1IFl10xt11KDbh0II\nIYKJ/Ia8AK356gjpWjEPRXs3RdIs4b5zF/eK582q+j57LSWz2ed07xJFXt1WzCPNhzAoHrQY7+6H\ng3rH86W9+Xv/059W7mLR8q0tXrNxxwkuNp1gt5JJ6rAxbX72mbL6JfHLWwf6vjca5H8BIYRojvyG\nvIDous7mrd7Fg+6N/MJ3PDy1V4Prtjp6sqImC73vGNSIuGaflxBjoVb3ri442JQDgCnKe32Y2YBD\n8a5+6C480mq27/aeYs/RUt777JBv3MCZPB6dUx+9DkC/5HOfnnh6VcTTS0oLIYRorNMmgy9cuJDs\n7Gxyc3NZvXo1GRkZlJaW8vjjj5OTk4PJZKJ79+7MmzcPq9W7V29mZiYZGRmoqreWee6558jM9H46\n/eSTT3juuedwu90MGDCABQsWEBYW1llvJyQ593xC5ndv8cuoFJI17yZH+3tOYVhm40/lG2wXcfdV\nLU8vVBQFk6Fhf76lT/2Kh2bV+8feufcztMS2bZ/8wTfHMBs1Jlzeo8HxU2W1DKgbsBh79Y/b9KyW\nTLttIDkFVaTGwTZ4nQAAGjlJREFUh7d+sRBCXKA6rSVh3LhxLF26lLS0NN8xRVH42c9+RnZ2NqtX\nr6Zr164sWrSowX3Lly9n1apVrFq1ylcgVFdX89RTT/Hqq6+yfv16IiIiWLJkSWe9lZDk2LEW+1dv\nAZBpzAcg/NanGH7tDb4tlf9TWzZneuTOwXXjEmBH1GgUtb7u/JfDO75BCW++NeJM/Yy5PBSVTfWe\nL9B1HbvTzYnCKrbsL+Qvf/0/YtVab67oxDY9ryWZ3eK4dkTXZt+7EEKITmxJyMpqvKZ+bGwsl1xy\nie/7IUOGsGzZslaf9fnnnzNw4EB69OgBwJQpU5g5cyYPPfSQ3/Keb2q/fcdXEeqKSuSUhahR/vlj\nu+XaGbhTohgV1XBzpWKbhitMxeRu26qLD0b9C4C+ngJsRwfx7Kd2Ykq/Z0S/BO6O+BIAJb77OWcW\nQgjRNkGz9qzH42HZsmWMHTu2wfF77rkHt9vNmDFjePjhhzGZTOTn55OaWj/9LTU1lfz8/M6OHFL2\nKH0ZqO9lr6c7w4dltlgg3HtDJpXVbV9OeVhG889yoaG7nC3efyi3nK5aUYNjlZvXcPzUpcywfgq5\nUKZ4uwUsI+5ocy4hhBDnJmiKhKeffprw8HDuvvtu37ENGzaQkpJCVVUVjz32GIsXL+aRRx7x22vG\nxzee1nc2EhP9P82vI5wqqcFWa6fSEsWNT73Y6vWTru3nl9cd0CseV6kBi7Hln9XnO08yPmw7AKXu\ncCJVG4byHFK0+hyxag27UiYycfgov2QLlFD5N/OfQjU3SPZAkeyB4e/sQVEkLFy4kGPHjvHqq6/6\nBikCpKR4lwmOjIxk0qRJvPHGG77j3377re+6vLw837Vno7i4Co9Hb1fmxMQoCgsr23VvZ3I43Tzw\nwmc8FVOIHteNwsLKTsseZtJwKxq11dUtvt6x/HLSdO8sgxcqbuIKyz5uCNvBdZYdDa67+b57Q+Jn\n3pxQ+Tfzn0I1N0j2QJHsgdFSdlVV2vXBOOBTIF988UV27drF4sWLMZlMvuPl5eXYbDYAXC4X2dnZ\n9O/fH4DRo0ezc+dOjh49CngHN44fP77Ts4eCgtJaMg15JGhVRHQf0KmvrSrg0g3QSneDze4mQa0k\n3xVDpR6GrW5a5TBzw30fZJChEEJ0rk5rSXjmmWdYt24dRUVF3HfffcTGxvLSSy/x2muv0aNHD6ZM\nmQJAeno6ixcv5vDhw8yZMwdFUXC5XAwdOpTp06cD3paFefPmcf/99+PxeOjfvz+zZs3qrLcS1Lbs\nL+SzbXk8cMsAwswG3t1wiD7GAgCi+43s1CyaquBEA3fzRUJBaQ1bducwxVroO/a5rR+3hv/b9/1j\nJXcx8uJu/HeHphVCCPGfOq1ImD17NrNnz250fN++fU1eP3ToUFavXt3s86655hquueYav+XrDAdP\nlON0e+jfvW1TAtvjs215HD1ygkP//IhetzzAzsPFDIuohAirX2YznA1V8RYJusuBy+3hzY/2cuOl\n3XG5PaTEh2M0aLy6cjc9DPWDFq3RZkoq7BTr0cQrFTh1DQcGHK7GCywJIYToWAHvbrhQfLUzn9/9\n/d88v2wrdkfH/cHTVIXJEd/Q3bYX10fPYlEcDAovwJDav8NeszmqquDSvS0JB46X8fWuk7zx4ff8\n5o3vWLxiFwAeXad7XZGwIupupt12MQpQ6fZ2PVV5zIDCgRP+3U1SCCFE66RI6CRLPvje9/XS9fs7\n9LW6GYoBUCpOsjBuOQZ3LYYW9mDoKKqq4NA1KiqqKaubUml3egDYccib8fipKhK1Ckrd4dx71zX0\nTImmS3w41R7vQEZzVAwAFWcxJVMIIYR/SJHQCXS94QyKL3fmN7k/gT/U1tqJqVuZ8ExKeGyHvF5L\nVFWh1q1SUVHN39buBSCpfCfJalmD62LVGuymGN/38TH1izJFJ3Zh1MVdmP6DQZ0TWgghhE9QTIE8\n33240TtKf5xlFxPDt3DMFY/ddhlmo//3moiuPQGAS1cxKB7fccXU+ftaWKPMuHQNg+LG4fQQodj4\nUd3GUiuqs4CxRIYZiVWrSUyvb+lIiLaQVOzdW8I48Fp+mnZRp2cXQgghRUKHc7o8vPfZYYy4mBi+\nBYDuhmLslSUQldbK3W23/2gR5d+8y91sBGBRxU2kaqXcG+ldzhhj5+92GGExYtc1jIoLgBvDtvnO\n3RaxGUd1OdW1duLDazDF1A+qtEZbcNc1cilh0Z0bWgghhI90N3Sw033vl5oPNjjurvbfQLyyKjtf\nrnibfpUbfccK3DHsd56xwJTW+fWg0aDiQsNSVyQMMJ5ocL52w1+JV6vQdDdabH3WcIuBg3WbRgWi\nBUQIIYSXFAkd6F//PsEfV+xgetRH/CBiEwA14d4/hvsO5DQaq9BeT73+LRqeBsfMZhOVehjrUu7H\nMGg8aszZr0h5rowGlSJ3NBbFyWDjMSyKk92O+tYTNXc7KZp3fIIaV78Xh1FTeb9mBG8oP0CNjO/0\n3EIIIbyku6GDnCqtYen6/fw+7u+oSn0xUDHgDsK/+wNbv88nvFchWf2Szul1dF0nwZnP7TGbAYi4\n93/A42Zxg4GKl53Ta7SXUVPZ7OjJ7RHf8ZOozwDIccezvzqF2yK8eXsaTgGgxnSpv8+g4kaj0tKl\n8UOFEEJ0GmlJ6CDL/3WQVK20vkAwmFDj0lHr+tgNipuKmnOf1vf59jwejfnI971qiUINwEyGphgN\nKtV6w7EQFlxssF/E4oprAbjImIeuqGCOaHAfgEGVf55CCBFI0pLQQSprHPx3jHfFyIg7F6DW9bkb\nDx8FIMN4EsUP3Q079uczrO5rQ8+sc36eP3n/2Dfcb2G309vdcNxtBSDFUIbbENlgX4Zeqd7pkFcO\nSUUIIUTgyEe1DnDsZCVRhfU7GCpRCb6vDUbvSoKXmg+SUHv4nF7nmf/dzOBT9UtXm0fd3cLVnc9Q\n1yKwxd4dgJqINPpkXcKogV2oPaOFQXNWNbgvLsrM649fzaUDpLtBCCECSYqEDvDZ9jyGmY8CYBn7\nAIpm9J0zmuq/VmpK2/0a2w4UkV78LUNN3jUYIu97NWi6GU4zat5/Xu/XjOT96hHkDL6fSVf1IaOb\nN6dLr/vnZ7Q0uldVZcdHIYQINCkS/MzpcrNhay4mvNP+DL0b7rxoiojmuMvb1L73+0Ptfp23svdw\nR8R3ALxWORaliT+0gabV/aGv1MP4zN4fg9k7nbGq1rsr5Ee1gwEInyD7OwohRDCSIsHPamwujLjI\nMJ/COGAcitLwR2wyaiyqmMBBZzIXG4+3+ryDJ8p54s/fsP/wyQbHI2q92z9/7ejHHVNv9d8b8KP/\nbA043bJA3VCMz239eLF8PFpiz05OJoQQoi2kSPCzGruLJK0cTXehpfRrdP70yP0TbiuphjLc9hrf\nuabWTXj+798y3fMGKR/PxJXn3SQqp6CS0RbvFtuVXUfRMyU4VyXU/qNIMBk1AMYNT2dk/yQcGDnm\n7tztq4UQQrSdFAl+tjenjF9HfwiAesaAxdMMdZ+mjXXdETX/9zsAXnx7GzP++DW1dpfv2j1HS+hn\nzCNC9U6VdO7z7nuw81CRbwXHW266vIPeybmLDDP5vr7z6j70SvUWMyajxuSxfQMVSwghRBvJFEg/\nWr/5OBs+3URWjLdFQI1JbvZa5+kffal3qeJdh0sAnd17DpE11LvZ0aLl27jeUj+4Ua9rdcgt8K5S\naOhzGUaD5u+34TfhFgOLHxmD2aShKg1bFSLDjM3cJYQQIlhIS4Kf6LrOso8PMD5sOy5dJfz236CY\nwpu89tE7B9M9vb6Z/a113q6Dl61vkfndAtwnD+Cp63roazzJKXcU+zzd0KuKeGfDQfYe8BYWWkpm\n44cHmTCzoVGBAPXdLkIIIYKX/Kb2k/JqBxpuBhqPczRmOFpCj2avHdgrntq+1/i+37DlBGbqV1+s\nrSjl2aVb6GE4RV9jATnGXuTaI3GXnWT9xiOEK3YAFEtkh72fzhIVLi0KQggRrKS7wU9yC6tJUCvR\nFJ1u/Qe0er12xpRFIy7SDPXdCodyyzh4wsDL1rUAmBK7sa+8hrGePVxiPsR1YdsBUCxRfn4Xneu5\nBy/DYpJ/gkIIEaykJcFPck+V08vo3awoNr13q9cXlNZwxOUd2Bip2kjV6osExV6FesaujsXWoex1\npuLSVXpGO4hVa4GmB0aGkoSYMBmbIIQQQUw+xvmBK38fl21fQD9LOEqEFdWa3uo9brfOHkc6PQ1F\njLXsIUkrx6YbMOGiKPcEg0zeroQD3W7HGhMGKBgUDyPcW/CgYOw2SLZRFkII0aGkJcEPalcvACBO\nq0GNS22wWVFzNE3hXzZvt8Royz4yjSc57opHVaCXYx/dtSIAKhIGMbJ/Einx9YMgVXQMXS/ugHci\nhBBC1JMiwc9MQ25q03XXjeiKG40VNfU7N4ZfOgmAeK2aboZijrgSGJyZgsmocf/EAXxj6+O71tB9\nWKNnCiGEEP4kRYIfPFt+M0sqr2TziPkYUvu36R6jQeP1x69myPW3AFDsjiSyW/0KjX2MBST37kdc\nlHe3xPSkSJbXXOY7r0Za/fgOhBBCiMakSPCDh386noKo/gzufXZjBFRVoVePLvx36RQWlt+Myaix\nuKJ+amRcatf6axUF8HZjFGiyhbIQQoiOJwMX/aCLNZwFv7i0XfdGhhnp2zOFURd3wWRQKXCfsd1z\nEzs7ziydwp3X9qNPozNCCCGEf0mREAQeudO7ZXKNzUW5HuY7rsV3a3Ddol9eTnm1gx5dQnt9BCGE\nEKFBuhuCiMmoAgozSqZy+JInGm2hbI220DMluk2zJ4QQQohzJUVCEDm9tbITA4Zo2UJZCCFEYHVK\nkbBw4ULGjh1LZmYm+/fv9x0/cuQIkydP5vrrr2fy5MkcPXr0nM+FMkVR6F7XlZDRNbaVq4UQQoiO\n1SlFwrhx41i6dClpaWkNjs+dO5epU6eSnZ3N1KlTmTNnzjmfC3WPTRnK//zXaNklUQghRMB1yl+i\nrKwsUlJSGhwrLi5mz549TJgwAYAJEyawZ88eSkpK2n3ufBBuMRBhkf0MhBBCBF7AZjfk5+eTnJyM\npmkAaJpGUlIS+fn56LrernNWqywwJIQQQvjLBT0FMj4+8pzuT0wM3amIoZo9VHOfFqr5QzU3SPZA\nkeyB4e/sASsSUlJSKCgowO12o2kabrebU6dOkZKSgq7r7Tp3toqLq/B49HblT0yMorCwsl33Blqo\nZg/V3KeFav5QzQ2SPVAke2C0lF1VlXZ9MA7Y6Lj4+Hj69+/PmjVrAFizZg39+/fHarW2+5wQQggh\n/EfRdb19H6XPwjPPPMO6desoKioiLi6O2NhYPvjgAw4dOsTMmTOpqKggOjqahQsX0qtXL4B2nzsb\n0pIQWkI192mhmj9Uc4NkDxTJHhgd0ZLQKUVCsJIiIbSEau7TQjV/qOYGyR4okj0wzqvuBiGEEEIE\nNykShBBCCNEkKRKEEEII0SQpEoQQQgjRJCkShBBCCNGkC3rFRbVua+ZA3R9IoZo9VHOfFqr5QzU3\nSPZAkeyB0Vz29r6nC3oKpBBCCCGaJ90NQgghhGiSFAlCCCGEaJIUCUIIIYRokhQJQgghhGiSFAlC\nCCGEaJIUCUIIIYRokhQJQgghhGiSFAlCCCGEaJIUCUIIIYRo0gW9LDNAaWkpjz/+ODk5OZhMJrp3\n7868efOwWq1s27aNOXPmYLfbSUtL4/nnnyc+Ph6AX//613z77bcUFhayZcsWIiIifM9s6b5gz97S\nuWDOfuTIEebMmUNhYSEGg4GLL76YuXPnYrFYgj67x+Phrrvuora2FoDExER++9vfkp6eHvTZz/TE\nE0/w/vvvd9i/m47InpmZSUZGBqrq/bz03HPPkZmZGRLZy8rKmDdvHrt378ZgMDB+/HgeeuihoM++\nZcsWfvvb3/qeX1xcTGJiIitWrAj67ADvvvsuf/vb31BVFU3TePLJJ8nKygqJ7O+99x5vvvkmHo+H\nrl278uyzzxIbG9tyEP0CV1paqm/cuNH3/bPPPqs/8cQTutvt1q+55hr9u+++03Vd1xcvXqzPnDnT\nd93XX3+tFxUV6RkZGXpVVZXveGv3BXP21s4Fc/bjx4/ru3fv1nXd+99g+vTp+h/+8IeQyK7rul5R\nUeH7+s0339SnTZsWMtl1Xdf/9a9/6U888USH/rvpiOwd/e+8I7Pff//9+htvvOH7/tSpUyGT/UwP\nPvig/vrrr4dE9pKSEn3o0KF6YWGhruu6/vHHH+vjx48PiewHDx7Ur7jiCr24uNh331NPPdVqjgu+\nuyE2NpZLLrnE9/2QIUPIy8tj165dmM1mX4U4ZcoU1q5d67vusssua7J1oLX7gjl7a+f8yd/Z09PT\nueiiiwBQVZVBgwaRl5cXEtkBoqKifF9XVVX5PtmGQvbS0lL+8Ic/8MQTT3RI5o7M3ln8nf3o0aPs\n37+fH/3oR75jiYmJIZH9TMXFxXz11VfccsstIZFd13V0Xae6uhqAyspKunTpEhLZ9+/fT//+/bFa\nrQBceeWVrF69utUcF3x3w5k8Hg/Lli1j7Nix5Ofnk5qa6jtntVrxeDyUlZW12DzT3vuCIXug+Du7\nzWbjvffe49FHH+2oyD7+zP7zn/+cPXv2EBcXx5IlSzoyNuC/7PPmzeNXv/pVg0Kno/nz537PPffg\ndrsZM2YMDz/8MCaTqSOj+yX7wYMHSU5OZtasWXz//fckJCTw+OOP07dv36DPfqaVK1cyatQoEhIS\nOiqyjz+yW61W5s2bx2233UZ0dDQej4e33norJLL369ePnTt3cvz4cdLT01mzZg01NTWt3nfBtySc\n6emnnyY8PJy777470FHOmmT3crlcPPLII1x66aWMGzfOD+la5s/sf/nLX/jiiy+46aab+NOf/uSH\ndC3zR/YPP/wQo9HIVVdd5b9gbeCvn/uGDRt4//33Wbp0KQcPHmTx4sV+Stg8f2T3eDxs376d22+/\nnRUrVjBp0iQefPBBP6Zsmr9/z7z//vvccccdfnlWa/yRvaqqiqVLl/Luu++yYcMGZs6cyUMPPYTe\nwZsp+yN7z549mT17No888gh33nknMTExABgMLbcVSJFQZ+HChRw7doyXXnoJVVVJSUlp0FxdUlKC\nqqqtVsjtvS8YsgeCP7O73W5mzJhBTEwMs2fP7sjYQMf83FVV5Qc/+AGrVq3qiMg+/sq+adMmNm7c\nyNixYxk7diwAEyZM4ODBg0GfHbz/vwJERkYyadIktmzZ0mG5wb+/Z1JSUnxNztdddx2FhYWUlJQE\nffbTtm3bRnl5OVdeeWVHRfbxV/Yvv/ySqKgoevXqBcCNN95ITk4OpaWlQZ8d4KabbuLdd9/lnXfe\n4fLLLyc5OZnIyMgW75EiAXjxxRfZtWsXixcv9jU1Dhw4EJvNxubNmwFYvnw5N9xwQ6vPau99wZC9\ns/kzu8fjYebMmWiaxvz581EUJWSyl5SUNPjlvnbt2g4ZYX+aP7P/5je/4fPPP+eTTz7hk08+AWDN\nmjX06dMn6LOXl5djs9kAbwtUdnY2/fv375Dc/s4+cOBAwsPDOXDgAADfffcdMTExxMXFBX320957\n7z0mTpzY6ifZc+XP7Onp6ezZs4fi4mIANm7cSGRkZMj83AsLCwGw2+288sor/OQnP2n1HkXv6HaS\nIHfgwAEmTJhAjx49fNPl0tPTWbx4MVu2bGHu3LkNppmc7jt76KGH2LFjBwUFBSQlJZGRkeHrR27p\nvmDP3tK5YM6+YcMG7r///gbT2YYNG8bcuXODPvu+fft44okncDqdAKSlpTFr1iy6du0a9Nn/U2Zm\nZodNgfR39q1btzJnzhwURcHlcjF06FCefPLJkMgOsHPnTn7729/icDgICwtj1qxZDBo0KCSy22w2\nRo0axdtvv03v3r39nrkjs7/xxhu8/fbbGI1GTCYTM2fO7JApkB2R/Wc/+xl5eXk4nU5uvPFGpk+f\n3uog6Qu+SBBCCCFE06S7QQghhBBNkiJBCCGEEE2SIkEIIYQQTZIiQQghhBBNkiJBCCGEEE2SIkEI\nIYQQTZK9G4QQ7TZ27FiKiorQNA1N0+jTpw+33HILkydPbnX+9YkTJxg3bpxvq2MhRPCR/zOFEOfk\n1Vdf5fLLL6eyspJNmzYxf/58duzYwYIFCwIdTQhxjqS7QQjhF1FRUYwbN46XXnqJFStWsH//fjZs\n2MCtt97KsGHDuPLKK/mf//kf3/WnN6sZMWIEQ4cOZevWrQC8++67jB8/nhEjRvDTn/6U3NzcgLwf\nIYQUCUIIPxs0aBBdunRh8+bNhIWFsXDhQjZv3sxrr73GsmXL+PjjjwH4+9//Dnj3Hdi6dStDhw7l\n448/5rXXXuMPf/gD33zzDcOHD+fXv/51IN+OEBc0KRKEEH6XlJREeXk5l1xyCZmZmaiqSr9+/bjp\nppvYtGlTs/ctX76cX/ziF/Tu3RuDwcADDzzA999/L60JQgSIjEkQQvhdQUEBMTExbN++nUWLFnHg\nwAGcTicOh6PFHevy8vL43e9+x8KFC33HdF2noKCAtLS0zoguhDiDFAlCCL86vQPd8OHDmTZtGnff\nfTevv/46ZrOZ+fPnU1paCtDkdt4pKSk88MADTJw4sbNjCyGaIN0NQgi/qKqq4tNPP+XRRx9l4sSJ\nZGZmUl1dTUxMDGazmR07drBmzRrf9VarFVVVOX78uO/YlClT+POf/8yBAwcAqKys5KOPPur09yKE\n8JKtooUQ7XbmOgmqqtKnTx8mTpzIlClT0DSNtWvXsnDhQsrKyhg5ciRpaWlUVFSwaNEiAF5++WWW\nLVuGy+Xi9ddfZ8iQIaxcuZIlS5aQm5tLVFQUl19+uUynFCJApEgQQgghRJOku0EIIYQQTZIiQQgh\nhBBNkiJBCCGEEE2SIkEIIYQQTZIiQQghhBBNkiJBCCGEEE2SIkEIIYQQTZIiQQghhBBNkiJBCCGE\nEE36f2iLsgmIRa9JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB0Xs8lcAAIi",
        "colab_type": "text"
      },
      "source": [
        "It looks like our models aren't doing better than our Linear Regression Model!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuu73IlbGS5I",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_8Q8XVBHKqE",
        "colab_type": "code",
        "outputId": "369cf8fb-64d7-49e6-b467-8c33eb4abbd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = elastic_net.predict(X_test), label = 'Elastic Net')\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = tree_reg.predict(X_test), label = 'Decision Tree')\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = lin_reg.predict(X_test), label = 'Linear Regression')\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = y_test, label = 'True')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF/CAYAAADD8Vq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38RKxlhgSUH",
        "colab_type": "text"
      },
      "source": [
        "# Auto ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJTsoHDgQ8U",
        "colab_type": "code",
        "outputId": "48c8ac5d-ae82-479b-fda1-27fc7be756b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/4e/9ce813120662d9bd357aac6cb922f4b08b85049ed86eb47fe34a02d27f14/TPOT-0.10.2-py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.16.5)\n",
            "Collecting stopit>=1.1.1 (from tpot)\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Requirement already satisfied: joblib>=0.10.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.28.1)\n",
            "Collecting deap>=1.0 (from tpot)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/98/3166fb5cfa47bf516e73575a1515734fe3ce05292160db403ae542626b32/deap-1.3.0-cp36-cp36m-manylinux2010_x86_64.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.21.3)\n",
            "Collecting update-checker>=0.16 (from tpot)\n",
            "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.3.1)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.2->tpot) (2018.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.6.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot) (1.12.0)\n",
            "Building wheels for collected packages: stopit\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp36-none-any.whl size=11955 sha256=c6a1a12af67b3a8f2bcbbb070b1d75a22ecb360466b268842aa397203be2ac3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "Successfully built stopit\n",
            "Installing collected packages: stopit, deap, update-checker, tpot\n",
            "Successfully installed deap-1.3.0 stopit-1.1.2 tpot-0.10.2 update-checker-0.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SDZEMH-g23K",
        "colab_type": "code",
        "outputId": "c03e960f-3bb2-4377-c63d-b210ea92fce9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/colabwidgets/controls.css": {
              "data": "/* Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

 /* We import all of these together in a single css file because the Webpack
loader sees only one file at a time. This allows postcss to see the variable
definitions when they are used. */

 /*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

 /*
This file is copied from the JupyterLab project to define default styling for
when the widget styling is compiled down to eliminate CSS variables. We make one
change - we comment out the font import below.
*/

 /**
 * The material design colors are adapted from google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/dist/palette.var.css
 *
 * The license for the material design color CSS variables is as follows (see
 * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/LICENSE)
 *
 * The MIT License (MIT)
 *
 * Copyright (c) 2014 Dan Le Van
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

 /*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

 /*
 * Optional monospace font for input/output prompt.
 */

 /* Commented out in ipywidgets since we don't need it. */

 /* @import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); */

 /*
 * Added for compabitility with output area
 */

 :root {

  /* Borders

  The following variables, specify the visual styling of borders in JupyterLab.
   */

  /* UI Fonts

  The UI font CSS variables are used for the typography all of the JupyterLab
  user interface elements that are not directly user generated content.
  */ /* Base font size */ /* Ensures px perfect FontAwesome icons */

  /* Use these font colors against the corresponding main layout colors.
     In a light theme, these go from dark to light.
  */

  /* Use these against the brand/accent/warn/error colors.
     These will typically go from light to darker, in both a dark and light theme
   */

  /* Content Fonts

  Content font variables are used for typography of user generated content.
  */ /* Base font size */


  /* Layout

  The following are the main layout colors use in JupyterLab. In a light
  theme these would go from light to dark.
  */

  /* Brand/accent */

  /* State colors (warn, error, success, info) */

  /* Cell specific styles */
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */

  /* Notebook specific styles */

  /* Console specific styles */

  /* Toolbar specific styles */
}

 /* Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

 /*
 * We assume that the CSS variables in
 * https://github.com/jupyterlab/jupyterlab/blob/master/src/default-theme/variables.css
 * have been defined.
 */

 /* This file has code derived from PhosphorJS CSS files, as noted below. The license for this PhosphorJS code is:

Copyright (c) 2014-2017, PhosphorJS Contributors
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

* Redistributions of source code must retain the above copyright notice, this
  list of conditions and the following disclaimer.

* Redistributions in binary form must reproduce the above copyright notice,
  this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.

* Neither the name of the copyright holder nor the names of its
  contributors may be used to endorse or promote products derived from
  this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

*/

 /*
 * The following section is derived from https://github.com/phosphorjs/phosphor/blob/23b9d075ebc5b73ab148b6ebfc20af97f85714c4/packages/widgets/style/tabbar.css 
 * We've scoped the rules so that they are consistent with exactly our code.
 */

 .jupyter-widgets.widget-tab > .p-TabBar {
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

 .jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] {
  -webkit-box-orient: horizontal;
  -webkit-box-direction: normal;
      -ms-flex-direction: row;
          flex-direction: row;
}

 .jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] {
  -webkit-box-orient: vertical;
  -webkit-box-direction: normal;
      -ms-flex-direction: column;
          flex-direction: column;
}

 .jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {
  margin: 0;
  padding: 0;
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-flex: 1;
      -ms-flex: 1 1 auto;
          flex: 1 1 auto;
  list-style-type: none;
}

 .jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] > .p-TabBar-content {
  -webkit-box-orient: horizontal;
  -webkit-box-direction: normal;
      -ms-flex-direction: row;
          flex-direction: row;
}

 .jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] > .p-TabBar-content {
  -webkit-box-orient: vertical;
  -webkit-box-direction: normal;
      -ms-flex-direction: column;
          flex-direction: column;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {
  display: -webkit-box;
  display: -ms-flexbox;
  display: flex;
  -webkit-box-orient: horizontal;
  -webkit-box-direction: normal;
      -ms-flex-direction: row;
          flex-direction: row;
  -webkit-box-sizing: border-box;
          box-sizing: border-box;
  overflow: hidden;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {
  -webkit-box-flex: 0;
      -ms-flex: 0 0 auto;
          flex: 0 0 auto;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel {
  -webkit-box-flex: 1;
      -ms-flex: 1 1 auto;
          flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-hidden {
  display: none !important;
}

 .jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab {
  position: relative;
}

 .jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab {
  left: 0;
  -webkit-transition: left 150ms ease;
  transition: left 150ms ease;
}

 .jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab {
  top: 0;
  -webkit-transition: top 150ms ease;
  transition: top 150ms ease;
}

 .jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging {
  -webkit-transition: none;
  transition: none;
}

 /* End tabbar.css */

 :root { /* margin between inline elements */

    /* From Material Design Lite */
}

 .jupyter-widgets {
    margin: 2px;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    color: black;
    overflow: visible;
}

 .jupyter-widgets.jupyter-widgets-disconnected::before {
    line-height: 28px;
    height: 28px;
}

 .jp-Output-result > .jupyter-widgets {
    margin-left: 0;
    margin-right: 0;
}

 /* vbox and hbox */

 .widget-inline-hbox {
    /* Horizontal widgets */
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: horizontal;
    -webkit-box-direction: normal;
        -ms-flex-direction: row;
            flex-direction: row;
    -webkit-box-align: baseline;
        -ms-flex-align: baseline;
            align-items: baseline;
}

 .widget-inline-vbox {
    /* Vertical Widgets */
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
    -webkit-box-align: center;
        -ms-flex-align: center;
            align-items: center;
}

 .widget-box {
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    margin: 0;
    overflow: auto;
}

 .widget-gridbox {
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    display: grid;
    margin: 0;
    overflow: auto;
}

 .widget-hbox {
    -webkit-box-orient: horizontal;
    -webkit-box-direction: normal;
        -ms-flex-direction: row;
            flex-direction: row;
}

 .widget-vbox {
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
}

 /* General Button Styling */

 .jupyter-button {
    padding-left: 10px;
    padding-right: 10px;
    padding-top: 0px;
    padding-bottom: 0px;
    display: inline-block;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    text-align: center;
    font-size: 13px;
    cursor: pointer;

    height: 28px;
    border: 0px solid;
    line-height: 28px;
    -webkit-box-shadow: none;
            box-shadow: none;

    color: rgba(0, 0, 0, .8);
    background-color: #EEEEEE;
    border-color: #E0E0E0;
    border: none;
}

 .jupyter-button i.fa {
    margin-right: 4px;
    pointer-events: none;
}

 .jupyter-button:empty:before {
    content: "\200b"; /* zero-width space */
}

 .jupyter-widgets.jupyter-button:disabled {
    opacity: 0.6;
}

 .jupyter-button i.fa.center {
    margin-right: 0;
}

 .jupyter-button:hover:enabled, .jupyter-button:focus:enabled {
    /* MD Lite 2dp shadow */
    -webkit-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14),
                0 3px 1px -2px rgba(0, 0, 0, .2),
                0 1px 5px 0 rgba(0, 0, 0, .12);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14),
                0 3px 1px -2px rgba(0, 0, 0, .2),
                0 1px 5px 0 rgba(0, 0, 0, .12);
}

 .jupyter-button:active, .jupyter-button.mod-active {
    /* MD Lite 4dp shadow */
    -webkit-box-shadow: 0 4px 5px 0 rgba(0, 0, 0, .14),
                0 1px 10px 0 rgba(0, 0, 0, .12),
                0 2px 4px -1px rgba(0, 0, 0, .2);
            box-shadow: 0 4px 5px 0 rgba(0, 0, 0, .14),
                0 1px 10px 0 rgba(0, 0, 0, .12),
                0 2px 4px -1px rgba(0, 0, 0, .2);
    color: rgba(0, 0, 0, .8);
    background-color: #BDBDBD;
}

 .jupyter-button:focus:enabled {
    outline: 1px solid #64B5F6;
}

 /* Button "Primary" Styling */

 .jupyter-button.mod-primary {
    color: rgba(255, 255, 255, 1.0);
    background-color: #2196F3;
}

 .jupyter-button.mod-primary.mod-active {
    color: rgba(255, 255, 255, 1);
    background-color: #1976D2;
}

 .jupyter-button.mod-primary:active {
    color: rgba(255, 255, 255, 1);
    background-color: #1976D2;
}

 /* Button "Success" Styling */

 .jupyter-button.mod-success {
    color: rgba(255, 255, 255, 1.0);
    background-color: #4CAF50;
}

 .jupyter-button.mod-success.mod-active {
    color: rgba(255, 255, 255, 1);
    background-color: #388E3C;
 }

 .jupyter-button.mod-success:active {
    color: rgba(255, 255, 255, 1);
    background-color: #388E3C;
 }

 /* Button "Info" Styling */

 .jupyter-button.mod-info {
    color: rgba(255, 255, 255, 1.0);
    background-color: #00BCD4;
}

 .jupyter-button.mod-info.mod-active {
    color: rgba(255, 255, 255, 1);
    background-color: #0097A7;
}

 .jupyter-button.mod-info:active {
    color: rgba(255, 255, 255, 1);
    background-color: #0097A7;
}

 /* Button "Warning" Styling */

 .jupyter-button.mod-warning {
    color: rgba(255, 255, 255, 1.0);
    background-color: #FF9800;
}

 .jupyter-button.mod-warning.mod-active {
    color: rgba(255, 255, 255, 1);
    background-color: #F57C00;
}

 .jupyter-button.mod-warning:active {
    color: rgba(255, 255, 255, 1);
    background-color: #F57C00;
}

 /* Button "Danger" Styling */

 .jupyter-button.mod-danger {
    color: rgba(255, 255, 255, 1.0);
    background-color: #F44336;
}

 .jupyter-button.mod-danger.mod-active {
    color: rgba(255, 255, 255, 1);
    background-color: #D32F2F;
}

 .jupyter-button.mod-danger:active {
    color: rgba(255, 255, 255, 1);
    background-color: #D32F2F;
}

 /* Widget Button*/

 .widget-button, .widget-toggle-button {
    width: 148px;
}

 /* Widget Label Styling */

 /* Override Bootstrap label css */

 .jupyter-widgets label {
    margin-bottom: 0;
    margin-bottom: initial;
}

 .widget-label-basic {
    /* Basic Label */
    color: black;
    font-size: 13px;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    line-height: 28px;
}

 .widget-label {
    /* Label */
    color: black;
    font-size: 13px;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
    line-height: 28px;
}

 .widget-inline-hbox .widget-label {
    /* Horizontal Widget Label */
    color: black;
    text-align: right;
    margin-right: 8px;
    width: 80px;
    -ms-flex-negative: 0;
        flex-shrink: 0;
}

 .widget-inline-vbox .widget-label {
    /* Vertical Widget Label */
    color: black;
    text-align: center;
    line-height: 28px;
}

 /* Widget Readout Styling */

 .widget-readout {
    color: black;
    font-size: 13px;
    height: 28px;
    line-height: 28px;
    overflow: hidden;
    white-space: nowrap;
    text-align: center;
}

 .widget-readout.overflow {
    /* Overflowing Readout */

    /* From Material Design Lite
        shadow-key-umbra-opacity: 0.2;
        shadow-key-penumbra-opacity: 0.14;
        shadow-ambient-shadow-opacity: 0.12;
     */
    -webkit-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .2),
                        0 3px 1px -2px rgba(0, 0, 0, .14),
                        0 1px 5px 0 rgba(0, 0, 0, .12);

    box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .2),
                0 3px 1px -2px rgba(0, 0, 0, .14),
                0 1px 5px 0 rgba(0, 0, 0, .12);
}

 .widget-inline-hbox .widget-readout {
    /* Horizontal Readout */
    text-align: center;
    max-width: 148px;
    min-width: 72px;
    margin-left: 4px;
}

 .widget-inline-vbox .widget-readout {
    /* Vertical Readout */
    margin-top: 4px;
    /* as wide as the widget */
    width: inherit;
}

 /* Widget Checkbox Styling */

 .widget-checkbox {
    width: 300px;
    height: 28px;
    line-height: 28px;
}

 .widget-checkbox input[type="checkbox"] {
    margin: 0px 8px 0px 0px;
    line-height: 28px;
    font-size: large;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    -ms-flex-negative: 0;
        flex-shrink: 0;
    -ms-flex-item-align: center;
        align-self: center;
}

 /* Widget Valid Styling */

 .widget-valid {
    height: 28px;
    line-height: 28px;
    width: 148px;
    font-size: 13px;
}

 .widget-valid i:before {
    line-height: 28px;
    margin-right: 4px;
    margin-left: 4px;

    /* from the fa class in FontAwesome: https://github.com/FortAwesome/Font-Awesome/blob/49100c7c3a7b58d50baa71efef11af41a66b03d3/css/font-awesome.css#L14 */
    display: inline-block;
    font: normal normal normal 14px/1 FontAwesome;
    font-size: inherit;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
}

 .widget-valid.mod-valid i:before {
    content: "\f00c";
    color: green;
}

 .widget-valid.mod-invalid i:before {
    content: "\f00d";
    color: red;
}

 .widget-valid.mod-valid .widget-valid-readout {
    display: none;
}

 /* Widget Text and TextArea Stying */

 .widget-textarea, .widget-text {
    width: 300px;
}

 .widget-text input[type="text"], .widget-text input[type="number"]{
    height: 28px;
    line-height: 28px;
}

 .widget-text input[type="text"]:disabled, .widget-text input[type="number"]:disabled, .widget-textarea textarea:disabled {
    opacity: 0.6;
}

 .widget-text input[type="text"], .widget-text input[type="number"], .widget-textarea textarea {
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    border: 1px solid #9E9E9E;
    background-color: white;
    color: rgba(0, 0, 0, .8);
    font-size: 13px;
    padding: 4px 8px;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    -ms-flex-negative: 1;
        flex-shrink: 1;
    outline: none !important;
}

 .widget-textarea textarea {
    height: inherit;
    width: inherit;
}

 .widget-text input:focus, .widget-textarea textarea:focus {
    border-color: #64B5F6;
}

 /* Widget Slider */

 .widget-slider .ui-slider {
    /* Slider Track */
    border: 1px solid #BDBDBD;
    background: #BDBDBD;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    position: relative;
    border-radius: 0px;
}

 .widget-slider .ui-slider .ui-slider-handle {
    /* Slider Handle */
    outline: none !important; /* focused slider handles are colored - see below */
    position: absolute;
    background-color: white;
    border: 1px solid #9E9E9E;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    z-index: 1;
    background-image: none; /* Override jquery-ui */
}

 /* Override jquery-ui */

 .widget-slider .ui-slider .ui-slider-handle:hover, .widget-slider .ui-slider .ui-slider-handle:focus {
    background-color: #2196F3;
    border: 1px solid #2196F3;
}

 .widget-slider .ui-slider .ui-slider-handle:active {
    background-color: #2196F3;
    border-color: #2196F3;
    z-index: 2;
    -webkit-transform: scale(1.2);
            transform: scale(1.2);
}

 .widget-slider  .ui-slider .ui-slider-range {
    /* Interval between the two specified value of a double slider */
    position: absolute;
    background: #2196F3;
    z-index: 0;
}

 /* Shapes of Slider Handles */

 .widget-hslider .ui-slider .ui-slider-handle {
    width: 16px;
    height: 16px;
    margin-top: -7px;
    margin-left: -7px;
    border-radius: 50%;
    top: 0;
}

 .widget-vslider .ui-slider .ui-slider-handle {
    width: 16px;
    height: 16px;
    margin-bottom: -7px;
    margin-left: -7px;
    border-radius: 50%;
    left: 0;
}

 .widget-hslider .ui-slider .ui-slider-range {
    height: 8px;
    margin-top: -3px;
}

 .widget-vslider .ui-slider .ui-slider-range {
    width: 8px;
    margin-left: -3px;
}

 /* Horizontal Slider */

 .widget-hslider {
    width: 300px;
    height: 28px;
    line-height: 28px;

    /* Override the align-items baseline. This way, the description and readout
    still seem to align their baseline properly, and we don't have to have
    align-self: stretch in the .slider-container. */
    -webkit-box-align: center;
        -ms-flex-align: center;
            align-items: center;
}

 .widgets-slider .slider-container {
    overflow: visible;
}

 .widget-hslider .slider-container {
    height: 28px;
    margin-left: 6px;
    margin-right: 6px;
    -webkit-box-flex: 1;
        -ms-flex: 1 1 148px;
            flex: 1 1 148px;
}

 .widget-hslider .ui-slider {
    /* Inner, invisible slide div */
    height: 4px;
    margin-top: 12px;
    width: 100%;
}

 /* Vertical Slider */

 .widget-vbox .widget-label {
    height: 28px;
    line-height: 28px;
}

 .widget-vslider {
    /* Vertical Slider */
    height: 200px;
    width: 72px;
}

 .widget-vslider .slider-container {
    -webkit-box-flex: 1;
        -ms-flex: 1 1 148px;
            flex: 1 1 148px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 6px;
    margin-top: 6px;
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
}

 .widget-vslider .ui-slider-vertical {
    /* Inner, invisible slide div */
    width: 4px;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    margin-left: auto;
    margin-right: auto;
}

 /* Widget Progress Styling */

 .progress-bar {
    -webkit-transition: none;
    transition: none;
}

 .progress-bar {
    height: 28px;
}

 .progress-bar {
    background-color: #2196F3;
}

 .progress-bar-success {
    background-color: #4CAF50;
}

 .progress-bar-info {
    background-color: #00BCD4;
}

 .progress-bar-warning {
    background-color: #FF9800;
}

 .progress-bar-danger {
    background-color: #F44336;
}

 .progress {
    background-color: #EEEEEE;
    border: none;
    -webkit-box-shadow: none;
            box-shadow: none;
}

 /* Horisontal Progress */

 .widget-hprogress {
    /* Progress Bar */
    height: 28px;
    line-height: 28px;
    width: 300px;
    -webkit-box-align: center;
        -ms-flex-align: center;
            align-items: center;

}

 .widget-hprogress .progress {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    margin-top: 4px;
    margin-bottom: 4px;
    -ms-flex-item-align: stretch;
        align-self: stretch;
    /* Override bootstrap style */
    height: auto;
    height: initial;
}

 /* Vertical Progress */

 .widget-vprogress {
    height: 200px;
    width: 72px;
}

 .widget-vprogress .progress {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    width: 20px;
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 0;
}

 /* Select Widget Styling */

 .widget-dropdown {
    height: 28px;
    width: 300px;
    line-height: 28px;
}

 .widget-dropdown > select {
    padding-right: 20px;
    border: 1px solid #9E9E9E;
    border-radius: 0;
    height: inherit;
    -webkit-box-flex: 1;
        -ms-flex: 1 1 148px;
            flex: 1 1 148px;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    outline: none !important;
    -webkit-box-shadow: none;
            box-shadow: none;
    background-color: white;
    color: rgba(0, 0, 0, .8);
    font-size: 13px;
    vertical-align: top;
    padding-left: 8px;
	appearance: none;
	-webkit-appearance: none;
	-moz-appearance: none;
    background-repeat: no-repeat;
	background-size: 20px;
	background-position: right center;
    background-image: url("data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjIuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCAxOCAxOCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgMTggMTg7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDpub25lO30KPC9zdHlsZT4KPHBhdGggZD0iTTUuMiw1LjlMOSw5LjdsMy44LTMuOGwxLjIsMS4ybC00LjksNWwtNC45LTVMNS4yLDUuOXoiLz4KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAtMC42aDE4djE4SDBWLTAuNnoiLz4KPC9zdmc+Cg");
}

 .widget-dropdown > select:focus {
    border-color: #64B5F6;
}

 .widget-dropdown > select:disabled {
    opacity: 0.6;
}

 /* To disable the dotted border in Firefox around select controls.
   See http://stackoverflow.com/a/18853002 */

 .widget-dropdown > select:-moz-focusring {
    color: transparent;
    text-shadow: 0 0 0 #000;
}

 /* Select and SelectMultiple */

 .widget-select {
    width: 300px;
    line-height: 28px;

    /* Because Firefox defines the baseline of a select as the bottom of the
    control, we align the entire control to the top and add padding to the
    select to get an approximate first line baseline alignment. */
    -webkit-box-align: start;
        -ms-flex-align: start;
            align-items: flex-start;
}

 .widget-select > select {
    border: 1px solid #9E9E9E;
    background-color: white;
    color: rgba(0, 0, 0, .8);
    font-size: 13px;
    -webkit-box-flex: 1;
        -ms-flex: 1 1 148px;
            flex: 1 1 148px;
    outline: none !important;
    overflow: auto;
    height: inherit;

    /* Because Firefox defines the baseline of a select as the bottom of the
    control, we align the entire control to the top and add padding to the
    select to get an approximate first line baseline alignment. */
    padding-top: 5px;
}

 .widget-select > select:focus {
    border-color: #64B5F6;
}

 .wiget-select > select > option {
    padding-left: 4px;
    line-height: 28px;
    /* line-height doesn't work on some browsers for select options */
    padding-top: calc(28px - var(--jp-widgets-font-size) / 2);
    padding-bottom: calc(28px - var(--jp-widgets-font-size) / 2);
}

 /* Toggle Buttons Styling */

 .widget-toggle-buttons {
    line-height: 28px;
}

 .widget-toggle-buttons .widget-toggle-button {
    margin-left: 2px;
    margin-right: 2px;
}

 .widget-toggle-buttons .jupyter-button:disabled {
    opacity: 0.6;
}

 /* Radio Buttons Styling */

 .widget-radio {
    width: 300px;
    line-height: 28px;
}

 .widget-radio-box {
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
    -webkit-box-align: stretch;
        -ms-flex-align: stretch;
            align-items: stretch;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    margin-bottom: 8px;
}

 .widget-radio-box label {
    height: 20px;
    line-height: 20px;
    font-size: 13px;
}

 .widget-radio-box input {
    height: 20px;
    line-height: 20px;
    margin: 0 8px 0 1px;
    float: left;
}

 /* Color Picker Styling */

 .widget-colorpicker {
    width: 300px;
    height: 28px;
    line-height: 28px;
}

 .widget-colorpicker > .widget-colorpicker-input {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    -ms-flex-negative: 1;
        flex-shrink: 1;
    min-width: 72px;
}

 .widget-colorpicker input[type="color"] {
    width: 28px;
    height: 28px;
    padding: 0 2px; /* make the color square actually square on Chrome on OS X */
    background: white;
    color: rgba(0, 0, 0, .8);
    border: 1px solid #9E9E9E;
    border-left: none;
    -webkit-box-flex: 0;
        -ms-flex-positive: 0;
            flex-grow: 0;
    -ms-flex-negative: 0;
        flex-shrink: 0;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    -ms-flex-item-align: stretch;
        align-self: stretch;
    outline: none !important;
}

 .widget-colorpicker.concise input[type="color"] {
    border-left: 1px solid #9E9E9E;
}

 .widget-colorpicker input[type="color"]:focus, .widget-colorpicker input[type="text"]:focus {
    border-color: #64B5F6;
}

 .widget-colorpicker input[type="text"] {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    outline: none !important;
    height: 28px;
    line-height: 28px;
    background: white;
    color: rgba(0, 0, 0, .8);
    border: 1px solid #9E9E9E;
    font-size: 13px;
    padding: 4px 8px;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    -ms-flex-negative: 1;
        flex-shrink: 1;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
}

 .widget-colorpicker input[type="text"]:disabled {
    opacity: 0.6;
}

 /* Date Picker Styling */

 .widget-datepicker {
    width: 300px;
    height: 28px;
    line-height: 28px;
}

 .widget-datepicker input[type="date"] {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    -ms-flex-negative: 1;
        flex-shrink: 1;
    min-width: 0; /* This makes it possible for the flexbox to shrink this input */
    outline: none !important;
    height: 28px;
    border: 1px solid #9E9E9E;
    background-color: white;
    color: rgba(0, 0, 0, .8);
    font-size: 13px;
    padding: 4px 8px;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
}

 .widget-datepicker input[type="date"]:focus {
    border-color: #64B5F6;
}

 .widget-datepicker input[type="date"]:invalid {
    border-color: #FF9800;
}

 .widget-datepicker input[type="date"]:disabled {
    opacity: 0.6;
}

 /* Play Widget */

 .widget-play {
    width: 148px;
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-align: stretch;
        -ms-flex-align: stretch;
            align-items: stretch;
}

 .widget-play .jupyter-button {
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    height: auto;
}

 .widget-play .jupyter-button:disabled {
    opacity: 0.6;
}

 /* Tab Widget */

 .jupyter-widgets.widget-tab {
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
}

 .jupyter-widgets.widget-tab > .p-TabBar {
    /* Necessary so that a tab can be shifted down to overlay the border of the box below. */
    overflow-x: visible;
    overflow-y: visible;
}

 .jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {
    /* Make sure that the tab grows from bottom up */
    -webkit-box-align: end;
        -ms-flex-align: end;
            align-items: flex-end;
    min-width: 0;
    min-height: 0;
}

 .jupyter-widgets.widget-tab > .widget-tab-contents {
    width: 100%;
    -webkit-box-sizing: border-box;
            box-sizing: border-box;
    margin: 0;
    background: white;
    color: rgba(0, 0, 0, .8);
    border: 1px solid #9E9E9E;
    padding: 15px;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    overflow: auto;
}

 .jupyter-widgets.widget-tab > .p-TabBar {
    font: 13px Helvetica, Arial, sans-serif;
    min-height: 25px;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {
    -webkit-box-flex: 0;
        -ms-flex: 0 1 144px;
            flex: 0 1 144px;
    min-width: 35px;
    min-height: 25px;
    line-height: 24px;
    margin-left: -1px;
    padding: 0px 10px;
    background: #EEEEEE;
    color: rgba(0, 0, 0, .5);
    border: 1px solid #9E9E9E;
    border-bottom: none;
    position: relative;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current {
    color: rgba(0, 0, 0, 1.0);
    /* We want the background to match the tab content background */
    background: white;
    min-height: 26px;
    -webkit-transform: translateY(1px);
            transform: translateY(1px);
    overflow: visible;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current:before {
    position: absolute;
    top: -1px;
    left: -1px;
    content: '';
    height: 2px;
    width: calc(100% + 2px);
    background: #2196F3;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:first-child {
    margin-left: 0;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:hover:not(.p-mod-current) {
    background: white;
    color: rgba(0, 0, 0, .8);
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon {
    margin-left: 4px;
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon:before {
    font-family: FontAwesome;
    content: '\f00d'; /* close */
}

 .jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel,
.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {
    line-height: 24px;
}

 /* Accordion Widget */

 .p-Collapse {
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
    -webkit-box-align: stretch;
        -ms-flex-align: stretch;
            align-items: stretch;
}

 .p-Collapse-header {
    padding: 4px;
    cursor: pointer;
    color: rgba(0, 0, 0, .5);
    background-color: #EEEEEE;
    border: 1px solid #9E9E9E;
    padding: 10px 15px;
    font-weight: bold;
}

 .p-Collapse-header:hover {
    background-color: white;
    color: rgba(0, 0, 0, .8);
}

 .p-Collapse-open > .p-Collapse-header {
    background-color: white;
    color: rgba(0, 0, 0, 1.0);
    cursor: default;
    border-bottom: none;
}

 .p-Collapse .p-Collapse-header::before {
    content: '\f0da\00A0';  /* caret-right, non-breaking space */
    display: inline-block;
    font: normal normal normal 14px/1 FontAwesome;
    font-size: inherit;
    text-rendering: auto;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
}

 .p-Collapse-open > .p-Collapse-header::before {
    content: '\f0d7\00A0'; /* caret-down, non-breaking space */
}

 .p-Collapse-contents {
    padding: 15px;
    background-color: white;
    color: rgba(0, 0, 0, .8);
    border-left: 1px solid #9E9E9E;
    border-right: 1px solid #9E9E9E;
    border-bottom: 1px solid #9E9E9E;
    overflow: auto;
}

 .p-Accordion {
    display: -webkit-box;
    display: -ms-flexbox;
    display: flex;
    -webkit-box-orient: vertical;
    -webkit-box-direction: normal;
        -ms-flex-direction: column;
            flex-direction: column;
    -webkit-box-align: stretch;
        -ms-flex-align: stretch;
            align-items: stretch;
}

 .p-Accordion .p-Collapse {
    margin-bottom: 0;
}

 .p-Accordion .p-Collapse + .p-Collapse {
    margin-top: 4px;
}

 /* HTML widget */

 .widget-html, .widget-htmlmath {
    font-size: 13px;
}

 .widget-html > .widget-html-content, .widget-htmlmath > .widget-html-content {
    /* Fill out the area in the HTML widget */
    -ms-flex-item-align: stretch;
        align-self: stretch;
    -webkit-box-flex: 1;
        -ms-flex-positive: 1;
            flex-grow: 1;
    -ms-flex-negative: 1;
        flex-shrink: 1;
    /* Makes sure the baseline is still aligned with other elements */
    line-height: 28px;
    /* Make it possible to have absolutely-positioned elements in the html */
    position: relative;
}

/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["../node_modules/@jupyter-widgets/controls/css/widgets.css","../node_modules/@jupyter-widgets/controls/css/labvariables.css","../node_modules/@jupyter-widgets/controls/css/materialcolors.css","../node_modules/@jupyter-widgets/controls/css/widgets-base.css","../node_modules/@jupyter-widgets/controls/css/phosphor.css"],"names":[],"mappings":"AAAA;;GAEG;;CAEF;;kCAEiC;;CCNlC;;;+EAG+E;;CAE/E;;;;EAIE;;CCTF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA6BG;;CDhBH;;;;;;;;;;;;;;;;;;;EAmBE;;CAGF;;GAEG;;CACF,yDAAyD;;CAC1D,yEAAyE;;CAEzE;;GAEG;;CAOH;;EAEE;;;KAGG;;EAQH;;;;IAIE,CAIwB,oBAAoB,CAGhB,0CAA0C;;EAGxE;;IAEE;;EAOF;;KAEG;;EAOH;;;IAGE,CAWwB,oBAAoB;;;EAU9C;;;;IAIE;;EAOF,kBAAkB;;EAYlB,+CAA+C;;EAsB/C,0BAA0B;EAa1B;4EAC0E;EAE1E;wEACsE;;EAGtE,8BAA8B;;EAK9B,6BAA6B;;EAI7B,6BAA6B;CAQ9B;;CEzMD;;GAEG;;CAEH;;;;GAIG;;CCRH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BE;;CAEF;;;GAGG;;CAEH;EACE,qBAAc;EAAd,qBAAc;EAAd,cAAc;EACd,0BAA0B;EAC1B,uBAAuB;EACvB,sBAAsB;EACtB,kBAAkB;CACnB;;CAGD;EACE,+BAAoB;EAApB,8BAAoB;MAApB,wBAAoB;UAApB,oBAAoB;CACrB;;CAGD;EACE,6BAAuB;EAAvB,8BAAuB;MAAvB,2BAAuB;UAAvB,uBAAuB;CACxB;;CAGD;EACE,UAAU;EACV,WAAW;EACX,qBAAc;EAAd,qBAAc;EAAd,cAAc;EACd,oBAAe;MAAf,mBAAe;UAAf,eAAe;EACf,sBAAsB;CACvB;;CAGD;EACE,+BAAoB;EAApB,8BAAoB;MAApB,wBAAoB;UAApB,oBAAoB;CACrB;;CAGD;EACE,6BAAuB;EAAvB,8BAAuB;MAAvB,2BAAuB;UAAvB,uBAAuB;CACxB;;CAGD;EACE,qBAAc;EAAd,qBAAc;EAAd,cAAc;EACd,+BAAoB;EAApB,8BAAoB;MAApB,wBAAoB;UAApB,oBAAoB;EACpB,+BAAuB;UAAvB,uBAAuB;EACvB,iBAAiB;CAClB;;CAGD;;EAEE,oBAAe;MAAf,mBAAe;UAAf,eAAe;CAChB;;CAGD;EACE,oBAAe;MAAf,mBAAe;UAAf,eAAe;EACf,iBAAiB;EACjB,oBAAoB;CACrB;;CAGD;EACE,yBAAyB;CAC1B;;CAGD;EACE,mBAAmB;CACpB;;CAGD;EACE,QAAQ;EACR,oCAA4B;EAA5B,4BAA4B;CAC7B;;CAGD;EACE,OAAO;EACP,mCAA2B;EAA3B,2BAA2B;CAC5B;;CAGD;EACE,yBAAiB;EAAjB,iBAAiB;CAClB;;CAED,oBAAoB;;CD9GpB,QAUqC,oCAAoC;;IA2BrE,+BAA+B;CAIlC;;CAED;IACI,YAAiC;IACjC,+BAAuB;YAAvB,uBAAuB;IACvB,aAA+B;IAC/B,kBAAkB;CACrB;;CAED;IACI,kBAA6C;IAC7C,aAAwC;CAC3C;;CAED;IACI,eAAe;IACf,gBAAgB;CACnB;;CAED,mBAAmB;;CAEnB;IACI,wBAAwB;IACxB,+BAAuB;YAAvB,uBAAuB;IACvB,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,+BAAoB;IAApB,8BAAoB;QAApB,wBAAoB;YAApB,oBAAoB;IACpB,4BAAsB;QAAtB,yBAAsB;YAAtB,sBAAsB;CACzB;;CAED;IACI,sBAAsB;IACtB,+BAAuB;YAAvB,uBAAuB;IACvB,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;IACvB,0BAAoB;QAApB,uBAAoB;YAApB,oBAAoB;CACvB;;CAED;IACI,+BAAuB;YAAvB,uBAAuB;IACvB,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,UAAU;IACV,eAAe;CAClB;;CAED;IACI,+BAAuB;YAAvB,uBAAuB;IACvB,cAAc;IACd,UAAU;IACV,eAAe;CAClB;;CAED;IACI,+BAAoB;IAApB,8BAAoB;QAApB,wBAAoB;YAApB,oBAAoB;CACvB;;CAED;IACI,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;CAC1B;;CAED,4BAA4B;;CAE5B;IACI,mBAAmB;IACnB,oBAAoB;IACpB,iBAAiB;IACjB,oBAAoB;IACpB,sBAAsB;IACtB,oBAAoB;IACpB,iBAAiB;IACjB,wBAAwB;IACxB,mBAAmB;IACnB,gBAAuC;IACvC,gBAAgB;;IAEhB,aAAwC;IACxC,kBAAkB;IAClB,kBAA6C;IAC7C,yBAAiB;YAAjB,iBAAiB;;IAEjB,yBAAgC;IAChC,0BAA0C;IAC1C,sBAAsC;IACtC,aAAa;CAChB;;CAED;IACI,kBAA8C;IAC9C,qBAAqB;CACxB;;CAED;IACI,iBAAiB,CAAC,sBAAsB;CAC3C;;CAED;IACI,aAA4C;CAC/C;;CAED;IACI,gBAAgB;CACnB;;CAED;IACI,wBAAwB;IACxB;;+CAE+E;YAF/E;;+CAE+E;CAClF;;CAED;IACI,wBAAwB;IACxB;;iDAE6E;YAF7E;;iDAE6E;IAC7E,yBAAgC;IAChC,0BAA0C;CAC7C;;CAED;IACI,2BAA8D;CACjE;;CAED,8BAA8B;;CAE9B;IACI,gCAAwC;IACxC,0BAAyC;CAC5C;;CAED;IACI,8BAAwC;IACxC,0BAAyC;CAC5C;;CAED;IACI,8BAAwC;IACxC,0BAAyC;CAC5C;;CAED,8BAA8B;;CAE9B;IACI,gCAAwC;IACxC,0BAA2C;CAC9C;;CAED;IACI,8BAAwC;IACxC,0BAA2C;EAC7C;;CAEF;IACI,8BAAwC;IACxC,0BAA2C;EAC7C;;CAED,2BAA2B;;CAE5B;IACI,gCAAwC;IACxC,0BAAwC;CAC3C;;CAED;IACI,8BAAwC;IACxC,0BAAwC;CAC3C;;CAED;IACI,8BAAwC;IACxC,0BAAwC;CAC3C;;CAED,8BAA8B;;CAE9B;IACI,gCAAwC;IACxC,0BAAwC;CAC3C;;CAED;IACI,8BAAwC;IACxC,0BAAwC;CAC3C;;CAED;IACI,8BAAwC;IACxC,0BAAwC;CAC3C;;CAED,6BAA6B;;CAE7B;IACI,gCAAwC;IACxC,0BAAyC;CAC5C;;CAED;IACI,8BAAwC;IACxC,0BAAyC;CAC5C;;CAED;IACI,8BAAwC;IACxC,0BAAyC;CAC5C;;CAED,kBAAkB;;CAElB;IACI,aAA4C;CAC/C;;CAED,0BAA0B;;CAE1B,kCAAkC;;CAClC;IACI,iBAAuB;IAAvB,uBAAuB;CAC1B;;CAED;IACI,iBAAiB;IACjB,aAAqC;IACrC,gBAAuC;IACvC,iBAAiB;IACjB,wBAAwB;IACxB,oBAAoB;IACpB,kBAA6C;CAChD;;CAED;IACI,WAAW;IACX,aAAqC;IACrC,gBAAuC;IACvC,iBAAiB;IACjB,wBAAwB;IACxB,oBAAoB;IACpB,kBAA6C;CAChD;;CAED;IACI,6BAA6B;IAC7B,aAAqC;IACrC,kBAAkB;IAClB,kBAA0D;IAC1D,YAA4C;IAC5C,qBAAe;QAAf,eAAe;CAClB;;CAED;IACI,2BAA2B;IAC3B,aAAqC;IACrC,mBAAmB;IACnB,kBAA6C;CAChD;;CAED,4BAA4B;;CAE5B;IACI,aAAuC;IACvC,gBAAuC;IACvC,aAAwC;IACxC,kBAA6C;IAC7C,iBAAiB;IACjB,oBAAoB;IACpB,mBAAmB;CACtB;;CAED;IACI,yBAAyB;;IAEzB;;;;OAIG;IACH;;uDAEoD;;IAMpD;;+CAE4C;CAC/C;;CAED;IACI,wBAAwB;IACxB,mBAAmB;IACnB,iBAAgD;IAChD,gBAA+C;IAC/C,iBAA6C;CAChD;;CAED;IACI,sBAAsB;IACtB,gBAA4C;IAC5C,2BAA2B;IAC3B,eAAe;CAClB;;CAED,6BAA6B;;CAE7B;IACI,aAAsC;IACtC,aAAwC;IACxC,kBAA6C;CAChD;;CAED;IACI,wBAAgE;IAChE,kBAA6C;IAC7C,iBAAiB;IACjB,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,qBAAe;QAAf,eAAe;IACf,4BAAmB;QAAnB,mBAAmB;CACtB;;CAED,0BAA0B;;CAE1B;IACI,aAAwC;IACxC,kBAA6C;IAC7C,aAA4C;IAC5C,gBAAuC;CAC1C;;CAED;IACI,kBAA6C;IAC7C,kBAA8C;IAC9C,iBAA6C;;IAE7C,0JAA0J;IAC1J,sBAAsB;IACtB,8CAA8C;IAC9C,mBAAmB;IACnB,qBAAqB;IACrB,oCAAoC;IACpC,mCAAmC;CACtC;;CAED;IACI,iBAAiB;IACjB,aAAa;CAChB;;CAED;IACI,iBAAiB;IACjB,WAAW;CACd;;CAED;IACI,cAAc;CACjB;;CAED,qCAAqC;;CAErC;IACI,aAAsC;CACzC;;CAED;IACI,aAAwC;IACxC,kBAA6C;CAChD;;CAED;IACI,aAA4C;CAC/C;;CAED;IACI,+BAAuB;YAAvB,uBAAuB;IACvB,0BAAwF;IACxF,wBAA2D;IAC3D,yBAAqC;IACrC,gBAAuC;IACvC,iBAAsF;IACtF,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,aAAa,CAAC,iEAAiE;IAC/E,qBAAe;QAAf,eAAe;IACf,yBAAyB;CAC5B;;CAED;IACI,gBAAgB;IAChB,eAAe;CAClB;;CAED;IACI,sBAAyD;CAC5D;;CAED,mBAAmB;;CAEnB;IACI,kBAAkB;IAClB,0BAA4E;IAC5E,oBAAoC;IACpC,+BAAuB;YAAvB,uBAAuB;IACvB,mBAAmB;IACnB,mBAAmB;CACtB;;CAED;IACI,mBAAmB;IACnB,yBAAyB,CAAC,oDAAoD;IAC9E,mBAAmB;IACnB,wBAAmE;IACnE,0BAAiG;IACjG,+BAAuB;YAAvB,uBAAuB;IACvB,WAAW;IACX,uBAAuB,CAAC,wBAAwB;CACnD;;CAED,wBAAwB;;CACxB;IACI,0BAA+D;IAC/D,0BAAiG;CACpG;;CAED;IACI,0BAA+D;IAC/D,sBAA2D;IAC3D,WAAW;IACX,8BAAsB;YAAtB,sBAAsB;CACzB;;CAED;IACI,iEAAiE;IACjE,mBAAmB;IACnB,oBAAyD;IACzD,WAAW;CACd;;CAED,8BAA8B;;CAE9B;IACI,YAA4C;IAC5C,aAA6C;IAC7C,iBAAgJ;IAChJ,kBAAqG;IACrG,mBAAmB;IACnB,OAAO;CACV;;CAED;IACI,YAA4C;IAC5C,aAA6C;IAC7C,oBAAuG;IACvG,kBAAiJ;IACjJ,mBAAmB;IACnB,QAAQ;CACX;;CAED;IACI,YAA6D;IAC7D,iBAAyJ;CAC5J;;CAED;IACI,WAA4D;IAC5D,kBAA0J;CAC7J;;CAED,uBAAuB;;CAEvB;IACI,aAAsC;IACtC,aAAwC;IACxC,kBAA6C;;IAE7C;;oDAEgD;IAChD,0BAAoB;QAApB,uBAAoB;YAApB,oBAAoB;CACvB;;CAED;IACI,kBAAkB;CACrB;;CAED;IACI,aAAwC;IACxC,iBAAwG;IACxG,kBAAyG;IACzG,oBAA+C;QAA/C,oBAA+C;YAA/C,gBAA+C;CAClD;;CAED;IACI,gCAAgC;IAChC,YAAiD;IACjD,iBAAmG;IACnG,YAAY;CACf;;CAED,qBAAqB;;CAErB;IACI,aAAwC;IACxC,kBAA6C;CAChD;;CAED;IACI,qBAAqB;IACrB,cAA0C;IAC1C,YAA2C;CAC9C;;CAED;IACI,oBAA+C;QAA/C,oBAA+C;YAA/C,gBAA+C;IAC/C,kBAAkB;IAClB,mBAAmB;IACnB,mBAA0G;IAC1G,gBAAuG;IACvG,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;CAC1B;;CAED;IACI,gCAAgC;IAChC,WAAgD;IAChD,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,kBAAkB;IAClB,mBAAmB;CACtB;;CAED,6BAA6B;;CAE7B;IACI,yBAAyB;IAIzB,iBAAiB;CACpB;;CAED;IACI,aAAwC;CAC3C;;CAED;IACI,0BAAyC;CAC5C;;CAED;IACI,0BAA2C;CAC9C;;CAED;IACI,0BAAwC;CAC3C;;CAED;IACI,0BAAwC;CAC3C;;CAED;IACI,0BAAyC;CAC5C;;CAED;IACI,0BAA0C;IAC1C,aAAa;IACb,yBAAiB;YAAjB,iBAAiB;CACpB;;CAED,yBAAyB;;CAEzB;IACI,kBAAkB;IAClB,aAAwC;IACxC,kBAA6C;IAC7C,aAAsC;IACtC,0BAAoB;QAApB,uBAAoB;YAApB,oBAAoB;;CAEvB;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,gBAA4C;IAC5C,mBAA+C;IAC/C,6BAAoB;QAApB,oBAAoB;IACpB,8BAA8B;IAC9B,aAAgB;IAAhB,gBAAgB;CACnB;;CAED,uBAAuB;;CAEvB;IACI,cAA0C;IAC1C,YAA2C;CAC9C;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,YAA4C;IAC5C,kBAAkB;IAClB,mBAAmB;IACnB,iBAAiB;CACpB;;CAED,2BAA2B;;CAE3B;IACI,aAAwC;IACxC,aAAsC;IACtC,kBAA6C;CAChD;;CAED;IACI,oBAAoB;IACpB,0BAAwF;IACxF,iBAAiB;IACjB,gBAAgB;IAChB,oBAA+C;QAA/C,oBAA+C;YAA/C,gBAA+C;IAC/C,aAAa,CAAC,iEAAiE;IAC/E,+BAAuB;YAAvB,uBAAuB;IACvB,yBAAyB;IACzB,yBAAiB;YAAjB,iBAAiB;IACjB,wBAA2D;IAC3D,yBAAqC;IACrC,gBAAuC;IACvC,oBAAoB;IACpB,kBAAyD;CAC5D,iBAAiB;CACjB,yBAAyB;CACzB,sBAAsB;IACnB,6BAA6B;CAChC,sBAAsB;CACtB,kCAAkC;IAC/B,kuBAAmD;CACtD;;CACD;IACI,sBAAyD;CAC5D;;CAED;IACI,aAA4C;CAC/C;;CAED;6CAC6C;;CAC7C;IACI,mBAAmB;IACnB,wBAAwB;CAC3B;;CAED,+BAA+B;;CAE/B;IACI,aAAsC;IACtC,kBAA6C;;IAE7C;;kEAE8D;IAC9D,yBAAwB;QAAxB,sBAAwB;YAAxB,wBAAwB;CAC3B;;CAED;IACI,0BAAwF;IACxF,wBAA2D;IAC3D,yBAAqC;IACrC,gBAAuC;IACvC,oBAA+C;QAA/C,oBAA+C;YAA/C,gBAA+C;IAC/C,yBAAyB;IACzB,eAAe;IACf,gBAAgB;;IAEhB;;kEAE8D;IAC9D,iBAAiB;CACpB;;CAED;IACI,sBAAyD;CAC5D;;CAED;IACI,kBAA8C;IAC9C,kBAA6C;IAC7C,kEAAkE;IAClE,0DAAiF;IACjF,6DAAoF;CACvF;;CAID,4BAA4B;;CAE5B;IACI,kBAA6C;CAChD;;CAED;IACI,iBAAsC;IACtC,kBAAuC;CAC1C;;CAED;IACI,aAA4C;CAC/C;;CAED,2BAA2B;;CAE3B;IACI,aAAsC;IACtC,kBAA6C;CAChD;;CAED;IACI,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;IACvB,2BAAqB;QAArB,wBAAqB;YAArB,qBAAqB;IACrB,+BAAuB;YAAvB,uBAAuB;IACvB,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,mBAA8D;CACjE;;CAED;IACI,aAA4C;IAC5C,kBAAiD;IACjD,gBAAuC;CAC1C;;CAED;IACI,aAA4C;IAC5C,kBAAiD;IACjD,oBAA4D;IAC5D,YAAY;CACf;;CAED,0BAA0B;;CAE1B;IACI,aAAsC;IACtC,aAAwC;IACxC,kBAA6C;CAChD;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,qBAAe;QAAf,eAAe;IACf,gBAA+C;CAClD;;CAED;IACI,YAAuC;IACvC,aAAwC;IACxC,eAAe,CAAC,6DAA6D;IAC7E,kBAAqD;IACrD,yBAAqC;IACrC,0BAAwF;IACxF,kBAAkB;IAClB,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,qBAAe;QAAf,eAAe;IACf,+BAAuB;YAAvB,uBAAuB;IACvB,6BAAoB;QAApB,oBAAoB;IACpB,yBAAyB;CAC5B;;CAED;IACI,+BAA6F;CAChG;;CAED;IACI,sBAAyD;CAC5D;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,yBAAyB;IACzB,aAAwC;IACxC,kBAA6C;IAC7C,kBAAqD;IACrD,yBAAqC;IACrC,0BAAwF;IACxF,gBAAuC;IACvC,iBAAsF;IACtF,aAAa,CAAC,iEAAiE;IAC/E,qBAAe;QAAf,eAAe;IACf,+BAAuB;YAAvB,uBAAuB;CAC1B;;CAED;IACI,aAA4C;CAC/C;;CAED,yBAAyB;;CAEzB;IACI,aAAsC;IACtC,aAAwC;IACxC,kBAA6C;CAChD;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,qBAAe;QAAf,eAAe;IACf,aAAa,CAAC,iEAAiE;IAC/E,yBAAyB;IACzB,aAAwC;IACxC,0BAAwF;IACxF,wBAA2D;IAC3D,yBAAqC;IACrC,gBAAuC;IACvC,iBAAsF;IACtF,+BAAuB;YAAvB,uBAAuB;CAC1B;;CAED;IACI,sBAAyD;CAC5D;;CAED;IACI,sBAAoC;CACvC;;CAED;IACI,aAA4C;CAC/C;;CAED,iBAAiB;;CAEjB;IACI,aAA4C;IAC5C,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,2BAAqB;QAArB,wBAAqB;YAArB,qBAAqB;CACxB;;CAED;IACI,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,aAAa;CAChB;;CAED;IACI,aAA4C;CAC/C;;CAED,gBAAgB;;CAEhB;IACI,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;CAC1B;;CAED;IACI,yFAAyF;IACzF,oBAAoB;IACpB,oBAAoB;CACvB;;CAED;IACI,iDAAiD;IACjD,uBAAsB;QAAtB,oBAAsB;YAAtB,sBAAsB;IACtB,aAAa;IACb,cAAc;CACjB;;CAED;IACI,YAAY;IACZ,+BAAuB;YAAvB,uBAAuB;IACvB,UAAU;IACV,kBAAoC;IACpC,yBAAgC;IAChC,0BAA6D;IAC7D,cAA6C;IAC7C,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,eAAe;CAClB;;CAED;IACI,wCAA+D;IAC/D,iBAAmF;CACtF;;CAED;IACI,oBAAiD;QAAjD,oBAAiD;YAAjD,gBAAiD;IACjD,gBAAgB;IAChB,iBAAmF;IACnF,kBAAqD;IACrD,kBAA+C;IAC/C,kBAAkB;IAClB,oBAAoC;IACpC,yBAAgC;IAChC,0BAA6D;IAC7D,oBAAoB;IACpB,mBAAmB;CACtB;;CAED;IACI,0BAAgC;IAChC,gEAAgE;IAChE,kBAAoC;IACpC,iBAAuF;IACvF,mCAA8C;YAA9C,2BAA8C;IAC9C,kBAAkB;CACrB;;CAED;IACI,mBAAmB;IACnB,UAAuC;IACvC,WAAwC;IACxC,YAAY;IACZ,YAAoD;IACpD,wBAA+C;IAC/C,oBAAmC;CACtC;;CAED;IACI,eAAe;CAClB;;CAED;IACI,kBAAoC;IACpC,yBAAgC;CACnC;;CAED;IACI,iBAAiB;CACpB;;CAED;IACI,yBAAyB;IACzB,iBAAiB,CAAC,WAAW;CAChC;;CAED;;;IAGI,kBAAqD;CACxD;;CAED,sBAAsB;;CAEtB;IACI,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;IACvB,2BAAqB;QAArB,wBAAqB;YAArB,qBAAqB;CACxB;;CAED;IACI,aAAyC;IACzC,gBAAgB;IAChB,yBAAgC;IAChC,0BAA0C;IAC1C,0BAAqE;IACrE,mBAA+F;IAC/F,kBAAkB;CACrB;;CAED;IACI,wBAA0C;IAC1C,yBAAgC;CACnC;;CAED;IACI,wBAA0C;IAC1C,0BAAgC;IAChC,gBAAgB;IAChB,oBAAoB;CACvB;;CAED;IACI,sBAAsB,EAAE,qCAAqC;IAC7D,sBAAsB;IACtB,8CAA8C;IAC9C,mBAAmB;IACnB,qBAAqB;IACrB,oCAAoC;IACpC,mCAAmC;CACtC;;CAED;IACI,sBAAsB,CAAC,oCAAoC;CAC9D;;CAED;IACI,cAA6C;IAC7C,wBAA0C;IAC1C,yBAAgC;IAChC,+BAA0E;IAC1E,gCAA2E;IAC3E,iCAA4E;IAC5E,eAAe;CAClB;;CAED;IACI,qBAAc;IAAd,qBAAc;IAAd,cAAc;IACd,6BAAuB;IAAvB,8BAAuB;QAAvB,2BAAuB;YAAvB,uBAAuB;IACvB,2BAAqB;QAArB,wBAAqB;YAArB,qBAAqB;CACxB;;CAED;IACI,iBAAiB;CACpB;;CAED;IACI,gBAAgB;CACnB;;CAID,iBAAiB;;CAEjB;IACI,gBAAuC;CAC1C;;CAED;IACI,0CAA0C;IAC1C,6BAAoB;QAApB,oBAAoB;IACpB,oBAAa;QAAb,qBAAa;YAAb,aAAa;IACb,qBAAe;QAAf,eAAe;IACf,kEAAkE;IAClE,kBAA6C;IAC7C,yEAAyE;IACzE,mBAAmB;CACtB","file":"controls.css","sourcesContent":["/* Copyright (c) Jupyter Development Team.\n * Distributed under the terms of the Modified BSD License.\n */\n\n /* We import all of these together in a single css file because the Webpack\nloader sees only one file at a time. This allows postcss to see the variable\ndefinitions when they are used. */\n\n@import \"./labvariables.css\";\n@import \"./widgets-base.css\";\n","/*-----------------------------------------------------------------------------\n| Copyright (c) Jupyter Development Team.\n| Distributed under the terms of the Modified BSD License.\n|----------------------------------------------------------------------------*/\n\n/*\nThis file is copied from the JupyterLab project to define default styling for\nwhen the widget styling is compiled down to eliminate CSS variables. We make one\nchange - we comment out the font import below.\n*/\n\n@import \"./materialcolors.css\";\n\n/*\nThe following CSS variables define the main, public API for styling JupyterLab.\nThese variables should be used by all plugins wherever possible. In other\nwords, plugins should not define custom colors, sizes, etc unless absolutely\nnecessary. This enables users to change the visual theme of JupyterLab\nby changing these variables.\n\nMany variables appear in an ordered sequence (0,1,2,3). These sequences\nare designed to work well together, so for example, `--jp-border-color1` should\nbe used with `--jp-layout-color1`. The numbers have the following meanings:\n\n* 0: super-primary, reserved for special emphasis\n* 1: primary, most important under normal situations\n* 2: secondary, next most important under normal situations\n* 3: tertiary, next most important under normal situations\n\nThroughout JupyterLab, we are mostly following principles from Google's\nMaterial Design when selecting colors. We are not, however, following\nall of MD as it is not optimized for dense, information rich UIs.\n*/\n\n\n/*\n * Optional monospace font for input/output prompt.\n */\n /* Commented out in ipywidgets since we don't need it. */\n/* @import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); */\n\n/*\n * Added for compabitility with output area\n */\n:root {\n  --jp-icon-search: none;\n  --jp-ui-select-caret: none;\n}\n\n\n:root {\n\n  /* Borders\n\n  The following variables, specify the visual styling of borders in JupyterLab.\n   */\n\n  --jp-border-width: 1px;\n  --jp-border-color0: var(--md-grey-700);\n  --jp-border-color1: var(--md-grey-500);\n  --jp-border-color2: var(--md-grey-300);\n  --jp-border-color3: var(--md-grey-100);\n\n  /* UI Fonts\n\n  The UI font CSS variables are used for the typography all of the JupyterLab\n  user interface elements that are not directly user generated content.\n  */\n\n  --jp-ui-font-scale-factor: 1.2;\n  --jp-ui-font-size0: calc(var(--jp-ui-font-size1)/var(--jp-ui-font-scale-factor));\n  --jp-ui-font-size1: 13px; /* Base font size */\n  --jp-ui-font-size2: calc(var(--jp-ui-font-size1)*var(--jp-ui-font-scale-factor));\n  --jp-ui-font-size3: calc(var(--jp-ui-font-size2)*var(--jp-ui-font-scale-factor));\n  --jp-ui-icon-font-size: 14px; /* Ensures px perfect FontAwesome icons */\n  --jp-ui-font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n\n  /* Use these font colors against the corresponding main layout colors.\n     In a light theme, these go from dark to light.\n  */\n\n  --jp-ui-font-color0: rgba(0,0,0,1.0);\n  --jp-ui-font-color1: rgba(0,0,0,0.8);\n  --jp-ui-font-color2: rgba(0,0,0,0.5);\n  --jp-ui-font-color3: rgba(0,0,0,0.3);\n\n  /* Use these against the brand/accent/warn/error colors.\n     These will typically go from light to darker, in both a dark and light theme\n   */\n\n  --jp-inverse-ui-font-color0: rgba(255,255,255,1);\n  --jp-inverse-ui-font-color1: rgba(255,255,255,1.0);\n  --jp-inverse-ui-font-color2: rgba(255,255,255,0.7);\n  --jp-inverse-ui-font-color3: rgba(255,255,255,0.5);\n\n  /* Content Fonts\n\n  Content font variables are used for typography of user generated content.\n  */\n\n  --jp-content-font-size: 13px;\n  --jp-content-line-height: 1.5;\n  --jp-content-font-color0: black;\n  --jp-content-font-color1: black;\n  --jp-content-font-color2: var(--md-grey-700);\n  --jp-content-font-color3: var(--md-grey-500);\n\n  --jp-ui-font-scale-factor: 1.2;\n  --jp-ui-font-size0: calc(var(--jp-ui-font-size1)/var(--jp-ui-font-scale-factor));\n  --jp-ui-font-size1: 13px; /* Base font size */\n  --jp-ui-font-size2: calc(var(--jp-ui-font-size1)*var(--jp-ui-font-scale-factor));\n  --jp-ui-font-size3: calc(var(--jp-ui-font-size2)*var(--jp-ui-font-scale-factor));\n\n  --jp-code-font-size: 13px;\n  --jp-code-line-height: 1.307;\n  --jp-code-padding: 5px;\n  --jp-code-font-family: monospace;\n\n\n  /* Layout\n\n  The following are the main layout colors use in JupyterLab. In a light\n  theme these would go from light to dark.\n  */\n\n  --jp-layout-color0: white;\n  --jp-layout-color1: white;\n  --jp-layout-color2: var(--md-grey-200);\n  --jp-layout-color3: var(--md-grey-400);\n\n  /* Brand/accent */\n\n  --jp-brand-color0: var(--md-blue-700);\n  --jp-brand-color1: var(--md-blue-500);\n  --jp-brand-color2: var(--md-blue-300);\n  --jp-brand-color3: var(--md-blue-100);\n\n  --jp-accent-color0: var(--md-green-700);\n  --jp-accent-color1: var(--md-green-500);\n  --jp-accent-color2: var(--md-green-300);\n  --jp-accent-color3: var(--md-green-100);\n\n  /* State colors (warn, error, success, info) */\n\n  --jp-warn-color0: var(--md-orange-700);\n  --jp-warn-color1: var(--md-orange-500);\n  --jp-warn-color2: var(--md-orange-300);\n  --jp-warn-color3: var(--md-orange-100);\n\n  --jp-error-color0: var(--md-red-700);\n  --jp-error-color1: var(--md-red-500);\n  --jp-error-color2: var(--md-red-300);\n  --jp-error-color3: var(--md-red-100);\n\n  --jp-success-color0: var(--md-green-700);\n  --jp-success-color1: var(--md-green-500);\n  --jp-success-color2: var(--md-green-300);\n  --jp-success-color3: var(--md-green-100);\n\n  --jp-info-color0: var(--md-cyan-700);\n  --jp-info-color1: var(--md-cyan-500);\n  --jp-info-color2: var(--md-cyan-300);\n  --jp-info-color3: var(--md-cyan-100);\n\n  /* Cell specific styles */\n\n  --jp-cell-padding: 5px;\n  --jp-cell-editor-background: #f7f7f7;\n  --jp-cell-editor-border-color: #cfcfcf;\n  --jp-cell-editor-background-edit: var(--jp-ui-layout-color1);\n  --jp-cell-editor-border-color-edit: var(--jp-brand-color1);\n  --jp-cell-prompt-width: 100px;\n  --jp-cell-prompt-font-family: 'Roboto Mono', monospace;\n  --jp-cell-prompt-letter-spacing: 0px;\n  --jp-cell-prompt-opacity: 1.0;\n  --jp-cell-prompt-opacity-not-active: 0.4;\n  --jp-cell-prompt-font-color-not-active: var(--md-grey-700);\n  /* A custom blend of MD grey and blue 600\n   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */\n  --jp-cell-inprompt-font-color: #307FC1;\n  /* A custom blend of MD grey and orange 600\n   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */\n  --jp-cell-outprompt-font-color: #BF5B3D;\n\n  /* Notebook specific styles */\n\n  --jp-notebook-padding: 10px;\n  --jp-notebook-scroll-padding: 100px;\n\n  /* Console specific styles */\n\n  --jp-console-background: var(--md-grey-100);\n\n  /* Toolbar specific styles */\n\n  --jp-toolbar-border-color: var(--md-grey-400);\n  --jp-toolbar-micro-height: 8px;\n  --jp-toolbar-background: var(--jp-layout-color0);\n  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0,0,0,0.24);\n  --jp-toolbar-header-margin: 4px 4px 0px 4px;\n  --jp-toolbar-active-background: var(--md-grey-300);\n}\n","/**\n * The material design colors are adapted from google-material-color v1.2.6\n * https://github.com/danlevan/google-material-color\n * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/dist/palette.var.css\n *\n * The license for the material design color CSS variables is as follows (see\n * https://github.com/danlevan/google-material-color/blob/f67ca5f4028b2f1b34862f64b0ca67323f91b088/LICENSE)\n *\n * The MIT License (MIT)\n *\n * Copyright (c) 2014 Dan Le Van\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n */\n:root {\n  --md-red-50: #FFEBEE;\n  --md-red-100: #FFCDD2;\n  --md-red-200: #EF9A9A;\n  --md-red-300: #E57373;\n  --md-red-400: #EF5350;\n  --md-red-500: #F44336;\n  --md-red-600: #E53935;\n  --md-red-700: #D32F2F;\n  --md-red-800: #C62828;\n  --md-red-900: #B71C1C;\n  --md-red-A100: #FF8A80;\n  --md-red-A200: #FF5252;\n  --md-red-A400: #FF1744;\n  --md-red-A700: #D50000;\n\n  --md-pink-50: #FCE4EC;\n  --md-pink-100: #F8BBD0;\n  --md-pink-200: #F48FB1;\n  --md-pink-300: #F06292;\n  --md-pink-400: #EC407A;\n  --md-pink-500: #E91E63;\n  --md-pink-600: #D81B60;\n  --md-pink-700: #C2185B;\n  --md-pink-800: #AD1457;\n  --md-pink-900: #880E4F;\n  --md-pink-A100: #FF80AB;\n  --md-pink-A200: #FF4081;\n  --md-pink-A400: #F50057;\n  --md-pink-A700: #C51162;\n\n  --md-purple-50: #F3E5F5;\n  --md-purple-100: #E1BEE7;\n  --md-purple-200: #CE93D8;\n  --md-purple-300: #BA68C8;\n  --md-purple-400: #AB47BC;\n  --md-purple-500: #9C27B0;\n  --md-purple-600: #8E24AA;\n  --md-purple-700: #7B1FA2;\n  --md-purple-800: #6A1B9A;\n  --md-purple-900: #4A148C;\n  --md-purple-A100: #EA80FC;\n  --md-purple-A200: #E040FB;\n  --md-purple-A400: #D500F9;\n  --md-purple-A700: #AA00FF;\n\n  --md-deep-purple-50: #EDE7F6;\n  --md-deep-purple-100: #D1C4E9;\n  --md-deep-purple-200: #B39DDB;\n  --md-deep-purple-300: #9575CD;\n  --md-deep-purple-400: #7E57C2;\n  --md-deep-purple-500: #673AB7;\n  --md-deep-purple-600: #5E35B1;\n  --md-deep-purple-700: #512DA8;\n  --md-deep-purple-800: #4527A0;\n  --md-deep-purple-900: #311B92;\n  --md-deep-purple-A100: #B388FF;\n  --md-deep-purple-A200: #7C4DFF;\n  --md-deep-purple-A400: #651FFF;\n  --md-deep-purple-A700: #6200EA;\n\n  --md-indigo-50: #E8EAF6;\n  --md-indigo-100: #C5CAE9;\n  --md-indigo-200: #9FA8DA;\n  --md-indigo-300: #7986CB;\n  --md-indigo-400: #5C6BC0;\n  --md-indigo-500: #3F51B5;\n  --md-indigo-600: #3949AB;\n  --md-indigo-700: #303F9F;\n  --md-indigo-800: #283593;\n  --md-indigo-900: #1A237E;\n  --md-indigo-A100: #8C9EFF;\n  --md-indigo-A200: #536DFE;\n  --md-indigo-A400: #3D5AFE;\n  --md-indigo-A700: #304FFE;\n\n  --md-blue-50: #E3F2FD;\n  --md-blue-100: #BBDEFB;\n  --md-blue-200: #90CAF9;\n  --md-blue-300: #64B5F6;\n  --md-blue-400: #42A5F5;\n  --md-blue-500: #2196F3;\n  --md-blue-600: #1E88E5;\n  --md-blue-700: #1976D2;\n  --md-blue-800: #1565C0;\n  --md-blue-900: #0D47A1;\n  --md-blue-A100: #82B1FF;\n  --md-blue-A200: #448AFF;\n  --md-blue-A400: #2979FF;\n  --md-blue-A700: #2962FF;\n\n  --md-light-blue-50: #E1F5FE;\n  --md-light-blue-100: #B3E5FC;\n  --md-light-blue-200: #81D4FA;\n  --md-light-blue-300: #4FC3F7;\n  --md-light-blue-400: #29B6F6;\n  --md-light-blue-500: #03A9F4;\n  --md-light-blue-600: #039BE5;\n  --md-light-blue-700: #0288D1;\n  --md-light-blue-800: #0277BD;\n  --md-light-blue-900: #01579B;\n  --md-light-blue-A100: #80D8FF;\n  --md-light-blue-A200: #40C4FF;\n  --md-light-blue-A400: #00B0FF;\n  --md-light-blue-A700: #0091EA;\n\n  --md-cyan-50: #E0F7FA;\n  --md-cyan-100: #B2EBF2;\n  --md-cyan-200: #80DEEA;\n  --md-cyan-300: #4DD0E1;\n  --md-cyan-400: #26C6DA;\n  --md-cyan-500: #00BCD4;\n  --md-cyan-600: #00ACC1;\n  --md-cyan-700: #0097A7;\n  --md-cyan-800: #00838F;\n  --md-cyan-900: #006064;\n  --md-cyan-A100: #84FFFF;\n  --md-cyan-A200: #18FFFF;\n  --md-cyan-A400: #00E5FF;\n  --md-cyan-A700: #00B8D4;\n\n  --md-teal-50: #E0F2F1;\n  --md-teal-100: #B2DFDB;\n  --md-teal-200: #80CBC4;\n  --md-teal-300: #4DB6AC;\n  --md-teal-400: #26A69A;\n  --md-teal-500: #009688;\n  --md-teal-600: #00897B;\n  --md-teal-700: #00796B;\n  --md-teal-800: #00695C;\n  --md-teal-900: #004D40;\n  --md-teal-A100: #A7FFEB;\n  --md-teal-A200: #64FFDA;\n  --md-teal-A400: #1DE9B6;\n  --md-teal-A700: #00BFA5;\n\n  --md-green-50: #E8F5E9;\n  --md-green-100: #C8E6C9;\n  --md-green-200: #A5D6A7;\n  --md-green-300: #81C784;\n  --md-green-400: #66BB6A;\n  --md-green-500: #4CAF50;\n  --md-green-600: #43A047;\n  --md-green-700: #388E3C;\n  --md-green-800: #2E7D32;\n  --md-green-900: #1B5E20;\n  --md-green-A100: #B9F6CA;\n  --md-green-A200: #69F0AE;\n  --md-green-A400: #00E676;\n  --md-green-A700: #00C853;\n\n  --md-light-green-50: #F1F8E9;\n  --md-light-green-100: #DCEDC8;\n  --md-light-green-200: #C5E1A5;\n  --md-light-green-300: #AED581;\n  --md-light-green-400: #9CCC65;\n  --md-light-green-500: #8BC34A;\n  --md-light-green-600: #7CB342;\n  --md-light-green-700: #689F38;\n  --md-light-green-800: #558B2F;\n  --md-light-green-900: #33691E;\n  --md-light-green-A100: #CCFF90;\n  --md-light-green-A200: #B2FF59;\n  --md-light-green-A400: #76FF03;\n  --md-light-green-A700: #64DD17;\n\n  --md-lime-50: #F9FBE7;\n  --md-lime-100: #F0F4C3;\n  --md-lime-200: #E6EE9C;\n  --md-lime-300: #DCE775;\n  --md-lime-400: #D4E157;\n  --md-lime-500: #CDDC39;\n  --md-lime-600: #C0CA33;\n  --md-lime-700: #AFB42B;\n  --md-lime-800: #9E9D24;\n  --md-lime-900: #827717;\n  --md-lime-A100: #F4FF81;\n  --md-lime-A200: #EEFF41;\n  --md-lime-A400: #C6FF00;\n  --md-lime-A700: #AEEA00;\n\n  --md-yellow-50: #FFFDE7;\n  --md-yellow-100: #FFF9C4;\n  --md-yellow-200: #FFF59D;\n  --md-yellow-300: #FFF176;\n  --md-yellow-400: #FFEE58;\n  --md-yellow-500: #FFEB3B;\n  --md-yellow-600: #FDD835;\n  --md-yellow-700: #FBC02D;\n  --md-yellow-800: #F9A825;\n  --md-yellow-900: #F57F17;\n  --md-yellow-A100: #FFFF8D;\n  --md-yellow-A200: #FFFF00;\n  --md-yellow-A400: #FFEA00;\n  --md-yellow-A700: #FFD600;\n\n  --md-amber-50: #FFF8E1;\n  --md-amber-100: #FFECB3;\n  --md-amber-200: #FFE082;\n  --md-amber-300: #FFD54F;\n  --md-amber-400: #FFCA28;\n  --md-amber-500: #FFC107;\n  --md-amber-600: #FFB300;\n  --md-amber-700: #FFA000;\n  --md-amber-800: #FF8F00;\n  --md-amber-900: #FF6F00;\n  --md-amber-A100: #FFE57F;\n  --md-amber-A200: #FFD740;\n  --md-amber-A400: #FFC400;\n  --md-amber-A700: #FFAB00;\n\n  --md-orange-50: #FFF3E0;\n  --md-orange-100: #FFE0B2;\n  --md-orange-200: #FFCC80;\n  --md-orange-300: #FFB74D;\n  --md-orange-400: #FFA726;\n  --md-orange-500: #FF9800;\n  --md-orange-600: #FB8C00;\n  --md-orange-700: #F57C00;\n  --md-orange-800: #EF6C00;\n  --md-orange-900: #E65100;\n  --md-orange-A100: #FFD180;\n  --md-orange-A200: #FFAB40;\n  --md-orange-A400: #FF9100;\n  --md-orange-A700: #FF6D00;\n\n  --md-deep-orange-50: #FBE9E7;\n  --md-deep-orange-100: #FFCCBC;\n  --md-deep-orange-200: #FFAB91;\n  --md-deep-orange-300: #FF8A65;\n  --md-deep-orange-400: #FF7043;\n  --md-deep-orange-500: #FF5722;\n  --md-deep-orange-600: #F4511E;\n  --md-deep-orange-700: #E64A19;\n  --md-deep-orange-800: #D84315;\n  --md-deep-orange-900: #BF360C;\n  --md-deep-orange-A100: #FF9E80;\n  --md-deep-orange-A200: #FF6E40;\n  --md-deep-orange-A400: #FF3D00;\n  --md-deep-orange-A700: #DD2C00;\n\n  --md-brown-50: #EFEBE9;\n  --md-brown-100: #D7CCC8;\n  --md-brown-200: #BCAAA4;\n  --md-brown-300: #A1887F;\n  --md-brown-400: #8D6E63;\n  --md-brown-500: #795548;\n  --md-brown-600: #6D4C41;\n  --md-brown-700: #5D4037;\n  --md-brown-800: #4E342E;\n  --md-brown-900: #3E2723;\n\n  --md-grey-50: #FAFAFA;\n  --md-grey-100: #F5F5F5;\n  --md-grey-200: #EEEEEE;\n  --md-grey-300: #E0E0E0;\n  --md-grey-400: #BDBDBD;\n  --md-grey-500: #9E9E9E;\n  --md-grey-600: #757575;\n  --md-grey-700: #616161;\n  --md-grey-800: #424242;\n  --md-grey-900: #212121;\n\n  --md-blue-grey-50: #ECEFF1;\n  --md-blue-grey-100: #CFD8DC;\n  --md-blue-grey-200: #B0BEC5;\n  --md-blue-grey-300: #90A4AE;\n  --md-blue-grey-400: #78909C;\n  --md-blue-grey-500: #607D8B;\n  --md-blue-grey-600: #546E7A;\n  --md-blue-grey-700: #455A64;\n  --md-blue-grey-800: #37474F;\n  --md-blue-grey-900: #263238;\n}","/* Copyright (c) Jupyter Development Team.\n * Distributed under the terms of the Modified BSD License.\n */\n\n/*\n * We assume that the CSS variables in\n * https://github.com/jupyterlab/jupyterlab/blob/master/src/default-theme/variables.css\n * have been defined.\n */\n\n@import \"./phosphor.css\";\n\n:root {\n    --jp-widgets-color: var(--jp-content-font-color1);\n    --jp-widgets-label-color: var(--jp-widgets-color);\n    --jp-widgets-readout-color: var(--jp-widgets-color);\n    --jp-widgets-font-size: var(--jp-ui-font-size1);\n    --jp-widgets-margin: 2px;\n    --jp-widgets-inline-height: 28px;\n    --jp-widgets-inline-width: 300px;\n    --jp-widgets-inline-width-short: calc(var(--jp-widgets-inline-width) / 2 - var(--jp-widgets-margin));\n    --jp-widgets-inline-width-tiny: calc(var(--jp-widgets-inline-width-short) / 2 - var(--jp-widgets-margin));\n    --jp-widgets-inline-margin: 4px; /* margin between inline elements */\n    --jp-widgets-inline-label-width: 80px;\n    --jp-widgets-border-width: var(--jp-border-width);\n    --jp-widgets-vertical-height: 200px;\n    --jp-widgets-horizontal-tab-height: 24px;\n    --jp-widgets-horizontal-tab-width: 144px;\n    --jp-widgets-horizontal-tab-top-border: 2px;\n    --jp-widgets-progress-thickness: 20px;\n    --jp-widgets-container-padding: 15px;\n    --jp-widgets-input-padding: 4px;\n    --jp-widgets-radio-item-height-adjustment: 8px;\n    --jp-widgets-radio-item-height: calc(var(--jp-widgets-inline-height) - var(--jp-widgets-radio-item-height-adjustment));\n    --jp-widgets-slider-track-thickness: 4px;\n    --jp-widgets-slider-border-width: var(--jp-widgets-border-width);\n    --jp-widgets-slider-handle-size: 16px;\n    --jp-widgets-slider-handle-border-color: var(--jp-border-color1);\n    --jp-widgets-slider-handle-background-color: var(--jp-layout-color1);\n    --jp-widgets-slider-active-handle-color: var(--jp-brand-color1);\n    --jp-widgets-menu-item-height: 24px;\n    --jp-widgets-dropdown-arrow: url(\"data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDE5LjIuMSwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCAxOCAxOCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgMTggMTg7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KCS5zdDB7ZmlsbDpub25lO30KPC9zdHlsZT4KPHBhdGggZD0iTTUuMiw1LjlMOSw5LjdsMy44LTMuOGwxLjIsMS4ybC00LjksNWwtNC45LTVMNS4yLDUuOXoiLz4KPHBhdGggY2xhc3M9InN0MCIgZD0iTTAtMC42aDE4djE4SDBWLTAuNnoiLz4KPC9zdmc+Cg\");\n    --jp-widgets-input-color: var(--jp-ui-font-color1);\n    --jp-widgets-input-background-color: var(--jp-layout-color1);\n    --jp-widgets-input-border-color: var(--jp-border-color1);\n    --jp-widgets-input-focus-border-color: var(--jp-brand-color2);\n    --jp-widgets-input-border-width: var(--jp-widgets-border-width);\n    --jp-widgets-disabled-opacity: 0.6;\n\n    /* From Material Design Lite */\n    --md-shadow-key-umbra-opacity: 0.2;\n    --md-shadow-key-penumbra-opacity: 0.14;\n    --md-shadow-ambient-shadow-opacity: 0.12;\n}\n\n.jupyter-widgets {\n    margin: var(--jp-widgets-margin);\n    box-sizing: border-box;\n    color: var(--jp-widgets-color);\n    overflow: visible;\n}\n\n.jupyter-widgets.jupyter-widgets-disconnected::before {\n    line-height: var(--jp-widgets-inline-height);\n    height: var(--jp-widgets-inline-height);\n}\n\n.jp-Output-result > .jupyter-widgets {\n    margin-left: 0;\n    margin-right: 0;\n}\n\n/* vbox and hbox */\n\n.widget-inline-hbox {\n    /* Horizontal widgets */\n    box-sizing: border-box;\n    display: flex;\n    flex-direction: row;\n    align-items: baseline;\n}\n\n.widget-inline-vbox {\n    /* Vertical Widgets */\n    box-sizing: border-box;\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n}\n\n.widget-box {\n    box-sizing: border-box;\n    display: flex;\n    margin: 0;\n    overflow: auto;\n}\n\n.widget-gridbox {\n    box-sizing: border-box;\n    display: grid;\n    margin: 0;\n    overflow: auto;\n}\n\n.widget-hbox {\n    flex-direction: row;\n}\n\n.widget-vbox {\n    flex-direction: column;\n}\n\n/* General Button Styling */\n\n.jupyter-button {\n    padding-left: 10px;\n    padding-right: 10px;\n    padding-top: 0px;\n    padding-bottom: 0px;\n    display: inline-block;\n    white-space: nowrap;\n    overflow: hidden;\n    text-overflow: ellipsis;\n    text-align: center;\n    font-size: var(--jp-widgets-font-size);\n    cursor: pointer;\n\n    height: var(--jp-widgets-inline-height);\n    border: 0px solid;\n    line-height: var(--jp-widgets-inline-height);\n    box-shadow: none;\n\n    color: var(--jp-ui-font-color1);\n    background-color: var(--jp-layout-color2);\n    border-color: var(--jp-border-color2);\n    border: none;\n}\n\n.jupyter-button i.fa {\n    margin-right: var(--jp-widgets-inline-margin);\n    pointer-events: none;\n}\n\n.jupyter-button:empty:before {\n    content: \"\\200b\"; /* zero-width space */\n}\n\n.jupyter-widgets.jupyter-button:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n.jupyter-button i.fa.center {\n    margin-right: 0;\n}\n\n.jupyter-button:hover:enabled, .jupyter-button:focus:enabled {\n    /* MD Lite 2dp shadow */\n    box-shadow: 0 2px 2px 0 rgba(0, 0, 0, var(--md-shadow-key-penumbra-opacity)),\n                0 3px 1px -2px rgba(0, 0, 0, var(--md-shadow-key-umbra-opacity)),\n                0 1px 5px 0 rgba(0, 0, 0, var(--md-shadow-ambient-shadow-opacity));\n}\n\n.jupyter-button:active, .jupyter-button.mod-active {\n    /* MD Lite 4dp shadow */\n    box-shadow: 0 4px 5px 0 rgba(0, 0, 0, var(--md-shadow-key-penumbra-opacity)),\n                0 1px 10px 0 rgba(0, 0, 0, var(--md-shadow-ambient-shadow-opacity)),\n                0 2px 4px -1px rgba(0, 0, 0, var(--md-shadow-key-umbra-opacity));\n    color: var(--jp-ui-font-color1);\n    background-color: var(--jp-layout-color3);\n}\n\n.jupyter-button:focus:enabled {\n    outline: 1px solid var(--jp-widgets-input-focus-border-color);\n}\n\n/* Button \"Primary\" Styling */\n\n.jupyter-button.mod-primary {\n    color: var(--jp-inverse-ui-font-color1);\n    background-color: var(--jp-brand-color1);\n}\n\n.jupyter-button.mod-primary.mod-active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-brand-color0);\n}\n\n.jupyter-button.mod-primary:active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-brand-color0);\n}\n\n/* Button \"Success\" Styling */\n\n.jupyter-button.mod-success {\n    color: var(--jp-inverse-ui-font-color1);\n    background-color: var(--jp-success-color1);\n}\n\n.jupyter-button.mod-success.mod-active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-success-color0);\n }\n\n.jupyter-button.mod-success:active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-success-color0);\n }\n\n /* Button \"Info\" Styling */\n\n.jupyter-button.mod-info {\n    color: var(--jp-inverse-ui-font-color1);\n    background-color: var(--jp-info-color1);\n}\n\n.jupyter-button.mod-info.mod-active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-info-color0);\n}\n\n.jupyter-button.mod-info:active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-info-color0);\n}\n\n/* Button \"Warning\" Styling */\n\n.jupyter-button.mod-warning {\n    color: var(--jp-inverse-ui-font-color1);\n    background-color: var(--jp-warn-color1);\n}\n\n.jupyter-button.mod-warning.mod-active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-warn-color0);\n}\n\n.jupyter-button.mod-warning:active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-warn-color0);\n}\n\n/* Button \"Danger\" Styling */\n\n.jupyter-button.mod-danger {\n    color: var(--jp-inverse-ui-font-color1);\n    background-color: var(--jp-error-color1);\n}\n\n.jupyter-button.mod-danger.mod-active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-error-color0);\n}\n\n.jupyter-button.mod-danger:active {\n    color: var(--jp-inverse-ui-font-color0);\n    background-color: var(--jp-error-color0);\n}\n\n/* Widget Button*/\n\n.widget-button, .widget-toggle-button {\n    width: var(--jp-widgets-inline-width-short);\n}\n\n/* Widget Label Styling */\n\n/* Override Bootstrap label css */\n.jupyter-widgets label {\n    margin-bottom: initial;\n}\n\n.widget-label-basic {\n    /* Basic Label */\n    color: var(--jp-widgets-label-color);\n    font-size: var(--jp-widgets-font-size);\n    overflow: hidden;\n    text-overflow: ellipsis;\n    white-space: nowrap;\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-label {\n    /* Label */\n    color: var(--jp-widgets-label-color);\n    font-size: var(--jp-widgets-font-size);\n    overflow: hidden;\n    text-overflow: ellipsis;\n    white-space: nowrap;\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-inline-hbox .widget-label {\n    /* Horizontal Widget Label */\n    color: var(--jp-widgets-label-color);\n    text-align: right;\n    margin-right: calc( var(--jp-widgets-inline-margin) * 2 );\n    width: var(--jp-widgets-inline-label-width);\n    flex-shrink: 0;\n}\n\n.widget-inline-vbox .widget-label {\n    /* Vertical Widget Label */\n    color: var(--jp-widgets-label-color);\n    text-align: center;\n    line-height: var(--jp-widgets-inline-height);\n}\n\n/* Widget Readout Styling */\n\n.widget-readout {\n    color: var(--jp-widgets-readout-color);\n    font-size: var(--jp-widgets-font-size);\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n    overflow: hidden;\n    white-space: nowrap;\n    text-align: center;\n}\n\n.widget-readout.overflow {\n    /* Overflowing Readout */\n\n    /* From Material Design Lite\n        shadow-key-umbra-opacity: 0.2;\n        shadow-key-penumbra-opacity: 0.14;\n        shadow-ambient-shadow-opacity: 0.12;\n     */\n    -webkit-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),\n                        0 3px 1px -2px rgba(0, 0, 0, 0.14),\n                        0 1px 5px 0 rgba(0, 0, 0, 0.12);\n\n    -moz-box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),\n                     0 3px 1px -2px rgba(0, 0, 0, 0.14),\n                     0 1px 5px 0 rgba(0, 0, 0, 0.12);\n\n    box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.2),\n                0 3px 1px -2px rgba(0, 0, 0, 0.14),\n                0 1px 5px 0 rgba(0, 0, 0, 0.12);\n}\n\n.widget-inline-hbox .widget-readout {\n    /* Horizontal Readout */\n    text-align: center;\n    max-width: var(--jp-widgets-inline-width-short);\n    min-width: var(--jp-widgets-inline-width-tiny);\n    margin-left: var(--jp-widgets-inline-margin);\n}\n\n.widget-inline-vbox .widget-readout {\n    /* Vertical Readout */\n    margin-top: var(--jp-widgets-inline-margin);\n    /* as wide as the widget */\n    width: inherit;\n}\n\n/* Widget Checkbox Styling */\n\n.widget-checkbox {\n    width: var(--jp-widgets-inline-width);\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-checkbox input[type=\"checkbox\"] {\n    margin: 0px calc( var(--jp-widgets-inline-margin) * 2 ) 0px 0px;\n    line-height: var(--jp-widgets-inline-height);\n    font-size: large;\n    flex-grow: 1;\n    flex-shrink: 0;\n    align-self: center;\n}\n\n/* Widget Valid Styling */\n\n.widget-valid {\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n    width: var(--jp-widgets-inline-width-short);\n    font-size: var(--jp-widgets-font-size);\n}\n\n.widget-valid i:before {\n    line-height: var(--jp-widgets-inline-height);\n    margin-right: var(--jp-widgets-inline-margin);\n    margin-left: var(--jp-widgets-inline-margin);\n\n    /* from the fa class in FontAwesome: https://github.com/FortAwesome/Font-Awesome/blob/49100c7c3a7b58d50baa71efef11af41a66b03d3/css/font-awesome.css#L14 */\n    display: inline-block;\n    font: normal normal normal 14px/1 FontAwesome;\n    font-size: inherit;\n    text-rendering: auto;\n    -webkit-font-smoothing: antialiased;\n    -moz-osx-font-smoothing: grayscale;\n}\n\n.widget-valid.mod-valid i:before {\n    content: \"\\f00c\";\n    color: green;\n}\n\n.widget-valid.mod-invalid i:before {\n    content: \"\\f00d\";\n    color: red;\n}\n\n.widget-valid.mod-valid .widget-valid-readout {\n    display: none;\n}\n\n/* Widget Text and TextArea Stying */\n\n.widget-textarea, .widget-text {\n    width: var(--jp-widgets-inline-width);\n}\n\n.widget-text input[type=\"text\"], .widget-text input[type=\"number\"]{\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-text input[type=\"text\"]:disabled, .widget-text input[type=\"number\"]:disabled, .widget-textarea textarea:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n.widget-text input[type=\"text\"], .widget-text input[type=\"number\"], .widget-textarea textarea {\n    box-sizing: border-box;\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    background-color: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    font-size: var(--jp-widgets-font-size);\n    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2 );\n    flex-grow: 1;\n    min-width: 0; /* This makes it possible for the flexbox to shrink this input */\n    flex-shrink: 1;\n    outline: none !important;\n}\n\n.widget-textarea textarea {\n    height: inherit;\n    width: inherit;\n}\n\n.widget-text input:focus, .widget-textarea textarea:focus {\n    border-color: var(--jp-widgets-input-focus-border-color);\n}\n\n/* Widget Slider */\n\n.widget-slider .ui-slider {\n    /* Slider Track */\n    border: var(--jp-widgets-slider-border-width) solid var(--jp-layout-color3);\n    background: var(--jp-layout-color3);\n    box-sizing: border-box;\n    position: relative;\n    border-radius: 0px;\n}\n\n.widget-slider .ui-slider .ui-slider-handle {\n    /* Slider Handle */\n    outline: none !important; /* focused slider handles are colored - see below */\n    position: absolute;\n    background-color: var(--jp-widgets-slider-handle-background-color);\n    border: var(--jp-widgets-slider-border-width) solid var(--jp-widgets-slider-handle-border-color);\n    box-sizing: border-box;\n    z-index: 1;\n    background-image: none; /* Override jquery-ui */\n}\n\n/* Override jquery-ui */\n.widget-slider .ui-slider .ui-slider-handle:hover, .widget-slider .ui-slider .ui-slider-handle:focus {\n    background-color: var(--jp-widgets-slider-active-handle-color);\n    border: var(--jp-widgets-slider-border-width) solid var(--jp-widgets-slider-active-handle-color);\n}\n\n.widget-slider .ui-slider .ui-slider-handle:active {\n    background-color: var(--jp-widgets-slider-active-handle-color);\n    border-color: var(--jp-widgets-slider-active-handle-color);\n    z-index: 2;\n    transform: scale(1.2);\n}\n\n.widget-slider  .ui-slider .ui-slider-range {\n    /* Interval between the two specified value of a double slider */\n    position: absolute;\n    background: var(--jp-widgets-slider-active-handle-color);\n    z-index: 0;\n}\n\n/* Shapes of Slider Handles */\n\n.widget-hslider .ui-slider .ui-slider-handle {\n    width: var(--jp-widgets-slider-handle-size);\n    height: var(--jp-widgets-slider-handle-size);\n    margin-top: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-handle-size)) / 2 - var(--jp-widgets-slider-border-width));\n    margin-left: calc(var(--jp-widgets-slider-handle-size) / -2 + var(--jp-widgets-slider-border-width));\n    border-radius: 50%;\n    top: 0;\n}\n\n.widget-vslider .ui-slider .ui-slider-handle {\n    width: var(--jp-widgets-slider-handle-size);\n    height: var(--jp-widgets-slider-handle-size);\n    margin-bottom: calc(var(--jp-widgets-slider-handle-size) / -2 + var(--jp-widgets-slider-border-width));\n    margin-left: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-handle-size)) / 2 - var(--jp-widgets-slider-border-width));\n    border-radius: 50%;\n    left: 0;\n}\n\n.widget-hslider .ui-slider .ui-slider-range {\n    height: calc( var(--jp-widgets-slider-track-thickness) * 2 );\n    margin-top: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-track-thickness) * 2 ) / 2 - var(--jp-widgets-slider-border-width));\n}\n\n.widget-vslider .ui-slider .ui-slider-range {\n    width: calc( var(--jp-widgets-slider-track-thickness) * 2 );\n    margin-left: calc((var(--jp-widgets-slider-track-thickness) - var(--jp-widgets-slider-track-thickness) * 2 ) / 2 - var(--jp-widgets-slider-border-width));\n}\n\n/* Horizontal Slider */\n\n.widget-hslider {\n    width: var(--jp-widgets-inline-width);\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n\n    /* Override the align-items baseline. This way, the description and readout\n    still seem to align their baseline properly, and we don't have to have\n    align-self: stretch in the .slider-container. */\n    align-items: center;\n}\n\n.widgets-slider .slider-container {\n    overflow: visible;\n}\n\n.widget-hslider .slider-container {\n    height: var(--jp-widgets-inline-height);\n    margin-left: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));\n    margin-right: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));\n    flex: 1 1 var(--jp-widgets-inline-width-short);\n}\n\n.widget-hslider .ui-slider {\n    /* Inner, invisible slide div */\n    height: var(--jp-widgets-slider-track-thickness);\n    margin-top: calc((var(--jp-widgets-inline-height) - var(--jp-widgets-slider-track-thickness)) / 2);\n    width: 100%;\n}\n\n/* Vertical Slider */\n\n.widget-vbox .widget-label {\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-vslider {\n    /* Vertical Slider */\n    height: var(--jp-widgets-vertical-height);\n    width: var(--jp-widgets-inline-width-tiny);\n}\n\n.widget-vslider .slider-container {\n    flex: 1 1 var(--jp-widgets-inline-width-short);\n    margin-left: auto;\n    margin-right: auto;\n    margin-bottom: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));\n    margin-top: calc(var(--jp-widgets-slider-handle-size) / 2 - 2 * var(--jp-widgets-slider-border-width));\n    display: flex;\n    flex-direction: column;\n}\n\n.widget-vslider .ui-slider-vertical {\n    /* Inner, invisible slide div */\n    width: var(--jp-widgets-slider-track-thickness);\n    flex-grow: 1;\n    margin-left: auto;\n    margin-right: auto;\n}\n\n/* Widget Progress Styling */\n\n.progress-bar {\n    -webkit-transition: none;\n    -moz-transition: none;\n    -ms-transition: none;\n    -o-transition: none;\n    transition: none;\n}\n\n.progress-bar {\n    height: var(--jp-widgets-inline-height);\n}\n\n.progress-bar {\n    background-color: var(--jp-brand-color1);\n}\n\n.progress-bar-success {\n    background-color: var(--jp-success-color1);\n}\n\n.progress-bar-info {\n    background-color: var(--jp-info-color1);\n}\n\n.progress-bar-warning {\n    background-color: var(--jp-warn-color1);\n}\n\n.progress-bar-danger {\n    background-color: var(--jp-error-color1);\n}\n\n.progress {\n    background-color: var(--jp-layout-color2);\n    border: none;\n    box-shadow: none;\n}\n\n/* Horisontal Progress */\n\n.widget-hprogress {\n    /* Progress Bar */\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n    width: var(--jp-widgets-inline-width);\n    align-items: center;\n\n}\n\n.widget-hprogress .progress {\n    flex-grow: 1;\n    margin-top: var(--jp-widgets-input-padding);\n    margin-bottom: var(--jp-widgets-input-padding);\n    align-self: stretch;\n    /* Override bootstrap style */\n    height: initial;\n}\n\n/* Vertical Progress */\n\n.widget-vprogress {\n    height: var(--jp-widgets-vertical-height);\n    width: var(--jp-widgets-inline-width-tiny);\n}\n\n.widget-vprogress .progress {\n    flex-grow: 1;\n    width: var(--jp-widgets-progress-thickness);\n    margin-left: auto;\n    margin-right: auto;\n    margin-bottom: 0;\n}\n\n/* Select Widget Styling */\n\n.widget-dropdown {\n    height: var(--jp-widgets-inline-height);\n    width: var(--jp-widgets-inline-width);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-dropdown > select {\n    padding-right: 20px;\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    border-radius: 0;\n    height: inherit;\n    flex: 1 1 var(--jp-widgets-inline-width-short);\n    min-width: 0; /* This makes it possible for the flexbox to shrink this input */\n    box-sizing: border-box;\n    outline: none !important;\n    box-shadow: none;\n    background-color: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    font-size: var(--jp-widgets-font-size);\n    vertical-align: top;\n    padding-left: calc( var(--jp-widgets-input-padding) * 2);\n\tappearance: none;\n\t-webkit-appearance: none;\n\t-moz-appearance: none;\n    background-repeat: no-repeat;\n\tbackground-size: 20px;\n\tbackground-position: right center;\n    background-image: var(--jp-widgets-dropdown-arrow);\n}\n.widget-dropdown > select:focus {\n    border-color: var(--jp-widgets-input-focus-border-color);\n}\n\n.widget-dropdown > select:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n/* To disable the dotted border in Firefox around select controls.\n   See http://stackoverflow.com/a/18853002 */\n.widget-dropdown > select:-moz-focusring {\n    color: transparent;\n    text-shadow: 0 0 0 #000;\n}\n\n/* Select and SelectMultiple */\n\n.widget-select {\n    width: var(--jp-widgets-inline-width);\n    line-height: var(--jp-widgets-inline-height);\n\n    /* Because Firefox defines the baseline of a select as the bottom of the\n    control, we align the entire control to the top and add padding to the\n    select to get an approximate first line baseline alignment. */\n    align-items: flex-start;\n}\n\n.widget-select > select {\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    background-color: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    font-size: var(--jp-widgets-font-size);\n    flex: 1 1 var(--jp-widgets-inline-width-short);\n    outline: none !important;\n    overflow: auto;\n    height: inherit;\n\n    /* Because Firefox defines the baseline of a select as the bottom of the\n    control, we align the entire control to the top and add padding to the\n    select to get an approximate first line baseline alignment. */\n    padding-top: 5px;\n}\n\n.widget-select > select:focus {\n    border-color: var(--jp-widgets-input-focus-border-color);\n}\n\n.wiget-select > select > option {\n    padding-left: var(--jp-widgets-input-padding);\n    line-height: var(--jp-widgets-inline-height);\n    /* line-height doesn't work on some browsers for select options */\n    padding-top: calc(var(--jp-widgets-inline-height)-var(--jp-widgets-font-size)/2);\n    padding-bottom: calc(var(--jp-widgets-inline-height)-var(--jp-widgets-font-size)/2);\n}\n\n\n\n/* Toggle Buttons Styling */\n\n.widget-toggle-buttons {\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-toggle-buttons .widget-toggle-button {\n    margin-left: var(--jp-widgets-margin);\n    margin-right: var(--jp-widgets-margin);\n}\n\n.widget-toggle-buttons .jupyter-button:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n/* Radio Buttons Styling */\n\n.widget-radio {\n    width: var(--jp-widgets-inline-width);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-radio-box {\n    display: flex;\n    flex-direction: column;\n    align-items: stretch;\n    box-sizing: border-box;\n    flex-grow: 1;\n    margin-bottom: var(--jp-widgets-radio-item-height-adjustment);\n}\n\n.widget-radio-box label {\n    height: var(--jp-widgets-radio-item-height);\n    line-height: var(--jp-widgets-radio-item-height);\n    font-size: var(--jp-widgets-font-size);\n}\n\n.widget-radio-box input {\n    height: var(--jp-widgets-radio-item-height);\n    line-height: var(--jp-widgets-radio-item-height);\n    margin: 0 calc( var(--jp-widgets-input-padding) * 2 ) 0 1px;\n    float: left;\n}\n\n/* Color Picker Styling */\n\n.widget-colorpicker {\n    width: var(--jp-widgets-inline-width);\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-colorpicker > .widget-colorpicker-input {\n    flex-grow: 1;\n    flex-shrink: 1;\n    min-width: var(--jp-widgets-inline-width-tiny);\n}\n\n.widget-colorpicker input[type=\"color\"] {\n    width: var(--jp-widgets-inline-height);\n    height: var(--jp-widgets-inline-height);\n    padding: 0 2px; /* make the color square actually square on Chrome on OS X */\n    background: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    border-left: none;\n    flex-grow: 0;\n    flex-shrink: 0;\n    box-sizing: border-box;\n    align-self: stretch;\n    outline: none !important;\n}\n\n.widget-colorpicker.concise input[type=\"color\"] {\n    border-left: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n}\n\n.widget-colorpicker input[type=\"color\"]:focus, .widget-colorpicker input[type=\"text\"]:focus {\n    border-color: var(--jp-widgets-input-focus-border-color);\n}\n\n.widget-colorpicker input[type=\"text\"] {\n    flex-grow: 1;\n    outline: none !important;\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n    background: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    font-size: var(--jp-widgets-font-size);\n    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2 );\n    min-width: 0; /* This makes it possible for the flexbox to shrink this input */\n    flex-shrink: 1;\n    box-sizing: border-box;\n}\n\n.widget-colorpicker input[type=\"text\"]:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n/* Date Picker Styling */\n\n.widget-datepicker {\n    width: var(--jp-widgets-inline-width);\n    height: var(--jp-widgets-inline-height);\n    line-height: var(--jp-widgets-inline-height);\n}\n\n.widget-datepicker input[type=\"date\"] {\n    flex-grow: 1;\n    flex-shrink: 1;\n    min-width: 0; /* This makes it possible for the flexbox to shrink this input */\n    outline: none !important;\n    height: var(--jp-widgets-inline-height);\n    border: var(--jp-widgets-input-border-width) solid var(--jp-widgets-input-border-color);\n    background-color: var(--jp-widgets-input-background-color);\n    color: var(--jp-widgets-input-color);\n    font-size: var(--jp-widgets-font-size);\n    padding: var(--jp-widgets-input-padding) calc( var(--jp-widgets-input-padding) *  2 );\n    box-sizing: border-box;\n}\n\n.widget-datepicker input[type=\"date\"]:focus {\n    border-color: var(--jp-widgets-input-focus-border-color);\n}\n\n.widget-datepicker input[type=\"date\"]:invalid {\n    border-color: var(--jp-warn-color1);\n}\n\n.widget-datepicker input[type=\"date\"]:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n/* Play Widget */\n\n.widget-play {\n    width: var(--jp-widgets-inline-width-short);\n    display: flex;\n    align-items: stretch;\n}\n\n.widget-play .jupyter-button {\n    flex-grow: 1;\n    height: auto;\n}\n\n.widget-play .jupyter-button:disabled {\n    opacity: var(--jp-widgets-disabled-opacity);\n}\n\n/* Tab Widget */\n\n.jupyter-widgets.widget-tab {\n    display: flex;\n    flex-direction: column;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar {\n    /* Necessary so that a tab can be shifted down to overlay the border of the box below. */\n    overflow-x: visible;\n    overflow-y: visible;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {\n    /* Make sure that the tab grows from bottom up */\n    align-items: flex-end;\n    min-width: 0;\n    min-height: 0;\n}\n\n.jupyter-widgets.widget-tab > .widget-tab-contents {\n    width: 100%;\n    box-sizing: border-box;\n    margin: 0;\n    background: var(--jp-layout-color1);\n    color: var(--jp-ui-font-color1);\n    border: var(--jp-border-width) solid var(--jp-border-color1);\n    padding: var(--jp-widgets-container-padding);\n    flex-grow: 1;\n    overflow: auto;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar {\n    font: var(--jp-widgets-font-size) Helvetica, Arial, sans-serif;\n    min-height: calc(var(--jp-widgets-horizontal-tab-height) + var(--jp-border-width));\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {\n    flex: 0 1 var(--jp-widgets-horizontal-tab-width);\n    min-width: 35px;\n    min-height: calc(var(--jp-widgets-horizontal-tab-height) + var(--jp-border-width));\n    line-height: var(--jp-widgets-horizontal-tab-height);\n    margin-left: calc(-1 * var(--jp-border-width));\n    padding: 0px 10px;\n    background: var(--jp-layout-color2);\n    color: var(--jp-ui-font-color2);\n    border: var(--jp-border-width) solid var(--jp-border-color1);\n    border-bottom: none;\n    position: relative;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current {\n    color: var(--jp-ui-font-color0);\n    /* We want the background to match the tab content background */\n    background: var(--jp-layout-color1);\n    min-height: calc(var(--jp-widgets-horizontal-tab-height) + 2 * var(--jp-border-width));\n    transform: translateY(var(--jp-border-width));\n    overflow: visible;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-current:before {\n    position: absolute;\n    top: calc(-1 * var(--jp-border-width));\n    left: calc(-1 * var(--jp-border-width));\n    content: '';\n    height: var(--jp-widgets-horizontal-tab-top-border);\n    width: calc(100% + 2 * var(--jp-border-width));\n    background: var(--jp-brand-color1);\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:first-child {\n    margin-left: 0;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab:hover:not(.p-mod-current) {\n    background: var(--jp-layout-color1);\n    color: var(--jp-ui-font-color1);\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon {\n    margin-left: 4px;\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-mod-closable > .p-TabBar-tabCloseIcon:before {\n    font-family: FontAwesome;\n    content: '\\f00d'; /* close */\n}\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel,\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {\n    line-height: var(--jp-widgets-horizontal-tab-height);\n}\n\n/* Accordion Widget */\n\n.p-Collapse {\n    display: flex;\n    flex-direction: column;\n    align-items: stretch;\n}\n\n.p-Collapse-header {\n    padding: var(--jp-widgets-input-padding);\n    cursor: pointer;\n    color: var(--jp-ui-font-color2);\n    background-color: var(--jp-layout-color2);\n    border: var(--jp-widgets-border-width) solid var(--jp-border-color1);\n    padding: calc(var(--jp-widgets-container-padding) * 2 / 3) var(--jp-widgets-container-padding);\n    font-weight: bold;\n}\n\n.p-Collapse-header:hover {\n    background-color: var(--jp-layout-color1);\n    color: var(--jp-ui-font-color1);\n}\n\n.p-Collapse-open > .p-Collapse-header {\n    background-color: var(--jp-layout-color1);\n    color: var(--jp-ui-font-color0);\n    cursor: default;\n    border-bottom: none;\n}\n\n.p-Collapse .p-Collapse-header::before {\n    content: '\\f0da\\00A0';  /* caret-right, non-breaking space */\n    display: inline-block;\n    font: normal normal normal 14px/1 FontAwesome;\n    font-size: inherit;\n    text-rendering: auto;\n    -webkit-font-smoothing: antialiased;\n    -moz-osx-font-smoothing: grayscale;\n}\n\n.p-Collapse-open > .p-Collapse-header::before {\n    content: '\\f0d7\\00A0'; /* caret-down, non-breaking space */\n}\n\n.p-Collapse-contents {\n    padding: var(--jp-widgets-container-padding);\n    background-color: var(--jp-layout-color1);\n    color: var(--jp-ui-font-color1);\n    border-left: var(--jp-widgets-border-width) solid var(--jp-border-color1);\n    border-right: var(--jp-widgets-border-width) solid var(--jp-border-color1);\n    border-bottom: var(--jp-widgets-border-width) solid var(--jp-border-color1);\n    overflow: auto;\n}\n\n.p-Accordion {\n    display: flex;\n    flex-direction: column;\n    align-items: stretch;\n}\n\n.p-Accordion .p-Collapse {\n    margin-bottom: 0;\n}\n\n.p-Accordion .p-Collapse + .p-Collapse {\n    margin-top: 4px;\n}\n\n\n\n/* HTML widget */\n\n.widget-html, .widget-htmlmath {\n    font-size: var(--jp-widgets-font-size);\n}\n\n.widget-html > .widget-html-content, .widget-htmlmath > .widget-html-content {\n    /* Fill out the area in the HTML widget */\n    align-self: stretch;\n    flex-grow: 1;\n    flex-shrink: 1;\n    /* Makes sure the baseline is still aligned with other elements */\n    line-height: var(--jp-widgets-inline-height);\n    /* Make it possible to have absolutely-positioned elements in the html */\n    position: relative;\n}\n","/* This file has code derived from PhosphorJS CSS files, as noted below. The license for this PhosphorJS code is:\n\nCopyright (c) 2014-2017, PhosphorJS Contributors\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without\nmodification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this\n  list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice,\n  this list of conditions and the following disclaimer in the documentation\n  and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its\n  contributors may be used to endorse or promote products derived from\n  this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n*/\n\n/*\n * The following section is derived from https://github.com/phosphorjs/phosphor/blob/23b9d075ebc5b73ab148b6ebfc20af97f85714c4/packages/widgets/style/tabbar.css \n * We've scoped the rules so that they are consistent with exactly our code.\n */\n\n.jupyter-widgets.widget-tab > .p-TabBar {\n  display: flex;\n  -webkit-user-select: none;\n  -moz-user-select: none;\n  -ms-user-select: none;\n  user-select: none;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] {\n  flex-direction: row;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] {\n  flex-direction: column;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar > .p-TabBar-content {\n  margin: 0;\n  padding: 0;\n  display: flex;\n  flex: 1 1 auto;\n  list-style-type: none;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='horizontal'] > .p-TabBar-content {\n  flex-direction: row;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar[data-orientation='vertical'] > .p-TabBar-content {\n  flex-direction: column;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab {\n  display: flex;\n  flex-direction: row;\n  box-sizing: border-box;\n  overflow: hidden;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabIcon,\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabCloseIcon {\n  flex: 0 0 auto;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tabLabel {\n  flex: 1 1 auto;\n  overflow: hidden;\n  white-space: nowrap;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar .p-TabBar-tab.p-mod-hidden {\n  display: none !important;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab {\n  position: relative;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab {\n  left: 0;\n  transition: left 150ms ease;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab {\n  top: 0;\n  transition: top 150ms ease;\n}\n\n\n.jupyter-widgets.widget-tab > .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging {\n  transition: none;\n}\n\n/* End tabbar.css */\n"]} */",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "text/css"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tpot import TPOTRegressor\n",
        "\n",
        "tpot = TPOTRegressor(generations = 100, population_size = 100, verbosity = 2, cv = tscv, max_eval_time_mins = 480, n_jobs = -1)\n",
        "tpot.fit(X_train, y_train)\n",
        "print(tpot.score(X_test, y_test))\n",
        "tpot.export('tpot_fitted_pipeline.py')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29 operators have been imported by TPOT.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0a61bfd32874fdc86f11f6b71771097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=10100, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 1 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 2 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 3 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 4 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744283000913\tLassoLarsCV(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 5 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282976905\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 6 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282976905\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by StandardScaler..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 7 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282976905\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 8 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282976905\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 9 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282976905\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-3\t-628.4744282976753\tLassoLarsCV(LinearSVR(LinearSVR(input_matrix, LinearSVR__C=0.5, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LinearSVR__C=10.0, LinearSVR__dual=True, LinearSVR__epsilon=0.01, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MinMaxScaler..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 10 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282965382\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-620.1879100114747\tLassoLarsCV(PCA(RidgeCV(ZeroCount(input_matrix)), PCA__iterated_power=5, PCA__svd_solver=randomized), LassoLarsCV__normalize=False)\n",
            "-5\t-620.1148097810701\tLassoLarsCV(PCA(ElasticNetCV(ElasticNetCV(RidgeCV(input_matrix), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), PCA__iterated_power=3, PCA__svd_solver=randomized), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 11 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282965382\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 12 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-628.4744282965382\tLassoLarsCV(LinearSVR(input_matrix, LinearSVR__C=20.0, LinearSVR__dual=False, LinearSVR__epsilon=0.1, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 13 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 14 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 15 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-622.665599968572\tLassoLarsCV(ElasticNetCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), ElasticNetCV__l1_ratio=0.55, ElasticNetCV__tol=0.01), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 16 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 17 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 18 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 19 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 20 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-622.6655999692214\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=39, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _mate_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 21 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 22 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 23 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 24 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 25 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-580.4199007607967\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 26 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 27 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 28 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 29 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _mate_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 30 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 31 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.7128420185011\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=21, KNeighborsRegressor__p=2, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 32 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 33 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 34 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 35 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Generation 36 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 37 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 38 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 array must not contain infs or NaNs.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Generation 39 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 40 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745868630521\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.45, ElasticNetCV__tol=1e-05)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 73.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 41 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Generation 42 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 43 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 44 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 45 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 46 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 47 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 48 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 49 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 50 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 51 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 52 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 53 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 54 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 55 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-621.5992208195072\tLassoLarsCV(KNeighborsRegressor(input_matrix, KNeighborsRegressor__n_neighbors=44, KNeighborsRegressor__p=1, KNeighborsRegressor__weights=uniform), LassoLarsCV__normalize=False)\n",
            "-3\t-618.3756128319089\tLassoLarsCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 53.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 56 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 57 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 66.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 58 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 59 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 60 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-542.0745863019476\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(ElasticNetCV(input_matrix, ElasticNetCV__l1_ratio=0.9500000000000001, ElasticNetCV__tol=0.0001)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 68.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 61 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 62 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 63 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-612.5522334632475\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=19, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 74.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 64 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 65 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 66 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 67 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 68 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 98.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 86.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 69 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9844268678606\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 70 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9844268678606\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=4 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Generation 71 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9844268678606\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 77.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 72 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9844268678606\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 93.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 73 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425164813\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 74 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9844268686527\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=5, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425164813\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 75 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425164813\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 76 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425164813\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 77 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 81.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 78 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 91.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 99.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 96.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 67.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 79 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.7882690534528\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 80 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 76.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 81 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required by MaxAbsScaler..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 82 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 83 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-611.9474425145575\tLassoLarsCV(ElasticNetCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), ElasticNetCV__l1_ratio=0.1, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 54.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 84 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.6766167576518\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 51.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 85 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.6766167576518\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.156755834186\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 89.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 86 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.6766167576518\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 85.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 64.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 88.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 87 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 88 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Generation 89 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 59.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 90 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 97.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 91 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 83.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 55.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 92 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 80.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 57.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 93 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 100.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 94 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 84.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 63.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 78.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 69.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 58.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 95 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 71.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=3 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 90.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 l2 was provided as affinity. Ward can only work with euclidean distances..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 96 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 82.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Invalid pipeline encountered. Skipping its evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 97 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 56.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 62.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 60.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 70.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 98 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 95.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 X contains negative values..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=2 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 99 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 75.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 72.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['Date', 'Volume', 'MA 9', 'MA 21', 'Change', 'Volatility'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5']\n",
            "expected Change, Date, MA 9, Volatility, Volume, MA 21 in input data\n",
            "training data did not have the following fields: f0, f1, f4, f3, f5, f2.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 94.\n",
            "_pre_test decorator: _random_mutation_operator: num_test=1 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
            "_pre_test decorator: _random_mutation_operator: num_test=0 x and y arrays must have at least 2 entries.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
            "Generation 100 - Current Pareto front scores:\n",
            "-1\t-628.4744283004435\tLassoLarsCV(input_matrix, LassoLarsCV__normalize=False)\n",
            "-2\t-611.9474425179229\tLassoLarsCV(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=3, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001), LassoLarsCV__normalize=False)\n",
            "-3\t-600.3775776175379\tLassoLarsCV(MaxAbsScaler(GradientBoostingRegressor(input_matrix, GradientBoostingRegressor__alpha=0.9, GradientBoostingRegressor__learning_rate=0.001, GradientBoostingRegressor__loss=quantile, GradientBoostingRegressor__max_depth=2, GradientBoostingRegressor__max_features=0.7000000000000001, GradientBoostingRegressor__min_samples_leaf=16, GradientBoostingRegressor__min_samples_split=8, GradientBoostingRegressor__n_estimators=100, GradientBoostingRegressor__subsample=0.9500000000000001)), LassoLarsCV__normalize=False)\n",
            "-4\t-578.3277502816261\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(input_matrix), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.001), LassoLarsCV__normalize=False)\n",
            "-5\t-531.1244797164247\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(input_matrix, DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=1e-05), LassoLarsCV__normalize=False)\n",
            "-6\t-521.3449759516209\tLassoLarsCV(ElasticNetCV(PolynomialFeatures(MaxAbsScaler(DecisionTreeRegressor(LinearSVR(input_matrix, LinearSVR__C=0.01, LinearSVR__dual=True, LinearSVR__epsilon=1.0, LinearSVR__loss=squared_epsilon_insensitive, LinearSVR__tol=0.01), DecisionTreeRegressor__max_depth=1, DecisionTreeRegressor__min_samples_leaf=10, DecisionTreeRegressor__min_samples_split=10)), PolynomialFeatures__degree=2, PolynomialFeatures__include_bias=False, PolynomialFeatures__interaction_only=False), ElasticNetCV__l1_ratio=0.8500000000000001, ElasticNetCV__tol=0.0001), LassoLarsCV__normalize=False)\n",
            "\n",
            "-1746.2957189005472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myHK1yA1MxBf",
        "colab_type": "code",
        "outputId": "cff539ca-f3ed-4df6-ff7f-26c6252475be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = tpot.fitted_pipeline_.predict(X_test), label = 'AutoML')\n",
        "ax = sns.lineplot(x = X_train['Date'].apply(dt.datetime.fromordinal), y = y_train, label = 'Training')\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = y_test, label = 'Test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF/CAYAAADD8Vq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETk0f8BDHLQFn/0VBkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbDt6lfiuiv",
        "colab_type": "code",
        "outputId": "15b8ad9b-6235-4970-b2c3-cdcfc9d442cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "f, ax = plt.subplots(figsize=(8,6))\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = tpot.fitted_pipeline_.predict(X_test), label = 'AutoML')\n",
        "ax = sns.lineplot(x = X_test['Date'].apply(dt.datetime.fromordinal), y = y_test, label = 'Test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAF/CAYAAADD8Vq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXegHFd59n9nZrbv3dubrnqXrGLL\nkoULNrbBcodQbMcYYxz8hRASIF9IaB+GgJMYCCEkOEAcMIRqcAxY7t2yLVtusiSrd+n2vn13yvn+\nmN2990qrq+Jb9l6d3z/2zpzdPTOrO/PM+77neYWUUqJQKBQKhUJxBNp4T0ChUCgUCkVpokSCQqFQ\nKBSKoiiRoFAoFAqFoihKJCgUCoVCoSiKEgkKhUKhUCiKokSCQqFQKBSKoiiRoFAoFAqFoihKJCgU\nCoVCoSiKEgkKhUKhUCiKokSCQqFQKBSKoiiRoFAoFAqFoihKJCgUCoVCoSiKEgkKhUKhUCiKYoz3\nBMaT3t4EjjP5m2BWV4fp7o6P9zRKDnVehqLOR3HUeSmOOi/DU2rnR9MElZWhk37faS0SHEeeFiIB\nOG2O82RR52Uo6nwUR52X4qjzMjyT4fyodINCoVAoFIqiKJGgUCgUCoWiKEokKBQKhUKhKMppXZNw\nJLZt0dvbiWVlx3sqI0pHh4bjOKP+PYbhpbKyFl1X/6wUCoViMqCu5oPo7e3E7w8SCjUghBjv6YwY\nhqFhWaMrEqSUJBJRens7qalpHNXvUigUCsXYoNINg7CsLKFQZFIJhLFCCEEoFJl0URiFQqE4nVEi\n4QiUQDh11LlTKBSKyYUSCSVONBrlkkvO57vf/fYJjX/uuWfYunXLCY196KEHuOCCldx3372FbVJK\nPvSh93LVVZcWtn3wg9ewd+/uk5u4QqFQKCY8SiSUOI8//ghnnLGEJ554FNM0jzt+3bpn2LbtrRP+\n/PnzF/DIIw8WXr/xxmuUlZWd0lwVCoVCMblQIqHEefDBP/LRj/4Zc+bMY926ZwG4446vct99vymM\nyb9++eX1PP/8c/z85z/llltu5OGH1wLws5/dw0c+ch0f+ch1/OM/fo1kMll475QpTfh8Pvbt2wu4\n0YUrr7x6DI9QoVAoFKWKWt0wDC9sbuX5Ta2j8tkXLGvk/KXDrwLYvXsX0Wg/Z5+9ip6ebh588I9c\ncsm7jzl+9epzueCCC1m4cBEf+MD1AKxf/wKPPPIgP/jBjwkGQ3zjG7dzzz1388lP/nXhfVdccTUP\nP7yWW275OJs2beSWWz7OT37yXyNzoAqFQqGYsKhIQgmzdu0fuPzyqxBCcNFFF7N16xY6OztO6jNe\nfXUD7373GkKhMEIIrr32/bz66oYhYy6++N2sW/cMTz75GO9857vQdX0kD0OhUCjeNq8/8xRvPvAr\npH38tKti5FCRhGE4f+nxn/ZHC9M0eeKJR/B4vIWaAcuyeOihB9B1fUjjkGw287a+KxgMcsYZS/nB\nD/6d733vh2/rsxQKhWKkkFIWVk2Fdz9Go9NG7N6NBC+6BWPKonGe3emBiiSUKOvWPcu0aTO4//6H\n+N3vHuB3v3uAf/3X/+Dhh9fS1DSN7dvd4sSuri5ef/21wvtCoRDx+EB70pUrz+HJJx8jmUwgpWTt\n2t+zatXqo77vwx/+KLfe+n+YM2fu6B+cQqFQHIf23iR/e9eLbNjWDkDIjrLfqiGVypBaeyepZ+5G\n2tY4z3LyoyIJJcqDD/6Ryy67Ysi2JUuW4TgOS5YsZcOG9dx004eYNm06ixefURizZs2V3HHH13j6\n6Se5/vobueKKq9m3bw9//ucfA2DhwsV89KN/dtT3zZo1m1mzZh9zPp/5zF8OSUP89Ke/JhKJvN3D\nVCgUiqI8+0YLfbEUPP3v9MhrCZPkBXMu/51ZzjdWtWNtfQyraTGeeeeN91QnNUJKOfEbXp8i3d3x\nIWH7trYDNDTMGMcZjQ5jYcucZyKdw9raMjo7Y+M9jZJBnY/iqPNSnNE8L6bl8H+//wKLKjPclP45\nXcHZ1CT38mL4Mn5zsIEbLp7Nebv/Db1mJoE1nx6VObxdSu3fjaYJqqvDJ/0+FUlQKBQKxahj97Zg\nt++CTBKZSYDhwXvmNQhN45k3mpleX8bsKW508s3dXcRTJpetArZARfIAAHVTpzLfCfH4ay2888yV\nWFufRmZTCG9gHI9scqNEgkKhUChGnfTj/4HT1zJkm964EK1hPr98YierFtYxe4qbOt2wvYNI0EOT\n3oYJGNgA+CpqWdNYw7/ft5nd+lxmOo9jHd6MZ/Y5Y304pw2qcFGhUCgUo4rMpnD6WvEuv5LwLf9J\n+Ob/AAR2y3aiiSyWLemOuqu00lmLTbu7OHthHU7PoSGfE6iqZfncGuqrgjy01V0KKeM9Y304I44T\n78bcu4FSzP4rkaBQKBSKUcXpOQxI9IZ5CG8A4Q+jVU/HbtlKdzQNQE/uv5v2dJO1HM5ZWIfTfZC0\n4drExxw/kbIwmhCsWTWNHe0ZpNCQ6fixvnbCkHn5XtJP3EX66R8hnbGpHztRxkwkfPKTn+Taa6/l\nfe97HzfeeCPbtm0DYN++fVx//fWsWbOG66+/nv379xfec6r7FAqFQlE62N1uTYFWPVDUrDctwm7f\nQ0+PW9zXG8vgOJIN2zooD3uZW60hk330Vi1z9zshIiEP4DrWzplSTsz2kervLfqdlu3wzV++zq7D\nfaN5aG8b6VhYhzYhwtVYu9eT3fTQeE9pCGMmEu68807++Mc/8vvf/55bb72VL37xiwDcfvvt3Hjj\njTz66KPceOONfOUrXym851T3KRQKhaJ0cLoPYhlBfr2+k7Uv7ue5N1vo8s8Ax8JsdzvM2o6kvTfJ\npj3drFpQh4y5/giyYRFJx0OUMB7DXYZt6Bq3XrWIuOOjv7d4uiGRMtl+sI+dh0pbJNitOyGbwnfu\njRizVpJ99X7s7kPHf+MYMWYiYXBnwXg8jhCC7u5utm7dytVXuw2Frr76arZu3UpPT88p71MoFApF\naWF3H+JAtoInX2/mf5/byz0Pb+dfH+sEwOlrL4x78rXDWLbDqkV1yKi7P1TbyG+S57JBXzHkM+sr\ngySkH5Epnm4wbTdsn8yUtuGSdWAj6AbG1CX43vlRhC/kph1KxH56TFc3fOlLX+KFF15ASsndd99N\na2sr9fX1BZMeXdepq6ujtbUVKeUp7auqqjrh+Ry5ZrSjQ8MwSqNM49Zbb8Y0s5imyaFDB5k9ew7g\ntnb+f//vayf9eWN1XJqmUVs7cVpNT6S5jgXqfBRHnZfinMh5sdMJYj2H2J9ZwMeuPoMrz59Fd3+K\nv/3uM9hoGOkevEY9Wcvh+c1t1JT7ecfyqfS/sJ40MHfxXDb+9gCLplQd9X1ZPYjH6i86DxPXztlB\njNvvdyLf2xI9jNY4l7opNQAkrvlL2u/9J9b9/EdUXfxhLj572mhPc1jGVCTccccdAPz+97/nm9/8\nJp/+9PiaYBxppuQ4zpiZDh2PH/3oHgBaW1v4+Mc/wk9+8svCvsFztG37uA2ZxtJMyXGckjIQGY5S\nMzsZb9T5KI46L8WprS2joyOKtecljOnLEd5g0XHZrU+BbfFGdgbXBT1E+5J4gIvOmkr3WyHM3jbm\nNaxg2+EYWRNWzJ9Cd3ecVFszIlhBKu3g8+oEvPpRv4NlBDGslqK/T3unG2Ho6UuNy+93ov9uMj3t\n6A3zB8ZWLCA9/R0sP/Aye5tX0jm9YkTmc6pmSuPy2Py+972Pl19+mYaGBtrb27Ftdw2sbdt0dHTQ\n2NhIY2PjKe2b7Lzyyst87GM38vWvf4WPfvRP2bDhJf7iL/6Ml156sTBm8OvOzg4+//m/5bbbbubm\nm6/nF7/46XhNXaFQTDKcnkOkn/ohyYe+jcymio4xd6wj4a/nkF3N1LqBm9S7z55GHxGqtRg3Zn/F\n1eEtAKxaVAeAjHWildUihODSFVNZubD2qM+WvjA+mS66IsC23QfAZLo0wvbFkI6NTPSihauHbH/R\ndyGH7Grmlo9/qmRMIgmJRIJoNFq4iT/11FOUl5dTXV3NokWLWLt2Le9973tZu3YtixYtKqQMTnXf\nSGHufAFzx3Mj+pl5PAsuxDP//FN67549u/nc577I4sVLAPjZz358zLH/8A//j7/4i0+xePFSTNPk\nr/7qz1m06AxWrFh5St+tUCgUeZxYl/vfjr2kHvlXAlf8X4THN2h/J07nPnZHLiYS9FIe8hb2RUJe\nqqdMpbJtA5olme3roVrzMbsxUvhsvWE+AB9815yi3y/8ZYgUyEwcERjaS2Yi1CTIZB9IB1FWM2T7\nq3tjbC+/kb9fvOIY7xw7xkQkpFIpPv3pT5NKpdA0jfLycn7wgx8ghOCrX/0qn//857nrrruIRCLc\neeedhfed6r7JzowZMwsCYTgSiTibNm3kW9/6J/IeHclkgv379ymRoFAo3jZ5IyPfeR8ms/6XpNfd\nQ+CSPy/stzv3A7AlUcO0uqND3Y0zZ5BtfxmAqYEkt162GCEE0rGQiR60I26eR2KEItALZryf+19s\npyeW4ZPvc6+N+RRrIl26IiEvsgYfZ0dfiubOBDdcUhodecdEJNTU1HDvvfcW3Tdnzhx++9vfjui+\nkcIz//xTftofTQKBobk/XdeRciDcls1mAXAciaZp/OQnP0f5ZikUipHGiXeDbuA541Jksp/sxrXY\nS9eg185093cdQAqNN7t9XDL76CI+LVJf+H9PqpeF09wxMt4DUqKVHZ1iGIw3XA5AtLeHdZv68XoG\nrnNWLgWRLGGRIOPdAEPSDRt3uqs6zpw//LGPFerOMQmYOnUa27ZtBdxUxN697rrjsrIyzjhjKb/4\nxc8KY9vaWunp6R6XeSoUismFTPQgQlUIoeE980qEL0xmw70Fe2G76wA9WjUYHi49e+pR79ciuRuh\n7gFpI2PutcnpbQZARIa/UQYjlQDs3nOYVMYiljBxct9tWfmaBIut+3tK0i8hH0kQg0XC7i6aakPU\nVZRG0yolEiYBN910C88//ywf/egN/OY3v2Du3HmFfV/96j+yc+cObr75ej7ykev42te+RCKRGMfZ\nKhSKyYIT70YLubVgwhvEu+Ja7Oat2Ie3IKXE6tzH7mSEq8+dQVXEf9T7tfJ6RLACz6J3uZ8XbceJ\ndpB+7h5EsAK9Zvi286EKVyTs3ec2jnKkJJ5yCxWtXE2CIyU/eWg7f3h+34gc80gi492IQARhuLUa\n8ZTJzkP9nDVv+DTLWKK6QJY4jY1TePDBJwuvV61azapVq4eMmTp1Gj/+8S+Kvr+mpoY77rizZJZ2\nKhSKyYOM96BNWVR47Vl8Mdktj5PZcC+ByimITJxD1iLeM6f4TU8YPsI3fRcn2Ye55XHs1p2kn/8f\ncGwC137hmMsq85RXuSJByyYI+HRSGZtoIksk6C2IBIDuaJqyoGcEjnhkcWJdQ6IIm/Z04UjJmXNL\nI9UASiQoFAqF4hSQjo1M9rF+X4b5Z8SZWhdG6B58qz5A+qkfkHryPwFolvU01gx/sxeBcjB8ZDeu\nBY+f4FV/h17ZdNw5hMuCdDoeyrQ0H7tsEXf9fgvRRBZqwbKHdlRMZ+1TP9gRIPvWE2Rf+wMIDQwv\nCIGMdmDMfUdhzBu7uigPe5nZWDrmXSrdoFAoFIqTxo73gnTY22/w/ObWwnZjzjloNTNx2nezTV+I\nqJ2Jrg1/qxFCoJXXg24QWPNp9LrZJzQHTQh8kSretSDElJoQgCsSYEgkAdwW1OOFuXcDmRd+jlY5\nBWPGmej1c9FrZuA95zr8593kjrFstuzt4ay5NWhCjNtcj0RFEhQKhUJx0lhRt+iu1wmxb283N1zq\n1kIJoeG/8Baym5/gl2/MYNWSyHAfU8B/wc0g3XbSJ4M3UgXpKOVhN69/bJEwfpEE6+CbiECEwJWf\nQ+jFb7tb9vaQMW3OnFc6qQZQkYSjyFflKk4ede4UitOHbLvb/rnLLqO1O0ln34Djol4zk96lf0o0\nqzOj4cRC53r93JMWCAAiWI6T7CPoMzB0QX9BJAy9HmWy9rhdo2Q6gQiWH1MgZEyb3zy1m9oKP4tm\nVI7x7IZHiYRBGIaXRCKqbnangJSSRCKKYXiPP1ihUEx4ErteJWFU0C3dSMHmvUOXVh/O9U6YXn/y\n/QJOBhGsQCb7ASgLeguRBPOISILEvRmPC9kkwhs65u4H1++noy/Fx65YhKdEmgzmUemGQVRW1tLb\n20k8Xnrrad8OmqbhFPE2H2kMw0tlZWmFyhQKxcgjzQzp/ZvZbyxlSk2IrOmwaU83l6wY8EJo604i\ngPqq4YsW3y5asBzsLJgpIiEv/UlXJNj20de8dNbG7x37257MxNHKi/cWSqYtnnztMCsX1LKwxKII\noETCEHTdoKZm8jWJUl3sFArFSGI1b0HaJm8xlaqIn9qKAOvebCFr2ng9blfatp4kVRE/Ps/wXWrf\nLiLodkl0kn2Uh7z0xTOAG0kwdA2fR8ORklTGHre6BJlJIvzFIwlPv3GYVMbmqnNnju2kTpDSimso\nFAqFouSx9r6K5g+zOV5NVZmPZXOqyVoOOwa5GrZ2J2msHt0oAuSWTwIy2U8kNJBusG2JoQv+6gPL\n+OBFboOo8VjhIKVEZuJwjHTDtgO9TK8Pn3DtxlijRIJCoVAcB9OyeeaNZuwxSNuVOtLKYO1/Hf/8\n1URTNpURPwumVeA1NB5/5RCZrI0jJa09CRrGQiTkIgkyF0mIJV1r5nwkYf60Chqq3Rt0OjMOkQQ7\nC7Z1zEhCNGFSVXa0G2WpoESCQqFQHIfNe3v42aM7eG1H53hPZdyxDrwJVobdngUAVJX58Hp0PnDR\nHN7a18Md//MqOw/2kTUdGke5HgFyNQm4IiES9GI7kkTKxLYdDN31G/B73ZTHeKQbZCYJcMzCxWgy\nSyRUem6QeZRIUCgUiuPQn8tzv75zcooEmY6f8Koua89LpPUw33w8ClDoyfCeVdP47HXL6Y1l+Pav\nNwIUnuBHFW8QdA9OLt0ArleCaUkM3b3FDYiEcUg3ZNxVHsUiCY6UxJLZwrxLESUSFAqF4jjk196/\nuacb0xpfe9+RRqbjxH/2KTLrfnr8sZkE1sFNbDRn0lQX4ax5NcwclEtfMrua229ZxdS6ELomCi6I\no4kQwl0GmegbIhJsxxkkEtwa/VKLJMRTJlJCJFi6IkGtblAoFIrjkBcJmazN1v29LJ9bOl363i75\ndsXm9mcwZq/CmHrGMcda+18Hx+KF2HQ+dN08lhZZsldTEeBLH1lJbyxN+Rg9IWvhKmSip/B9/cks\npuUUiSSMh0g4diQhX2SpIgkKhUIxgYkmsjRUBQn49EmXcpDJgRUJqYe+TfrFXyDNdNGx5u6XSBiV\ntFDD6jOOvVzcY2jUVY5+PUIeEa7GiXUNiiSYWLnVDQC+cUw3MEwkIZYXCSUcSVAiQaFQKIpgte7A\natsFQCyeYkWwmeWzq3hjV9ekWuXgpFy3wuAH78BzxiWYW54g8bsvYzVvHTou2YfdspXXMjNYOruG\nUKB0iu20cDUy2UvQC7om6E9ksGwHI+deqAmBz+u2kh7MW/t7iKfMUZ3bcJGEvPFTmYokKBQKxcTB\nOrCR1AP/ROrhfwGgJrmPNckHuCS8i3jKZNeh/nGe4ciRtzTWyuvwn/8RAtd+ATSd1GPfQw4SQ9be\nV0BKXohPZ9WiuvGablFEWQ1ICcm+gleCZTsY2kA3Rb9XHxJJSKYt/uXXG7nr/s2jOjeZSbrtoT2B\no/bFEq5AGau0zKmgRIJCoVDgWg2b258jcf8/kHr0u+5G20JKiZF1b6T1Bx+nypPmtUmUcpDJfvCF\nELobGTAa5uNd8h4w08h0DNNy+MbPXqX/rRfo99TSI6o4s8RqMrRwNQBOrJtI0DuQbhjUB8HvNYbU\nJCTS7g16cGOq0UBmEghvEFGk/XM0mUXXBEF/6ZYHKpGgUChOe+zeZuK/+Czp534MZhrfuTfiXX4l\nOBaJWJKwTOYGZvlwzRZe39k5aRrByVR/wWsgT8HFMNVPa3eC/S19ePsPsinVyLI51ePS/2A4tLAr\nWmS8+4hIgnuLk1Li92hDREIy7UYVRvtYZCYBxzBS6k9kCQc9aEUERKmgRIJCoTjtsfa/Dtkkgav/\nnuCH7sC79DK0yiYAettaKNNSWJ4Q3qVrmJvZSnnqEPvbJkc/FJnsL4iCPAMuhv20dCWo1uJoOBxI\nl3HOovrxmOawiHAVAE68i/KQl2gyO6QmIf3E97lSPj0k3ZCvRfD7Rre3hBtJKC4SYoks5SVctAhK\nJIwKpjV5ipoUismKtLJIyy0cy3bsJ+Wp5CBNhf0iF8KOdrYS0VI4vjK8K66FYAUfCm7gte3tdPal\neGOCpx6cVD/iiEhCwcUw1U9Ld4J63U239IpKls6pHvM5Hg9heBGBCDI2EEkwLQdPbnWD09dGg9M2\nJJJQEAmjHUlIxxD+4u2yo8lsSRctghIJI866TS389ffWcagjPt5TUSgUw5C47yskfvW3AKTb9rMz\nUcY3fvYqX777ZR5cv5+E5poEpbs7KNNSaIFyhMeP/9w/ZarRQ1nzS/z7fZv59//dTGt3grt+v4Vo\nrlp9IlE0khCIAOAk+2npSjI7lABgyuxZo97V8VQRZTU4uXSD7UiiiSx6zidBWmnKnCiJVKaQJsqL\nhIB3lCMJqRgicHTzJtOyaelKUl95dEFjKaFEwgjS3pPkF4/vJJO1efqNZl7e2k5vLDPe01IoFEWQ\n/W3IVBS7cx/+TDetsppbrlhIWcDDfc/u5Qu/2IFEkO3vpEykMcKucZAx+xz6RDn1mX1kTffJ9Ks/\neYVXt3fw5q6u8Tykk0ZmU2Bljq5J8PjB4y+kG2YEEkh/hOvWLB+nmR4fLVydq0lwCzCzloMnJxIw\nM+jYOIk+mjtdwZMvXBzNSIKUEivZz0t7khw4Ij2142AfGdNm2ZzSKgI9EiUSRgjbcfivtVsxNI0l\ns6p4dmMzP/zjWzy4fv94T02hUByBlAMpwfTz/wNAKjSFC5dP4fM3nc0dt62mtjJMjCBmXwcRLYWn\nzM3TCyHI6kF0O0td7ikwn2J0Jlgxo8x5JBwZSchvsxN9dPSmqNH6MSqnlHQVvghEcFLRITl+PZdu\nkKa7gqFWj7FhezswEEmQvP3f7OnXD/PTR7YfvcNMo0ub5pjgX36zcYi/xpu7u/EaGgunV7zt7x9N\nlEgYIda+eIC9LVFuvnwB711ZhSZt3unbjkz0jPfUFArFEcj0QDrQ6dwLgKiaXtjWWB3irHk1dJlB\nPLE2vMJGG3QjdXQ/hpM5yuY3b7M7UXASvQBH1SSAW5eQjfXiSIew2Y1W0TDW0zspRKAcskkigYHb\nmkfXkI4FtluwuKTWYcO2DqSUJJMZPln2GLXJvcN+7pu7OtjT3Ddkm2nZbrfLQ+72VzYfpGn3fcR/\n+yU3OpNDpt3oQUIGiKdM9re6r+Mpkzd2d7J4ZhXeEk3f5FEiYQTY09zPAy/s59wzGjjTepO6J7/C\nvzT8gQ+GNjCz9+Xxnp5CoTgCmbs5bpnyfrTzbuEPyRVU1Q01CJpWV0avE6JedgBDb6TS48cjs4WQ\ntZ4z7YkmRte9b6Sxm7eC0NBrZh61TwQiOMkoEZHCsFJoFVPGfoInQb6OIqIPpHh1XQNz4PXCKouO\n3hQH2+NkkwkWeNqozLYc9VndPTF23fuvxDub4anvEXno81gtA5GCnliGPc1Rdjf34ziSJbF1rPLs\nQvY2k938WGGcTLmdMhub6hDAW/t62Nca5Ws/2UA0keWSs5uO/OqSQ4mEEeCp1w9TWebjxrO8ZF7+\nDVrdHIxK19dcZIcWMB5sj/H9+zfTF1e1CgrFeGHnRMKrzQ7tVSt4Kr2ExpqhFejT6kLss2oLr4eE\n5D1+fCJLfzzLhcsbufMT59JQFRxSuCilLHn7ZuvARvSGeUWr70WwHC0TZbbhiiS9fu5YT++kyEd6\n/E6iINo8uhjSh6LB6+7bsK0dM+3WJmjOwLLI/kSWXz6xkx/f80ca+t7k4GsvMlscxi/TZNb/qjAu\nnnTFYCJt0taTpIoozXYVseolZDc9UohU2Sk3chAsr2JGQxlPb2zmn37+GiD4wk1ns2RW6a0UORIl\nEkaAGy6dx+03nYFc90NEsILg5Z8l+N4v0RuYRtCOFS4UHb1JvnPvm7y2o5PnNh6tXhUKxdjQ2+7m\npff36+xvc5/2jmxrXFMRYJOcX3g9OJIgvAH8wiSZsQgFPFRF/ESCniHphu/fv4XbvvnMKB7F28OJ\ndeH0HMKYfmbR/SJQjmGnmO9pBcOLVjO96LhSQQTdSIJIRykL5twjdQ05KJKgJbpZNLOSV7Z3II8Q\nCW/u7uLzP1jPU681c0Gja56lxTsK73UGpRFiuXqGRMriQHuMoJYhKX1sLX8nmGmybz4EQDbmpiOM\nYIQls6voj2dZOKOS2z+2ilmNkVE5DyONEgkjQDjgQd/wC2S8m8AlnxhQ5YEKKrQkvbEM/fGMW7hi\nO0ytDfPilrZJ49imUEw0+jvdi3+/E2Ddm634PDq1Ff4hYzQhqKmtpMVyC8u04ECBme4L4hcWAknY\n796QIjkTnzz5bpF5Z79Sw841cHKmLOGff/4ae1uihX3bDvTy8j73CfxM30H0ujkIrXSLFmHoss18\nN0hD1yAXSRBlNTh9LZyzoJau/jTJeK7xkuPe8J97s4Wg3+Abt61meYV7LoKxgwCYUsMZJDYGRxIO\ntscIiSyWHmBXPIQx9x1ktzyBFe8lG3cLQz3hcq5YPYNPvX8pn/nQcsIl1BzreCiRMAKYO57D2rsB\n78r3ozfMK2zXyqoo15Icbo/znXvfpD+R5TPXLWfNOdPo6Euxu3nyNIlRKCYSqb4uYo4fB40D7THO\nmFWFrh19OZw/tYJ7ve8ncPlnhoTkdb/bBtmLWaj4z5v45Mk77eYjFaWGk+gBBM3pEDsP9/PWvu7C\nvv99dg+/3R0mQZCQyKA3zD/2B5UIA1bSUcpDPgCMQekGo2kxmGnOqnP7JQSE+1tp0i0+PdwZZ05T\nOfWVfuz23QCUm66Y7LIjBeMtGFgZkUxbHGyPE9azaIEyWroS+M5+HzgWfS/+L1ain6zUCYZCBHwG\nK+bXlrQFczGUSBgBZH87xpz0g80cAAAgAElEQVTVeM+8csh2f3ktXmFz9/2v0NKV4FN/spQ5U8pZ\nNMNdb93clRiP6SoUpy1SSg60xbDivWSMMvw5I53lc4vnhv/kwtnc+TdrjgrJe3IiwS9MQoMiCYm0\nhWW76cWmXI3DvtbSFAky2Y/wh2ntdZ+QO/vdm+mhjjh7WqIkpJ+fxc7HQseYtnQ8p3pCCMPrejuk\nogWvBGNQ4aLedAYAnr4DLJlVNUgkWKSzFp19aabVhnD6WiGbwsRAyy2P7HTKwB4oSo2l3PcmUibd\n/Sn8ZPCFymjrSZLwVOJZcAHR1x9D9B4k7vhLeuno8VAiYQTwrb6OwKV/gRBDT2eo2i16qtCSXHvB\nLJbMdi9EeT9x21bpBoViLOjqT/Hg+v18+e6X+do9rxCw4/jLq5laF0bAMQ1tDF0j4Dv6Au8NDhIJ\nudBxJLc+P5YLRXs97t/5vtbS7PEgU67TYmuP+7DSleuG+OzG5kIUZLvZyB+a/qbkixbziEA5cnC6\nwdAKHgl69XTwhXA69nDOonoCwv2dNGkVHtim1oYLUYSDxqzC53baZejSGnBrzP3G8bRJOhFDQzKl\nqQ7HkTy64RDeFe8FwN+7h7j0F4TkRGRMREJvby+33XYba9as4ZprruFTn/oUPT2uf8B9993HNddc\nw1VXXcUnPvEJ+voG1qNu3LiRa6+9ljVr1nDrrbfS3d19QvtKBW+5e+Gp0JJctmpaYXu+M5ltl3bl\ns0IxUXCiHaTX/wpz5/M40Q6kdLAOvIHd28z6LW383X+u5/fP7mKBt50vLN7PNF+cyvo6LljayMUr\nmig/Sf98X9CNEriRhIF0Awx4JWRN9+97b0t/SZosOUm3Z0Nrl1uk19mXIpO1Wf9WG6sX1xfsl8vL\nSts2eDBaIOKmG4IDNQmFwkWPH71uDnbHHs5eUMvS6e5x6dLicM5Gv6kujNO+G+EL0x2YAUDc8UG+\nQVMumpBPN/THs3hsNwJTUV3FOYvrefK1w8S1MiIrLsu9318QkhORMREJQgg+/vGP8+ijj/LAAw8w\nbdo0vv3tb7Nnzx6++93v8tOf/pQHH3yQZcuW8Z3vfAcAx3H43Oc+x1e+8hUeffRRVq5cybe//e3j\n7islRMjtTHb96uohfudGzgXMckrvwqFQTETMXS9ibn6U9DN3k/j13xG/55OkHv030k/9kO2bt/CX\nlc/yL3W/408y99PQ8QJ63Ww8Cy7kwuVTuOmyBSf9ff4hImEg3QDuMjpwDXcA+uJZHn/l0Egc5oji\nRhIitPa4IqEnlmH9W22kMjbvOrOJxmo3WlJR5hvPaZ4UIicSBgoXBVi5wkWPH71+Dk5vCx4nzeIp\nrkjQpM3hzgQ+j05NuVuPoNXPwQ64aeE+J4g/mBNKOZGQX91gO5KgcEWI8IW49vyZZC2bR14+SMV5\n78cWHvqcgEo3HI+KigpWr15deH3mmWfS0tLCzp07WbRoEVVV7s30oosu4oEHHgBgy5Yt+Hw+Vq5c\nCcANN9zAI488ctx9pYQIlIPQqPOlh2w3cn7ilookKBQjgtPfAcEKgh/8Br4LPopn9jkYc1bjdB/k\nsv77mKG3451/PoHLPk345v8geM3n31YIXfO7Nw2/GFq4CIMiCZbDBUsbOWteDb97Zk9JuTFKKZHJ\nKATK6exNUVnmQ0p44MX9NFYHmTe1nMZq9+m5IlzaXQoHI4LlOKl+ysOusPEYGjKbu/4aPvS6OQDY\nnfsg64ojXdq09SRpqA4iMgmcvlb0+rmFh7x+J4jH535evngxn24ACGm5SIUvTGN1iHcsruep1w4T\nkwFemnYLj2XPwmtM3Mz+mM/ccRx+9atfcckll7Bw4UI2b97MoUOHkFKydu1akskkfX19tLa2MmXK\ngMNXVVUVjuMcd18pITQNEazAiQ+1ZtY0gRBg5WoSWroS7D6sVjooFKdKf1szu/t9PLTNxFj0LvwX\n3cq2+iuxNQ8RLUXr3A/gv+BmjJlnIbxvP3wuPO5nBHSzUPwYya3NjyXzkQQHj0fjncunYDuS7mi6\n+IeNB2Ya7CwPbezFkZKluXqp3liGi85sQgjBlJpcJCE8sSIJZBLMawrxp++ex4JplUgrA4YXoWno\ndbMBgd2xp2CfrGORMW2CPgO7Y4+7rX4uepl7TuIijGbkhNKgdEO+ViWYK4AUfldUXXv+LCxbct9T\nu2mT1Ti+csQEW9EwmDGPgXz9618nGAxy0003oWkaX/7yl/nsZz+LEIJLL73UnZQxNtOqri7e43sk\nMWubkIkOamuHtgr16Bo+n0FtbRk/fng7Ow/28t9fvmzU5nHk9ytc1HkZykQ9H52pLrqcRu5ft48D\nnQmuu3Q+dz20l8t9C6nVYpx70Xve1rEd+V47DAmg3OtQVzdgiuPz6pjSHW/aDuVlfqY2uEvzDK+n\nZM5vtjtGHGhPeZhSE+LKC2bz3JsteAyNa981l7Kgl0vOmcH+9jjLFtYfs1NiqRxPnmhtHV1AbQhu\nvGIxAJ26jeML5uZaRqamCaPvIFJmsQADNy0UCnrxxfaREhr1i5ZRb3aw+dWpHPLOZH4wAD1QGfGg\nV4dJpk1mT61g96G+QrqhdkoDeqiM2toyLl45lYdf3MecqRVEwt6SO08nw5iKhDvvvJMDBw7wgx/8\nAC1XvHfVVVdx1VVXAbBp0yZ++ctfEg6HaWxspKVlwJWwp6cHTdOoqKgYdt/J0N0dxxnlugA7WIfZ\n/AIdHdEhalLXBdFYhs7OGH2xNB29KQ439+Ebhd7mtbVldHaWZoX1eKLOy1Amyvlw4j1YB97AmHU2\nWrACaabx2wm0SB0fuWABv3piJ69v7yDg03nCPBuvR+dC5CkfW7HzInMufWHDHrKvLOChrStOR0eU\nbNbGMi2yafdJs6U9yrTq0igCtFrd66f0R/jGx1fjOBKfV2fFvFrSiQzpRIaALvjL9y0h1p+i2Jkr\nxX8vpu1GPbqaW9Az7tN/KhbD0b0Dc62eRWr/G4gyt7BclxaptEV50CG27y206ml095tI2+Hu+CXM\nbChjlu0aY/V09pFKhXEk1JT52A1EdPf37Y47iKT7He9Z0cTTrx1m2/4e5jaVl8R50jRxSg/GYyYS\nvvOd77BlyxZ+9KMf4fUO5Lg6Ozupra0lk8nwve99j1tvvRWAJUuWkE6nefXVV1m5ciW//vWvufzy\ny4+7r9TQKqeAmUYmehHhqsJ2XdOwcnbN+Sro9t4k0+snruJUKEYLKR2sfa9h7liHfXgzSIlM9uFb\n9QHMPtdi2VvVwDvPamJWYxk/fXgHF69ooizoIZ2xRzzcKzQDR/Mwp3povr48Z6hkO24DYo+hFyrb\n882gSgGZdNObeijnJqkJvnjT2VRH/MO9reTRcq6LMjnIm8LMIDwDKROtbg5yxzo3DYEbSTBtB6/u\n1ip45p0PUPjdwgEPwuP+ztLMFtJJ9VW5dIzXAk9giCNlXWWQS1dO4/ENBwurXyYqYzL7Xbt28cMf\n/pCZM2dyww03ADB16lS+//3v84UvfIGWlhZM0+TKK6/k5ptvBkDTNL75zW9y++23k8lkaGpq4lvf\n+tZx95UaWqVbO+H0taANEgmGLgpLIPNV0G09SiQoFMUw33qKzIs/R4Qq8Z55NebOF3D62wDoPnyI\nMBCpdzvqzWyIcPvHVo36nHRfgJnVQ5e2lQW9dPWnCsLfa2iFm0QiNT4iQVpZMi/9Gu+yy9EibqdL\nmXJFgr+8sjBuWt3op19Hm3x/jfzxAUgzXaghAdDr3eLFfH2Bjo1pOVTJbjDThf1lOZEQCngKNQmW\nmSGes3Gur3Q/s9xjFuoRBnP9exbw1KuHJpQFczHGRCTMmzePHTt2FN139913H/N9K1asKKx2OJl9\npYRW6V64nN5mmLqksN3QtULhYv6C0tadHPsJKhQTALtlGyJSR+i6f0ZoGnb3QZz+NmQ2RerwdsJA\n3bQxbkDkDRSMevJEQl72tkYLwt9raBi6hs+jkxinHg52207MrU/hxLoIXPbX2Ie3YO5+CVsKwoNE\nwmSg0L8hNRBJkGZ6iKW2VtEEHn+hp4MhXJFQZ7UCoNe71vr5SELIbxREgp3JEMcVCXWVbiQhrGcR\nvqNFQn1VkL/+4DJqyid2dGZix0EmAMJf5rp89bYO2a7rWmEJZMYciCQoFIqjsbv2u8vScrVMWnkD\nZss2oo/8O7VtW+l3AkypL+6aOFoIT2BIG2JwRUIsmS38TXsMt8YoFDDGNN1gd+3HbtuFMXtVwUHQ\nPrSJ+M/+CswU0hvkifQSqitKo0ZipBAePxheZOqIdEN4wHZbaBp67Szslm04CDy5SEKl1Qm+UKFW\nwe91m35NrQ2jpdxrs5XNEMtFIMpDXirLfJRpGYSvuNjKrxqZyCiRMMoIIdArmzB3rsNu34kWqUer\nno5fqy3YMmctVyy0qkiCQnEUMh1HxrvRz7i0sE0rrwcri2jbyhvmLELv+CBTtbFdZia8AcgOjSSU\nh7xI6S4lhAFr5qDPQyI1NpEEaWVJPf59ZKyTzGu/R4vUoVU0IiJ1CF8Iz5zV7KOJh365ic9M8BqE\nYohA+VHpBjxDxZBeNwe7ZRumEcJnxTFNE69MI/xlhfoVIQR3fuI8ADZscJfX22aGeMYVCeGghy/f\nvBLj/t+glU0M2+pTYeI6PEwgfOfeiGfJe9Ai9Tj97WRf/wMX8UohkpDNRxJ6k6p9tEJxBHbXfgC0\nmpmFbVpFIwAC6Ko6k7PPPmPM5yWCFdi9zciM6/vvJPsKhkpduWZJnpyJTjhgkDwikrBuUwv/9cDW\nEZ9XdtMjyFgnvnfcAJkETuc+9IYFBC//LIGL/w/G9OV0x1zBUj3BQ+HFyLsuAmQ3P4pM9KKFhz7p\n5+sOTMNNQxjYeGUG4QsW/UzN6xY+2maWeNLEa7gppAqfA+koIlfrMRlRImEM0Gtn4n/HDQTWfJrQ\ndf+IZ/ElnOVsotx0q7JNyyHoM8hkbfripePKplCUAnbXASDXoCeHVt7g7pOCVPmsou8bbbzLLodM\nkswbD2C37ybx889QbbppxSNFQsjvOaomYfPeHl7Z3j6ifR2ceDfZjWsxZq3Eu+xy9GnLgEHFejny\nxk41kzCSoAUiyGQUmY6TWf9r9OnL8J551ZAx+pTFeBZeSH/ErT8whIPXSSO8xUWCkVuR55hZYqks\n4ZxxlhN1W0lrkfrROpxxR4mEccC7/Eo0JDVmK5btYDuS6fWuom3rVu2jFYrB2M1vuaHyQcVnIlgB\nhpf9Vi2hsvGpytdrZmDMPx/zrScw970KQJnZBUB3TiR4czUJQb9B/IhIQjSewbLlEIvft0vmpd+A\nlG4UAfCtuBYRri60Sc6ztyVKZZlvVHxZxpt8usEtXpR45p6LMIa6RgqPD/+Ft5L1uxEGAxvDPrZI\n0HORBCcXSajwCZIPfgtz14sAhVUjkxElEsYB4cmpd8curGzIL33MFy+u39JGNKmiCorTG7u3Gbt5\nK54F7xyyXQiBs+y9PJZeWgjxjwee+eeDbWG+9RQAAcsNc+ef1D2Ght21n8s7/huZjg95b74RVL5+\n4e1itWzH2rsB75lXoeWNgurnEr7xX4Ysv06kTTbt6WbVwsl5YxPBcreOJZdyGCwuj0J3IwIekRMJ\nx0g3eAwPjhQ4VpZ4ymSOrxO7+S3MLY8DSiQoRhrdrRcVjkk2t1SqvjKAz6PT2p2kP57hv9Zu5aUt\nbeM5S4Vi3DG3PAG6gWfhRUft6592IdvNJiLB8RMJesM88AbAdm/4eroPXRN09bsFjV5Dw27bRTjb\nRSNdhfojGBAJPbG339NBSknmxV8gwtV4l1857NjXdnRiO5LViydniNxdBikLPhrFlicWxg4SCbqd\nPuZYj0fHREfmRMJMkVutJh1EIDIi/UBKFSUSxoOCSLALKxu8Hp36qgBtPUl64+6TRTIzPuuqFYpS\nQGYSmLtewDP33IKT3mDykbbxjCQIzcDI5f0BZKKXSMhLT9T9G/Z4dGTSrYyv1/sLdQmZrE06m2sl\nPQKRBJnqx+k5hHfJZQhj+PPx0ltt1FcGmNkwOY3bCl4Jfe6NfFiRYLgiISgyaNKGY6QbPIaGKQdE\nQqN1GPKrICZxFAGUSBgfhI4ENGkVnix8Hp3G6hBtPUn6Yu7FT4kExemMueM5sLJ4znh30f351svj\nKRIAPAveiYjUoTcuQCZ6iAS92LmeMF5Dw0n0AjmRkHNd7B+USuwZEZGQC60PSisUozeWYcfBPlYv\nrp/QnQmHI++66PS5/SlORCSUCTeac6yahLxIcMwsZjpFZaYFI2ffPJlTDaB8EsYFIQQ2BkJahZoE\nj6HRUBVkw9Z2OvvcUGU6Yw/3MQrFpESaaRL3fQUZ7URvXIBeM6PouGjCveGOZ7oBwJi6hPAN3yT9\n/P9g7l4/RLR4Da0QSajTowVDpeigVUwjUZNQEAlFIi6D2bCtHQm844yGt/2dpUo+6uT0trhP+8Ok\nAoTu/lZlmnvNPWa6QddIokM2wyyjEw0Hz5zV6JVN6PWT1yMBlEgYNxyho9l2IZLg9eg0VAWRwM7D\n7kUllVWRBMXph92+GxntwJh/Ad5lVxy1v7U7wdNvNNPek8LQBQFfaVToi3AVZJNUVQ8safQYOtlB\nkYTnd3WxYHol/YkM840WZvt6ORB7+9bIeZGgBcqHHffS1nZmNpTRUFX8iXkyIHLnQMa7Eb4wQhw7\nYJ6PJEQKIuEYkQSPjikNtGyWuZ52JBp6wzyMaUtHePalhxIJ44QjdDQG1yRohT/cHQdzIkGlGxSn\nIXbrDhAa/vM+PKQgrKsvxR9f2M8LW1rJWwtURXwlEzbPryCo9eZC17iN3NKJPhAa5VqKZ1/Zw6IZ\nlfQnspzr280K337+LbYY03L4+WM7uPq8mdSeglXyQCTh2HUGrd0JDrTFuOGSyf3ki8fvrlqwTSjS\neGkwWl4kiJxIOFa6Qdcw0fFYGeYavWTLpw2sUpvkqJqEccIRBrociCT4DL0gEuK5vGVKpRsUpyF2\n2060mhlDBMLmvd184Ucv8dLWdt6zclqhMt/nKY0oAoAIuSKhSneXMXsMDawMmCm0utkALK0x+e8H\nt7G/LUaF7nqiTE/voqUrwbpNrTzx6uFT+m6ZioJmHLPwDuDlre0IYNWiybmqIY8QopB2Ga4eASg0\nbipEEo5Tk2BYSWYYXTh180dwxqWNEgnjhNR0NGkXlkB6PRo+r05VZMD0I63SDYrTDGmb2B170BuG\nXoQ3bG0n4DP45z9/BzdcOo93nem2YC+lfidaTiRUaO7N32NoyIQbFTRmnAkIrl+QJGvZPL+plUrd\nvTGdoe8v1CFt2N6O45y8A6OTirpL8Y4RVXGk5KWt7SycUUllma/omMlEPuUgfMMbbeUjCWVabhnq\nMdINhi4wpUGt04kuJN6mxSM32RJHiYRxQgoDfUjhovtENDhXqNINismA3b4bq2X7iY3t3A+2dZRI\n2N8WY/aUCFU5G+F50yoASsoQSIQqAUHYiQFunZGTdOsR9NrZ6NOW4juwnpsunYtAEhFJHKEzx2in\nrdMVE/3xLLtyNUkng0xFh001bNjaTkdvincubzz5A5uAnHAkwXNikQQhBLbQ0YRrBR6cpiIJilHG\n0Qx07EJLWV+uW9xQkaDSDYqJT2bDb8m8fO8JjbVbdwA5k6Ic6axFS3diyLp+TQju+psLue2a0nmi\nE7qBCETw265IcCMJrkgQoQq8iy5GJvtYHWnjmrOr0XEwww3oQtLb2QmArgk2bOs46e92RULxokXL\ndrjv2b1Mrw9zziRPNeTRgjmRMJzbIqDnREKZSCF1L0I/dpmeLdx9h5xavIHhxcdkQomEcUJqBoZw\nCtECr2doJCES9JAx7VMKPSoUpYRMRcE8MVdBu20nWsUUDvULzFwq7mB7HClhZuPQ5X1+r4Ghl9Yl\nTISr8GbdNsWuR4IbFdCClejTlyFCVZjbn+Gas9xICBXTAIj29CKAs+bV8OqODmzHKXxmV3+Kr/z3\nBnqixz6Hw0USDnXE6Y6muWL1DLQSKfIcbQbSDceLJLjpBl3I447Ni4TDYsoIzHDiUFp/YacRMhdJ\nSGYsNCHQNfePt7Ha/YfakPuvqktQTHScVBR5AiJBOg522y66fFP52j2v8OxG1wznQJv7ZD4RHAK1\nUBVaqg8h3BSijHaAL4TwBhCajmfhRdiHt2C3uBETo9b1gEjH+gj6DVYvbiCWNNl+YCDlsP1AH4c7\n4xzuLN78TUqJTEWPufwxLy4m87LHIznRdIOeq0mAY6ca8tjCHdvunT7suMmGEgnjhWbgETaptIXX\noxUKjhbNqOQjl83nnEVurlWlHBQTGelYkEmckEhweg6BmeLhfW5h3cEOtyHS1v09VJb5qAiXfsGd\nCFchEz2UBQw3ktDXgl4x8OTpWXghCI3smw8CEGiYCYBfpgkHvSybU4Xfq/PytvbCe1pznWGP+cBg\npsCxjhlJ6M5ZRA8uip7snGgkwTAMLOneBrXg8B4TWc1PVupEQ9NGZpITBCUSxgmpGRg4JDMWXmPg\nZ9A0wcUrplKWc5FTxYuKiUyh86GZQcqB1JmUkq//9BVe2Nxa2JY4sBWADu9UpteHaelK0NqdYNOe\nbs5fOjEK7rRwFZhpaoMCn1fH6WtFqxyYuxaqxJhxlpuCETqe6iYAQiJDWcCDx9BZMb+W13d0Ytlu\nyiG/giOTHfrAkMnatHYnkMm8R8KxIwkeQyMc8BTdPxnJe1Yc65zk0TWBIdzzbMxeOezYjfpy/jV6\nBYHg6RORASUSxg/NwBA2qYxVqEcYTN5FTrkuKiYyeZMfpO2a2+SIJk32tcbYecgNq1u2w56Nr9Hr\nhPjo+89j3tQKmrsSPPbKIXRd49Kzp47H9E8aEaoG4E/Pq+b9q+uR6RhaxVCB41l8cW5sBcIXxkEQ\n0jKFm/g5i+pIZiy27OsBoKUQSRgqEh5/9RBfu+cVzFiX+3nBiqJz6ommqYr4S8Z0aizQ6uYQuOJv\n0JsWDTtOH1TT4pmzetixjjdIi11FODC+NuBjjRIJ44WeiySkjyESvG6RjEo3KCYyBZEASGugR0FH\nr/t03BvP8ObuLm7/75epMw8j6uczo6GMppoQmazrJ/COxfWUj3MTpxMl/wQ7PWwyxevWUmgVQwvd\n9KbFiEg9WlkNQtPI4CMs0oSDrkhYPLOKkN9gw7Z2TMse6OVyxANDV3+KrOmQaHcNmLTy4v0YemIZ\nqk+jVAO4SxaNacuGtWQG1/8AoE+Gjpua8OQERThwehkVn15HW0robiQhmbGKhgH9PvenUYWLiomM\nTMcGXmTT4Hfz5h297o2vL5bhsVcOEcj2EPGm8S1cDkBTrXvBth3J+UsnTjOivOuiE+8BLbey4QiR\nIIRG8IrPFl5n9QDBXLoBwNA1zl5Qx8vb2rn07HjBgjptDn1gyDe4ynS34DG8OZ+Go+mOplk6q/rt\nH9wkRNcEf997HZFImH88zti8l014nBuKjTUqkjBOCM2DgT1MJMHdptpFKyYyQyMJA8WL7TmR0BvL\n0NGb4h217ri8iVJTjSsSasr9BeOkiYAIloMQyEQPTl8r6B5E+OgbtFbeUHjyt4wQYS1TiCSAm3LI\nZG0efPFAYduR6Yb+XKts2d+GVt5QNJ1g2Q7RePa0Klo8GXRNIyn9COP4N35Prnas7DSq7QAVSRg3\nhDHgkzC4cDFPIB9JUOkGxQTD7msh/eQPQdMQ+qALqjmQbsiH0BNpi2TaYkptD3gChfx90O9h6exq\nls+tnlBr+4WmI4KVOIkeyCTRIvUIbfhnMccTJCQ6h0QUF06vJBLysnF3F1NqQqQy1lHXgmhOJBiJ\nTrRp8yhGbyyDBKojp0czopNFz6UbPEWuwUeSH3M6FYCCiiSMH7obSZAUb1Lj8+oI1OoGxcRCWhnS\nj9+FjHfj9Ldjt+0c2DdoGWS+JgFAAhVOH1p53ZCn4c9et5xLVkyMgsXBiHAVMt6DE+9x20cfD3+Y\nkJahbFBBnKYJzl/SQMCn85d/soSg3yi4s4K7OqQ/kUXHxm/2HVUcmSfvkVClREJRNCHQhDgxkZCv\nSQgqkaAYA4RuuC5fSMqKFGVpQuD36Wp1g2JCkXnh5zi9zfgv/cRR1eJDRUKK+kHmPgGzFy0yOSyD\ntVAVTqIHGe9GK5JqOBI9ECEk0pQdURD3gYvm8O1Pnk9jdQi/Vx9Sn5TK2Fi2Q60eQyDRyoufu7wB\nU33VybefPl3QdVEQAMNxuqYblEgYJ7RcGNbAJnIMZRrwGSqSoJgwmDtfwNyxDu9ZV2NMXYIxc8UR\nA9x0QzxlkkhbLMjVGmg46KketEjpNGt6O4hwFTLWhczEi9YjHEldfQ0e4dCw4bvYnfsK2zVNFNKO\nfq8xpCYhmnRTDXWaW8shy+r57m/f5LfP7B5yzdjT3E9F2KvSDcNg6KJQlDgceZEQUiJBMRaInB2o\nIZxjLu8KeA1Vk6CYENi9LaSf/yl64wK8Z78PAH2Ku0Y9I90bnTTdOoT8yoYF012RUOdNIaSDiNSO\n9bRHBS1UBY77d6udQLpBD7orPpyu/WRevb/oGL9HH2KmlK9HmBVx/3sw6WfTnm4efukgn//hep55\noxnbcdjd3M/cpvLTyiPhZNE17YTSDYtmVHLekoaS6xcy2pxeR1tC5PuYG9gFd8UjUekGxUQh+8YD\noBn4L/kEQnOfyoRu4Fz+Rb7VfzUAMhdJ6Ohz6xGm15fh9+rMjrjbJ0u6YXAdwolEErScCZIIV2Mf\n2oTd13LUmCPTDXmR0BTMkpU6r+9zz+lnr1tOY1WQnz26g3+451W6+tPMaRredfB0R9dOrCZh+dwa\nPn516XQdHSuUSBgnCiJB2ESGiSQoMyXFRMDpOoDRuADtiLX68WATnU4ZjhQ4mYFIggCquzcyv9Jk\nVsitVZgs6QYtNCASTiiSMG0pwQ9+neCf3A66gbn58aPG+Lz6kHRDfvljYyBDrxPi6Y0tNFYHWTq7\nmr//8Apuu3oxhztdSyYTt4YAACAASURBVOy5SiQMS1XEr9Ixw6CWQI4ThXQDzrFFgs+gq//EWuwq\nFOOFtDI4/a0Ys1cdtS+RMgFBWhro2QGRUFOmYz57Nx+bcwGaLwA7DERo4vghDMdAJEEc0+BoyHih\noVe5TYM8c8/D3PkCvlUfQPjDhTFH1SQksggBFSJBjxEhY9qFGg8hBOcuaSCdtXj2zRam15d+98zx\n5PMfPgtNU+mYY6EiCeOEnjPvMIRN5BjphsAopxuslm1YrTtG7fMVpwdOTzNIiVZ9dAtdVyRAFg92\nxhW8Hb0p5pSbgMToP4Qea3P9BI5joTtREIEIaLrbm0E7uecwz9LLwM6S3fb0kO1+r47tSEzLbUYU\nTWYpC3iQiR7Ka900zfzpQ0XWxSum8tWPnXNCofTTGY+hox/Hy+J0Rp2ZcUIz3IuHgV1o5nQk/lEu\nXEytvZPUA/+ElM6ofYdi8hFPmfzogbfoT2Rx4t3Y7bsA0IuIhHg6Zx0sDZxCJCHJtKArGJyeQ9ht\nO9EbipsBTUSE0BChqoJF88mgV01FbzoD860nkfbAA4Iv58CazlqYlsOmPd1MrfYjk/3UTZ3Kpz+4\njFULJ0e6RlFaKJEwTuge1ybVEM5RlcfScUg9cRdndT9Iud2D7YzuTdxu2T6qn6+YXDy/qZWX3mpn\n674eEr/9Epn1vwJPAFFWc9TYRMq90WWkB2mmSWUsokmTBq8rGHBsMNPoUyZXQZhnwTvxzDv3lN7r\nXbYGmezD2ruhsM2fEwmZrM26TS30xjJcfVYlINHCVSyfW6OehhWjwpj8q+rt7eW2225jzZo1XHPN\nNXzqU5+ip8dtg/q73/2Oa665hve+9728//3v5/+z995RclR33vfnVujqMB0maTRB0qCAMggxIIxM\nMAYJTLCBtVdr42dtFp9lHdZr++DXYQ2vwYYlHLzex3iBddrHDwuv12CwAEuAjReTkySUs0bSzEia\n3NO5u6reP6rD9CTNSBM0o/s5h8Po3qqu2zU9Xd/7i++++27+vI0bN3LdddexevVqbr75Ztrb24c1\nNxlQ9UJ2Q1/sRJjMvrep6drIpe7t/Wq2jxYi22wnvfu1MXl9ydTkzW1HAGhva4dsgSR12uwB0+yi\nvSwJdjqZL8dcpvQUHafWLBjLJY87xvLrcC2+/ITOVeuWooRqSH2wHjvb3SnXFbYnnua5NxqZWxdk\nbiiXZimbN0nGjnERCUIIbrnlFtavX8/atWuZMWMGDzzwAJ2dndx999388pe/5JlnnuFLX/oSt99+\nOwCWZXHbbbdx++23s379ehoaGnjggQeOOzdZUPVcTMIAVoJeNe69IsnhYxH2NneP+hpybgbz8NZR\nf23J5OLwsR52Nx5faDe1RTl41Imaj7c7YsG48DO4P/KFAY/PxSQkbR3SiXyNhBKz22lwZPhQymeg\neAKj8TamBEII9KWrsNobMbMxQzl3w4vvHKKzJ8knPnwGdtT5fZ2IW0MiGS7jIhJCoRArVhRKtC5b\ntozm5mZs28a2baJRp3RoT08P06c7ndG2bNmCYRg0NDQAsGbNGtatW3fcuclC7zoJfbEzvUSCkuLx\nP+7m/sc3jH71xex17Hg3tiVTLU9nmp/7d5r+zz+TSiaHPO7NrUdQhKCusgSz+ygAavWCfK5/XyKJ\nnLtBg0ySo9meDa5kJyIwDeO8v8J17vWj+E6mBvq8CxFGCenN64GCu+HNbUc5sy7IwlmlWNFOYHhp\nlhLJiTLuKZCWZfH4449z2WWXUVZWxp133sn1119PIBDAsix+/etfA9DS0kJNTaEPe1lZGZZl0dXV\nNeRcKDRJ0qhU59YvnjXADiprSbCFgkekaG6LkjFt3tx2lI+cUzsql7ctE8wMwhvCjnVhx8PDSteS\nTE0q081UKF00vfh/OeOavxvwGMu2eWvbURadUUpF0IO6ux1coPSplNjWFeffntzMjZfMJhpPU+LR\nSdo6ajJMyeE3qPWVQaQNZfo8XIs+Mh5vb9IhNBfavAudAEbLxO0qfFV//KKsaycZBVVD6DLHXzJ2\njLtIuOuuu/B6vdx0001EIhEee+wxfvvb3zJ79myef/55vvzlL/P73/9+XNZSXl5y/IPGiLQWIgZc\ne+FMApXFecyxHoUYgDeEJ5wiYzp+yde3HuFTq07Md1vZ5xpWIkoEMCpqSRzsImSkMSpPv3zqvvfl\ndMS2LTrsHhJoVDT/BV/PpXhnL+t33NZ97bR1J/hfVy+iO5IksrObuPCy73Ccy88vCIUn/7Kfw60R\nfvbcdjwulcpSDx+0zuQ8VzvLO9ez3ABS4K+uIzRJ7v9EfE7CM+fQtuUFSo0U1nRnM7FkTjkXNzhZ\nJG2aRcblntDPsPz7GZqpcH/GVSTce++9NDY28vDDD6MoCq+++ip+v5/Zs2cD8LGPfYxvf/vbdHZ2\nUl1dTXNzoTxpR0cHiqIQCoWGnBsJ7e0RLMsenTc3QqyIYy3o6Y6QbC0O4kq3dTnHGCE8ogmAgM/F\n3sPdvLO5ifrpI/PfVlb6ae1zjZyp0vQ6EekdTU1o2umVQjXQfZnq2Jkk6V2vYzZvwzjvRpTgdBJd\nrejC5M/2h1iS2Y711L/ivfEunnjtKKvPn8G0Uqdb47rX9+PSFeZOL2FHYwa3GuFIyscfXtvH2Wc4\nVqieWIoX32pkyewyGo/00NadYHZNgLeba3lv4SW8//YmVpa1cm5ZD8nyBZPi/k/U5ySjOH/nbQf2\nI6oXcOGS6aw6b0Z+LfGeCLZqTNg9PB3/fkbCqXZ/FEWc0MZ43ETCgw8+yJYtW3j00UdxuZygvbq6\nOrZt20Z7ezvl5eW8+eablJSUUFpaSigUIpFI8O6779LQ0MATTzzBlVdeCcCSJUsGnZs0ZN0NmAPE\nGWRjBURJKZ72/YDN5efW8ezrB3hlYzP1V45CkFfWpZFrMWtFu07+NSWnLFY8THrzC06RnmQUhEqm\naRvuCz9DxPZhAHPPWszjb03jq9qzdL7wCC/vaiBU4uLalWeQMS3e2X6U5fMqcbs0qso8JJUe9mem\nsa8lTDJtYugqf3q/iVTGYs1l86gIujnaGafUb/D29mNE4hl29vhYuGwJnpVnTPQtOeVR/I51xgof\nw1W7qH/fgHQCoRkTsDLJ6cS4iITdu3fzyCOPUF9fz5o1awBHIDz00EPccsst3HTTTei6jsvl4sc/\n/jFCCIQQ3Hfffdxxxx0kk0lqa2u5//77AVAUZdC5yYLItorGSvebs3NpZSVl2MLGIENtpY/zFkzj\njW1H+dRlc4t8lCeCnXGuIfyVIAR2bPxEgp2IgOZCaANXmpSMPomXH8Vs2oo2azn60lUovlLif/x3\nEi8/ihKoA6C8ZiZzFlXyzPYj3ND2FqvcBgePOtalzfvaiSYyXLDYEZWVAZ2oGqO7agaZXTb7mrqZ\nXRvkj+8dZtncCmoqfADMmFaCbdsInMwIgGmlnvG/AZMQ4SsDRcUOHxtw3s6kQJciQTK2jItImDdv\nHjt3Dlz+9/Of/zyf//znB5xbvnw5a9euHfHcpCBrSbCHsCTogXJSgFdJUuZ3c8myWl7bcoS3tx/j\n4rNr+p83AnId+YTLi/AEsWOdJ/V6w76ubRP93ffRzjgX9wVrxuWaEqcBkz7/YtwXF/7WvJ/4HrGn\nf4Deug/TFgSmV3OZL8U/v38mdUorV3s38qujM4ClvLPjGCUenUX12Uj6Y3tQsJm7dCnK7gg7DnbR\n0hEjEk9z5YriyotCCFwuNd9wqCrrvpAMjVAUhL8Cs+MwqQ/Woy++rLC5AGlJkIwLskTXRKEM7m6w\n006Ht1w3OY9IURYwmFMboKbCxyubCvEYlm2fWFxFTiToBsIbGjd3g9XVjN3TOq6Wi9MdOxnFTvQ4\ndQl6IYSCPud8ADqsEspDPmoqfCyqL+O3USdluTJ5iGgizb6mMPNnhNBU5ysjs/89UF14zziLM2r8\nvLntCOvfPsjsmgDz6vp3HTQ0hdZsjYTKkLQkDBclMA3z0Ack33yczKHNRXN2JiktCZIxR4qECUII\n4VgTzEHcDaqW7wLn1zKUeHSEEFx8dg37msMcPubsyv7zDzv492e2jPj6+VoMWZEwXg9ts2m780Om\n//uWjC62mSHxl/8kve8dgH4iAch3bmy3/PizjcZWnTeTFDpJzU+F2sOOxi6OdcWpr3YitW3bInPg\nPbQZSxGawQ0Xzaa1K0FrV4KrVswcsPKiS1exAZ9bo8Sj95uXDEwuLgHo911hp5PSkiAZc6RImEg0\nI2/2LyKTRGhuhOH4dad5C/0dzpnnZCPsawkD0NoVz+/QRkQ27kFobpTxFAnN2wCwrbHrbilxSO/4\nM+ntL5N650kARKiqaN60LH71P8d411rITjEn3y73rDnlPPiVD+Mqq6ZSCfM/m5wMm1nTHZFgtR3E\njnWh1S8HYGF9GZctr2VOTYBz5hXXTMhh6E4xIBmPMDKUQOF3ZicixZOZJEJaEiRjzLjXSZAUEJpR\nVF0xR86MKFyO73Z6SWFnVup3vhS6epzzMpZN2hx5A6giS4IvhB0PY5vpYp/nKGNbFplcM6mBYjEk\no4Jt21it+0m979QbsRM9IASKvzjF9a1tR3l1cwuvch4zpxWnRgV9LhJl05l+7BBb9jl9VnKpt2br\nPgDU6jPzx9+0aj6WbaMMYEUAcOnOfmSajEcYEfqZK0E3SP7lV9jJaNGcnU6CtCRIxhhpSZhAhO7O\n7+iLyJoRheF8oV60sODj1VQFv1enM1tnwTStfI/5kWD3iknIp1r1tI74dUaC1d4IKacs70BuFsnJ\nYadipLb9idhTdxB7+k7sTAptrtOJUJRUINTCnsC0LNa+diBv+s9lHvRGBKbjJY5bpKgIuvPHWm2N\nYPgQJcVdHwcTCFCwJMh4hJEh3CW4Fl4KurufSCCdlNUWJWOOtCRMJPrQlgRcHkCgW8XHlJYYdPbk\nRIJN6gREgpNBIUB15Wsl2N3HIHRyWRNDXrLJcTUo5bOwpUgYVZIbn3UsB5kUSvlMjA//L/S5F2BF\nO8nseQMlVByPsHF3O0c743zxE0v4YF/7gMGGuc/FksoM7umFkt1mWyNqxawBYw8Gw5UVCVXS3XBC\nCMOHnSy4G2wzA7YJMo1YMsZIkTCBOJaEAWIScpYEoYDL028HEfIbxe6GE7Uk6AZCiHxAm5Vt2NOb\n5rYozW1RGhacfDVGs3k7Smktir8ca5Dcb8mJkd7xCkqwGvfFn0OpqM8/wBXdg1Jay/ZoKc/96h0+\ntHg6KxZX8ecNhyn1G5xzZsWgv9ucSLj5w+W45jrlwG0zg9VxGH3JFSNan0vGJJwUwvAVxyTkYopk\nTIJkjJHuholEcw0YuNg7tUkYXuyciT5Lqd/IuxsyJ+hucIRIdhdi+MDlxQr3FwkvvHOIR36/lVT6\n5LpE2mYas2UXas1CULSB60NIThg7Hkatno9aeUbRDl8Igfev7uKpzkUcbo3w+B93842fvMbWA51c\nsqwGVRn8K0AJOOJBRI7lgxqtziawMqgVs0a0PkOTMQkng3CXFG0WCjFF0t0gGVukSJhAhO7OVz7s\nTe/UJuHyYbU1YnY05edLSwx6YmnSGQvTtMiYFrY9sloJdiaR/4JxrAlVA1oSemIpTMvmwJGTq0Fu\nHtsHZgq1dhFouoxJGEXsTMoprOMZuFy3EArhaIqLzqrhzr87nysaZjB/RohLlg3dUVRoLic9tqc9\nP2a1NQKgVtSPaI0+j47X0Ah4ZfrjiSAMn1NOO0tOJMgUSMlYI0XCBCJ0A9JJku8+Rey5+wsP+l6p\nTfrcFVjhVmLP3IUVcb6sQ9kMh+5IMt8hcsTWhD451kqwakBLQk/ceZjvbe4e2ev3wWzaBkKgVc9H\nKFIkjCZ23EmHVQYRCRnTIprIEPC5qKss4VOXzeX/+cxygr7j+7NFSVn+cwdOPAK6GxEcmfvpYxfM\n4ra/OWdEcQySAk5MQi+3Y6/AY4lkLJEiYSLRDOx0AvPYPsymrZiHnYpqvVObXGd/DN8nfwC2TeKV\nX2Lbdj4NsjOSJJNNfxxpGmTfuu9KoAo70t4voDASy4qEpvCJvccsZvN2x1du+ECV7obRJCcSBrMk\n9GR/h4FhiIK+KCXl2L1FQnsjavlMJ15mBAR8rnydBcnIEUYJdiKa30jk3ZTSkiAZY6RImECE7oZM\nMr9DSG141plIFxdJUQLTMFZ8EvPwFjK7XqW0JCsSepJkrBOzJNh96r4rwSqw7X5pkJGcJaGpe8Qu\njd7XMo/uRatZ6Ayo0pIwmhxPJISjTpnvgHfkIkH4yrAiHdi2jW1ZWG0HUUYYjyA5eYTb52Qz5FKm\nMzJwUTI+SJEwkegG2LZT7VDVMY/sctIEbbPfDkFfdBlq9XwSb/wXQdUJZOzqSWLmLAkjdTdkinOs\nC2mQBZeDZdlE42lKPDrd0VQ+7XKkmEf3gG068Qjg5OubmRMWHZJijicSurMiIVhyYpYEzBQko1jd\nLU5cyQjjESQnjzCcYle5NMhcfxc0GbgoGVukSJhARPYP3I51oc25AOEJkHz7t85cnx2CEArui28G\n00R95zHAJpbMnHBMguPSKDw0cuVfewcvRhJpbGD+zBDgpEOeCFbXEecaZTOcAVUHbEcMSU4aa7iW\nhBNwN4iScucakfZ80KK0JEwA2RLtdiL7N5gLXNRlnQTJ2CJFwgSSFwK2jeILoS9djZUteTuQr1EJ\nVmGcdyPmwU0sMo6QSheEwcgDFxNFQkS4S8Dw5esXrH1tP69sdLpNzp/hiITDrScoEiLtTsMqj+OT\nzpd+lk2eRgU7HiajGKx7r2VA60w4lrUknIC7QeklEsy2RlB1lFD1yS1YMmJyfVwKloSs20GmQErG\nGCkSJpLeD2nDh2vRZZDt1zBYuVV94SUA1OvtxFOF4L+RiAQ7k8RO9CB8pUXjSqCQBvnH95t4/k1n\n51hd4SPgc52wJcGOtCN85YVgt2x5YNnk6eSwM0ni63+MeXgzYdPgv1/eyxN/3NNPKISjKQxdxXCp\nI76GKHHalduRdqy2AyjlMxDKyF9HcnLkOsLm4pdkCqRkvJAiYQIRvfyJwvAhXB5c2Up2g/3xC92N\n8FdSrXaRSBXM9enM8E33efN/sHhHqASnYXU7c4lkJv/6fo9ObYVvwPr+w7petAMl+7ABsu4GpCXh\nJMkc/IBM4wasrhbClhu/V+fFdw/xn+t2YFkFoRCOpgj4Tqw+gXD7QdWwetow2w7KeIQJQvGVgqqT\n2vS8U3kxnSurLutOSMaWEYmElpYWNm7cOFZrOf3oHXeQbebkOms1+tLVRR32+qKU1lKldBJP9rIk\njCAFMicE+tbzd9IgO8ikk0X9IEqyIqG5LYp1AsGGdqQ979uGXu4GaUk4KTIH3sv/nLRULm+YwTUX\nzuKVTS387NltROJp/mPtVt7deeyE4hHAKbQlSsoxD2+BdFzGI0wQwuXFc8WXsTqbiD17L1ZPW76s\nukQylgyrd0NzczNf//rX2bFjB0IINmzYwLp16/jLX/7CD3/4w7Fe45SlKCbA5cv+34v7Q38z5Hlq\nWR0VjR+QSqbyY73jE45HwZJQVTTu/Nsm2V5cVMnv1amp9JFMm3R0J6gYQSc/28pgR7vyvm3nDTgi\nQTZ5OnFsM0Pm4CaU0hqszmZq1E6iXp1LltVj6CpP/s8+PtjbTix58kJMm7mM9Ob1ACMuxywZPbSZ\nZ+NZ/TXi63+M1XEI4enflEsiGW2GZUm4/fbbufTSS3n//ffRNEdXrFy5ktdff31MFzfVKXI3uH3D\nPk8pq0UVFp5kocjNyCwJLYiS8n4ujZxoSHa05McMl4quqdRWOOsbicshfeA9Eq/8CrDzvm0gH5Mg\nayWcOGbrPkjFcTXcSGraIv47uiJfB+HqD9Xz6cvnkUiZXLliJgBVJ9EzwbXkChACFBWldOhSzpKx\nRatbjOdj33CqXrpksyzJ2DMsS8LmzZt59NFHURQlb97y+/309JxcPf/TngEsCcNBKa0DIJhuBZwv\n7d6Bi7Zt853/eIsrGur4yJIyzKhFbz1odR1BCU5nf0sYVRHMrHKyDnJpkGbXEcAZ83ucXX9vkXD2\n3AoA/vvPezjaEefLNywdcJ2JFx8C21mXUuRuyIkE6W44UexoF+AIu6alf8emHZu4updL4fKGGVx0\ndg2GrnLpshpKPCeeKqf4K9DPvAgr2lFwFUkmDK16Pt6P/3O/7rASyVgwLEtCeXk5jY2NRWN79uyh\nulqmQp0Mok92w3DJxRKUmF35sd4ioSuS4mhHjD1N3SRee4yWJwouIdu2sbqPoISq+fX6nfzXS7sL\na+iTBikAf3Z36nXrlPoNmnqlQR5o6eGDvW350tD91llZX/hZuhtGjG0Nbh0Kd3YA0BpT6MmmOPr7\nNE8y8u2ZvXjdJ9cV3rj483iu+sZJvYZk9FDL6tCq50/0MiSnAcMSCTfffDO33norTz75JJlMhmef\nfZavfe1rfOELXxjr9U1tcuZ+RSsqbHQ8hKpjIRBW4SHbWyQcaXce5G1dCazwUVLHGrEtJ1PBOroH\n0gmUsjo6e5K0dsWLXlsJVKFEHJGw5qPz+PTl87CTUdIH3qMmG7yYI54t5nToWISBEGrhPfV2N+R3\no1IkDIp5ZDeRX96K2X5owPmuNkckvL4nUujNcAJ1EIaLEEIGyUkkpyHDEgl/9Vd/xW233ca6deuo\nrq7md7/7HV/96le57rrrxnp9UxqhqKDqCMM74i9gEw3F6l0noZACeaTDKdvc1h13SvZaGeyeNgCS\n7z6F8ARQZq8gHE3R1ZMsEhhKsAo16hy7YFYpc2qDJN95ksQL/5s5wQzN7dF8el0uKO5Ay8DNn+xM\nCqVqLt6P/3Nx/EPekiDdDYORadoKZorU5hcGno/3kLA13t7RTjiWQlMV3CdQB0EikUiGYtg2yMsv\nv5zLL798LNdyWiI0Y0SuhhymUNFErzoJvUz+LVmR0BVJYXudFs9W9xGsaAdm83aMD/0NPSmFXDJj\nezjB9DInsE0JVqHteRMNE7dLdawIu14FoN7TQzpj09odp6rUSyzhPOT3t/TwkYEWmUmiBKejVs0t\nHpeBi8fFbN0PQGbvG1gXfArFXdxB0YpHiFoGx7rjbNnXjt+ry52+RCIZdYZlSXj22WfZu3cvAPv3\n7+emm27is5/9bH5MchLoRr4u+0iwhIZO72JKvdwNWZHgIp2v8W51HSH1zlMIXyn6wo/QFSk0a2rr\n5XJQAtMQ2JQrPbhdqiMQMo7Pu0o4Ju7mVqdlba5Ow/4jg1kSksW1ILIU3A3SkjAQtm1jtR5wel2Y\nGcxDm/sdI1IREsKDqggOt0bH1NUgkUhOX4YlEv71X/+VYNDJyb333ntZunQp559/Pt///vfHdHGn\nA8LlzXd4GwmW0NB7WRJSRTEJMUr9Bn4lkR9Lb38Z8+huXOdci9BcRSKhtbtwnBJ0giIr1R7cLg2z\nrRHhK0P4SvGnnDbSh9uipDIWpmVj6CrNbVGSqQEqPqaTiIFiLWTg4pDYsS7seDfa3BUAWNHOfsdo\nmRim7mXxGU6sh/8EKypKJBLJUAxLJHR0dFBRUUEymeS9997ja1/7Gl/60pfYsWPHWK9vymOsvAnj\nvBtGfJ6laMXuhkyuZbRJe3eCJWeUFYkEq/sIwl+BPv9iALojhUJMbd29LAnZWgmz9VZ0TcGOhxHe\nEEpZHaK7mfKAm+a2aN7VMH9mCNuGxqOFdNhtBzroCCccS8JA5aWlu2FIcq4GrXoB6B6nlXgfdDOO\npXs5b8E0YGyDFiUSyenLsERCWVkZjY2NvPLKKyxduhSXy0UymRyw45xkZGjV81HLZ474PEtoaBSs\nB5msSNh1qBsbWDq7nJDqiATXNOf1jeUfz9co6IokEUBF0E1bV0FMCMPHYe9CLjG2YXY2Y8e6nUDH\n0lqsrmbqKjw0tUbzrobF9c5Odn82ePHl9w/zwBMbee6NA5BJ9Wt5DdLdcDzMxo2guVDKZ6L4Qth9\nLAm2beMmAa4SzplXia4plAVkox+JRDL6DCtw8Ytf/CI33HADqqryox/9CIDXX3+dBQsWjOniJINj\nKwV3g64peUvCq5tb8BoaZ88tZ5/PmS9ZfiXhne+jzbswf35XJIXf56Kq1NMvDfKdko9wVXQP6Q/+\ngB3vRp02G7WsjrSZYV4wxdbGGJG4YwWoKvNSFjDY3xLmlU3N/PqFXQCEu7NpkUNYEqS7oT92IkJ6\nzxvoZ65EaC6EN4TVx5IQjSfxihSqpwSvW+P2z51HaYkUCRKJZPQZlki44YYbuOqqqwDweJxSoMuW\nLePBBx8cu5VJhsRWNDQcl4HHpZI2LaKJNO/tbOWis6vRNZVz6nQ4DOtaZ/DRKy4sOr8rkiTkczG7\nJsja1w/w7o5jNGRN192mm1ZRiberxWkp7QnkqzzOdIfJmGo+7dHr1jhjeoBNe9t5Z/sxlswuwzRt\nIhFnPmGq9Ht8CdUp8zuISPj5s9soD7q5cGk1B4/05Nd1OpDa8T9gptEXZ7uBekNYR3YVHRPu6MQP\naL4AUKiGKZFIJKPNsLtAplIp1q9fzyOPPMLTTz+NqqpUVlaO5dokQ2Cret6S4DY0UmmTt7cdJWNa\nXHSWUwlzRsAmIdz8aUNzv/O7IklCfoNrLqxnTk2Anz+3PZ/lkEiZRNQAVttBsG2EN4hSWg0IKnEy\nHHY3OamVXkOjvtpPMmWysL6UL1+/lMqQh1jUKbq07v2j/a4thABFH9SSsHFPG+vePsgjz2zlkd9v\nHbSi41TDtkzSW/+IWrMQtcwpt634Sp1Axl6uvXCn435w+2WDH4lEMrYMSyRs2LCBK664gieeeIKd\nO3fyxBNPsGrVKjZs2DDW65MMhqKjZVMgPYZG2rT4ywct1FX6mJXtxWDHuklrPrp7ZTIA7D7cxdHO\nOKESF7qmcOvHlwDwf1/chW3bJFIZYloQTMdSITxBp55DYBq+5DEEsOdwViS4NS5ZVssnL53DV248\nC5euUuY3SCecqoLlwQAAIABJREFUOIf2qDVw7IqqDRiTkEyZRBMZUmmL/S1hTMumsyfZ//wpSKZx\nA3a0A33JFfkx4SsFy8ROFqpadmarLXoDUiRIJJKxZVjuhrvvvps77riDq6++Oj/2/PPP84Mf/IAn\nn3xyzBYnGQK1EJPgcak0Ho0QT2ZY89F5+aI6djxMxuUnlsiQzljomkJ3JMn9j28kVOLi8oYZAJQH\n3Vx/0Rk88ac9vLPjGPGkSdJfCtlns/A6DyO1rBars4nK0gaOdTpWB4+hYegqV11QaCEc8hu4cARA\n3FRJpEw8RuGjtutQF9OVgUVCR48jLoQAbLCBtu4ElSNoTz1ZSW95EeGvQJu5LD8mvCEg29DJ7Wdv\nczfvbNrHEi8Ey8sHeymJRCIZFYZlSThw4EA+JiHH6tWrOXjw4JgsSjIM1GJLQjyZQVUEFyyuyh9i\nxcPYhuO3zjUB2rjHacj0jzeeRV1loT7DRxvqmFXl579e2k1PLEXKXZqfUzzOayiltVjho8wsd6IM\nVEXg0vp/hEr9Bi7hCICkrRGOFtItdx/u4r7/2kAsPXDgYnvYEQm3XLOIr37yLKC42NNUxWw/hNmy\nE9eijyKUwj1V8iKhk9bGfbzxu9/wEc92AFTPyOtrSCQSyUgYliVh1qxZPPfcc1x77bX5sXXr1jFj\nxoxhXaSzs5NvfvObHDx4EJfLxaxZs7jzzjs5cOBAUUGm9vZ2Kisr+d3vfgfAxo0buf3220kmk9TW\n1nL//fdTnt09DTV3OiB6xyRka/Yvm1tRlC9vx7sR0+YB0BNLUxZws2F3GxVBN7WVxcFuqqLwuasW\ncOd/voNtg+nu1drZ41gSlLIZYNvM9cd5F8fVMFAp4NISAyMrElK2Rnc0RVWZl55Yioef2Ypl25ho\nAwYudoQd88W82iAhv4EQjiVhqpPe8iKoLvT5FxWNC58jEuLrHsQNfFwHyx1An3UxouT0+bxLJJKJ\nYVgi4Tvf+Q633norv/71r6mpqaGpqYnGxkYefvjhYV1ECMEtt9zCihVOBbl7772XBx54gLvvvptn\nnnkmf9wXv/hFzj33XAAsy+K2227jnnvuoaGhgZ/+9Kc88MAD3HPPPUPOnTZoOpowudq7kdk9Om+w\nmA+fVWjdbWeSkE6g+ZwHfE8sRSKVYduBTj5yTu2AD/dZ0/1c0TCDF945BN6Qk4WgqKC7AVCywXQz\njDBg4DUG/viUBgxcwhEAKRxLgmXb/Mez2+iJpfAaGhnUQURCAoHjstBUhTK/UVTsaSqS2voS6Z2v\noC+6zGnX3YucuwHgv2Mf4tKrLuOMM+fKPg0SiWRcGJa7Yfny5bz44ot85jOfYfHixdx000288MIL\nLF++fFgXCYVCeYEATvpkc3NxxH17ezuvvfYaH//4xwHYsmULhmHQ0NAAwJo1a1i3bt1x504XhOpC\nx2SudoTqzCGqy70smV1ox2zHnBREV8AZC8dSbN3fSca0WDavYtDX/cRFZ7B0djlnzipDlJQhvIH8\nA0kJVoGiUmE7gXOeQUSC19DwqE5GQs6S8Ic3G9myr4O/+eg8KoJuTBRsq39MQns4kRcIAOVBz5S2\nJNjJKMnXH0OdcRbGBWv6zQtVx/epe7gz/lmU+Zcwe/48KRAkEsm4MewukMFgMP8APxksy+Lxxx/n\nsssuKxp/+umnWblyJRUVzgOspaWFmpqa/HxZWRmWZdHV1TXkXCgU4nRA0XRUYeNVUpRoKnd9dgVK\nr4eHHXeyDzyBUqCLnlia7cc68bk15tUNHhXvdml87VNnAxDbUVO02xeKhhKqxps4iiJq8LoH/vgI\nIQg5xgdSaGzZ184H+9o5f+E0Lj2nllc3HyGT0SCdxLQswtE0pX4nzqEjnCyqHlgZdLOtsX/vgqmC\n1dMGto0+/6KB+1wABKbTEd9OqESWXpZIJOPLoCLh05/+9LB2LI899tiILnjXXXfh9Xq56aabisaf\neuopvv71r4/otU6W8vLJG/jV4XdiCkpEEpFRqJoWKJqPdqSJAdNn1aKp3aQs+GBfB+ctmk719OGl\nzpk3/hPYNqqv0KbYqq4neXgns2svoXaan8pK/4DnLqwrgSbw+nxs2tuOEPDVvzmXgM+Fx63RkZhG\n9ZENHFn3M+7ZMZdf/b9X4zE0uqIp5tQG8687sybI61uPECr1omvqCdypoRls/eNFtDNODCirm4F7\nkLV09SSxgeoh7vdoMdH341RF3peBkfdlaKbC/RlUJHzyk58c9Yvde++9+VgGpVcE98aNG+nu7uaS\nSy7Jj1VXVxe5JDo6OlAUhVAoNOTcSGhvj2BZk7P/RDIDOuAlgZWEY8fCRaIudeQIAN1JnWCJweub\nmuiJpVg4M0Rra88gr9oX4fwXKxyf9laR6X6Vr3xqLprHN+hrza0ySDWB4XZDT5SaCh/JWJLWWBLb\nsnlZuZBzzq4msOl5bjb20njwAsqCHlo745w9uzz/uoYqsG3Yc6CdiuDopkFWVvpHcC/GhlRzEwDd\nGTc9g6zlcKtTI0FY1piu91S4H6ci8r4MjLwvQ3Oq3R9FESe0MR5UJFx//fUntaC+PPjgg2zZsoVH\nH30Ul6vYbPrkk09y3XXXoWmF5SxZsoREIsG7775LQ0MDTzzxBFdeeeVx504XlKxpWhHZYgKZZD7A\nEJwaCQDCEyDoM9jX3I2qCJacUTbQyw0bNVue2ZtsRQ0NbpGw00nQXAR9Bodao8ypKRyrqQqJFBgr\nPsXWg2Hmdb5KONJNj66RMa0id0MucyOZnppVF+1oBygqwhMY9JiemOPy8ctOjxKJZJwZMibh5Zdf\n5uWXX+bOO+/sN3f77bfz0Y9+tGj3Pxi7d+/mkUceob6+njVrnOCsuro6HnroIRKJBM8//zy/+c1v\nis5RFIX77ruPO+64oyjN8Xhzpwuqrhf9207FEUUioRsMH0LVCGZ92QtnlQ4abDhcchkOZsdh1Kq5\ngx+YSSI0g4DPufbc2t4iQZDOOBacbuE8HJOxOKls18qyQOF9uHRHJKTShbbYUwkr0oHwlSLE4DHE\nuRoXAa8+6DESiUQyFgz5xPjFL37BV7/61QHnrrvuOv7t3/5tWCJh3rx57Ny5c8A5t9vNe++9N+Dc\n8uXLWbt27YjnTgdUvXhXaafjQKEAkh0Po2TrGwSzQYFDZTUMF+GvAEXFDh8b8jg7nQS9IBLm1BZ2\nyqqqYFqOZSBuZkVAIkbUdmoklPcSCe6sSEikpqZIsKMdKL6BrTumZaEqirQkSCSSCWNIkbB37958\nmmFfzj33XPbs2TMmi5Icn74igVRxmqAdD+dN2KFsG+Flc0dBJAgF4fJip4+TlphJITSDc8+sJJky\nmV7mzU9pqsg3bYpllOzyE3Qkc5aEgrvByLsbpqZIsCIdqFVz+o1v3tfO/37yA65aMQsbGwGUeKQl\nQSKRjC9DioREIkEkEqGkpH+wQzQaJZGYuvnrpzqqbtDbS2+nYkXzVqwbtcLpp3DVhfVU+F1FZvyT\nQndjp4YucGRnkqAZzKkNMqe2OHZBUxQypuNuiGZFQiYRpz2dwKUpRQ/DqexusG0ra0k4r9/c2tcO\nAIK1rx/A79XxeXQURdZHkEgk48uQxZQWLVrE+vXrB5x78cUXWbhw4ZgsSnJ8tD7Bn30f2na8O9+Y\nqaaihAuXVDNaCJcbhmNJ0I0BpzRNyVsSoumsSEgm6OhJUhpwF2VpGLozn5yC7gY7HgbLRJQUuxt2\nH+5iT1M3n7x0Dh5DpSeWzrttJBKJZDwZ0pLw93//9/zTP/0T4XCYVatWUVlZSWtrKy+88AI//elP\n+dGPfjRe65T0oZ+7oddD27YykE70K/E7WgjdM6QlwbYymB2H0erPHXBeU0TekhBJCdAgk0rQEU5Q\nHigWFm6X8xFNTEVLQrQLANEnJmHdWwfxuTUuPruGD/a1s3V/B37papBIJBPAkCLhoosu4oc//CH3\n3nsv9913X368urqaH/zgB3z4wx8e8wVKBqZvdb7e7obcA1y4vIwJLg92rGvQafPIbkjF0GadPeC8\npiqYWUtCT9oRCWYqSXs4wdLZxU2LcpaEKeluSGbrH/QScy3tUTbubuOaC+sxXCpza4OOSJCWBIlE\nMgEcNx/uyiuv5Morr2Tfvn35ssezZ88ej7VJhkCofVMge5n/k45gGCuRIHQ31hDuhkzjRlA0tLol\nA86rqmNJsG2bcFIBD2SSccKRFGX+YkuCpioIMTUDF3PCrvfvaf3bB9E0hY+e69SjyKWO+mX6o0Qi\nmQCGnTQvhcEphtb7oSGyKZAOdjLqjBpjJRI8MIS7wTy4CbVmQVHdht7oqoJl2yRSJknLsRTEojFs\nitMfwekDYejqlEyBtPuIue5Ikte3HOHDZ9XkYxBm1wTQNYWK0Qo6lUgkkhEwrC6QklOQXpYE4fEX\nPbTzrgfDNzbXdrmLLRe9sBMRrO4jqDWDB7WqqhOYGImnSWd1ajLmrLks2P9haLjUU97dkNz4LGb7\noRGd09PluGx2H3WKJb303mFM02b1eTPyx3gMje/ffD6XZS0LEolEMp5IkTBJybkbbM1w6hYMIBLG\nzN3g8oCZwrb6P7jN9oMA+fTLgci1gY7E09gIUraKYjkFg/paEgAMXT2lyzLbmSSpt39LatPzIzov\nGg5j2oL39nUTT2Z4+f0mls+vpKqs+Pc2vcyLoY9+cyuJRCI5HidXo1cycWRFguLyOIGERe6GsY9J\nAJyMij7WCqu90VnXMERCrpJgytYwRAYg3zK6N4auntIpkHbCCUA0D2/Btq1BSyzbtl2U3pmJR4jb\nLrY1dlGxqZlYMsOVK2aOy5olEolkOAwqEg4fPkxdnWPiPHRocDOqrutUVFQUNWeSjAOKCgiE7ka4\nilMS8yJhLGMSyPaL6CMSzLaDCF8ZinvwFqla3t3gmNkzQkcXJiUefcAds2NJOPVFgp3owWo/iFpR\n3++Y6G//GX3ehbjO/lh+zErGiNkumtuiPPtGI2fWBYsaYUkkEslEM+iT/dprr2XDhg0AXHHFFQgh\nsO2B2yq73W5uu+02PvOZz4zNKiX9EEKAqoHL49QtiIULk6kYCAW0gYsZnTSurEhI9w9etNoaUcqH\n3g33tSRYio5LZAZ0NYATkxBPZk5mxWNKTiQAZA5t6ScS7FQMq+MwqS0voS+9EpFrk56KEbedAEXb\ntrlp9fzxWrJEIpEMi0FFQk4gAOzYsWPQF7Btm507d/K5z31OioTxRtUd07/L3adOQgxh+IpM26OJ\nyImEvv0iMkms7hZcs/uXGe5N78BFAFs1MMgU9WzojaGrdEWSJ7vsMSNX7wDdjXl4C5xzTdG8Felw\njot2YDZvy6eGKuk4luZhzWVzWVhfRl3l2BS/kkgkkhPlpAMXhRAsWLBgwHbSkrFFqDrC5UHxlmLH\nurGyBY7sZAzGqpASvWMSii0JVvshsG2UiuNYEpRiS4LQXegiM2hvCUNXJkVMglZ/LubR3f2aX9mR\n9vzP6V2v5n/WzDim6mHV+TOZMU0KBIlEcuoxqCXh05/+9LB2oo899hgAq1atGr1VSYaF8AYRvlL0\nMz9MauNzpLf+EeO8G7OWhLETCegDWxLymQ3lgwctQnF2A4CiGxgiOri7YZLEJOhzLyCz+zXM5u1o\ns87Jz+csCdqsc8jsf8/5/bi86FYS2+2ZkDVLJBLJcBhUJHzyk5/M/3zw4EGefPJJrr/+empqamhu\nbubpp5/mxhtvHJdFSgbGc9U3EJoL4fKgzVpGetvLuM65BjsZHbuSzGQbPNE/JsFqawTDhygpH+i0\nPJqWdTfEUmiqQNHduMTA7gbbtjFcp7hISEZAd6PWLADNRebQliKRYEfaQSi4ll1NpnED6b1v41p4\nKQapMf09SSQSyckyqEi4/vrr8z9/6lOf4uc//znz5s3Lj1177bV85zvf4R//8R/HdoWSQVG8hUh4\n/awrnQfQrtcgFUP4Ssfsujl3g9m0jUxJed7HbrY1olbMOq4FKu9uiKdxuzQ0txudDNXlxZkSqa0v\nkXzz/+MCo5aX0iuxbBtljOIsTgY7EUG4SxCqjlqzkMzhLUXzVqQd4StFmTYHpbSG9K5XsWatQBcm\nqnuMCl5JJBLJKDCsmIS9e/cyc2axn7muro59+/aNyaIkI0edfiZK5WxSm9c7loRxcDdk9r5F/I//\njm2Z2FYGq+PwcTMboNjd4DFUAoESyjyin18+c2gLmGnKYgcoU6KkT9GCSnYygsimfGp1S7DDR7HC\nxwrz0Q6UknKEEOhnXoR1dA+Rw7sA0L2Dp4pKJBLJRDMskXDeeefxrW99iwMHDpBIJNi/fz/f/e53\naWhoGOv1SYaJEALXWVdidx/FjofBNXY71HwKH0Ayinl0D1ZnC1iZISst5uid3eBxaQjdQFipfsdZ\nHYcg2+3SEOlTtl20nYjk60VodUsBiqwJVqSdo0k3B46E0eZ9CISCvf2PABg+GbAokUhOXYYlEv7l\nX/4FgGuuuYZzzjmHa6+9FsuyuPvuu8d0cZKRoZ1xbj4eYEwtCb0RKpnGjYVKi8cJWgSnwROAbYPb\n0BCaAZkUtl2wFNjJKHakHXX6mYAjEk7VuIScuwFABKsQ/gonFRKwLQs72smGZoun/mcfijeEOmMp\n7qMfAOD2ByZs3RKJRHI8hlUmMRQK8aMf/QjLsujo6KCsrAxFUbCsU9P8e7oiFBXX0lUk33h83ALi\n1JoFmAc3gpUBzYUSnH78c9RCXIHHpRaKPmXSoDs/55olqdPPxDy8BbfIkDpF0yAdkeC4DYQQaLVL\nSO99E9vKYLbsAsukzfKz7UAnPbEUnrOuIn5wEwAlQSkSJBLJqcuI6iQoikJFRQW7d+/m3nvv5eKL\nLx6rdUlOEH3BJWhzLkCtHbwL42jgufbbeG+8C23WMqyuFjIH3kcpn1nsihiEXEwCOF0OhZ6tOphx\nCibZ6QTmsT0AqNOdYNm+7oY3tx7hqVcmPibGNjOQjiOMgttAnbEE0gnMQ5tJ/Pk/iBvlvJ+sx7Jt\n3tvVilazgDZPPQC+0NCZIBKJRDKRDLvhQkdHB2vXruXpp59mx44dnHvuuXz3u98dy7VJTgChu/F8\n9NYxv45W7ZQQFi43ydcfw460o808e3jn9hIJeXcDQDJGcuerpDb8HtIJhNuft0y4RZruXlUX39p2\nlIPHItxw8exRekcnRq7aouiVpaDVLgKhkHjll9jxMK9WfBZ32KDU0Hhn+zEuXVbL895PQLyRLwUq\nJ2rpEolEclyGFAnpdJo//elP/O53v+PVV19l5syZXH311TQ3N/PjH/+Y8nK5CzrdUfyVKKV1WJ2H\nh+z82BttEHdDbO092PFu1JnLUErKUILT8+mWPi3D1v0dnDt/GgDhWIrUKRCjYMednhnCXXAbCJcX\nddoczKO7UWecxcbmEmZVuZk13c9zbxygO5qiLZwmEKqfmEVLJBLJMBlSJKxcuRIhBDfccANf+cpX\nWLx4MQCPP/74uCxOMjnQZi0j1Xn4uJUW88f3tSRkg/7Q3XguubnIIpELZqwLafx+X3u+3XJ3NHVK\nBDJaPa0AKP6KonF1xlKnRPPCK2j+oI1l8yo4f+E0nn39AO/uOEZbd5zZNTIeQSKRnNoMKRLmz5/P\ne++9x6ZNm5g1axZ1dXUEg7KVraQYfcnl4HIft2dDjr6WBLVmIZ6rv4k6fR5C1YuOFUIB3U11QKW9\nKUlze4yaci/haIqMaWNaFuow4iDGCjvcBoASmFY07lpyBUqoml9sEtjYLJtbSV1lCTUVPv7yQTPR\nRIby4MBlqCUSieRUYchv11//+te8+OKLrFy5kl/84hesXLmSW2+9lVgsRiZz6rbulYwvijeEsewa\n54E+DHo/1D2Gls0IWNRPIOQQupvKrMt/8952YskMGdNpW55MTWyGjdVzzCkuZRTXpRAuD4fc83lr\n+zE+vvKMvNXg/AXTOHjUiWOokCJBIpGc4hz3W722tpYvfelLvPDCC/zqV7+isrISRVG47rrruO++\n+8ZjjZIphqKIfHllt2sYsbO6Gxdpait9bN7XTjhaKLw00S4HK9yKEqgcsBR1d9QJtDx7bsEVcd7C\ngsVhsIZWEolEcqowIjttQ0MDd911F6+99hrf+9732LVr11itSzLFyTV58hjqcY8VLg92OsFZs8vZ\ndaiLox2FxlITLRLsnjYU/8AZComkszZ3r/dYXe7Ll5+WlgSJRHKqc0LOXMMwuOaaa/jZz3422uuR\nnCbkmjx5jONbEoTuhnSCpbPLMS2bN7cdyc8lJ7DAkm1bWD2tiEAlkXgas09xsXjKccn1tZZ8ZHkt\nNRU+/D7XuK1VIpFIToSJi/iSnNbkghfdrmFYEnQ3djrO3LogbpfK+7va8nMTaUmwY91gpsFXwbcf\neYP1bx8qmo8nHZHg6fMeL11Wyw9uWXFKdrSUSCSS3kiRIJkQVHX4lgR0N3YqgaYqLK4vI2MWduwT\nWSshl/4YVgJEExk27m4rmk+kTFRFoGvyz0wikUxO5LeXZELINXnyDCNwMeduAFg6p7iAV2IC3Q2Z\nfe+AUDliOWva1xwmlihk/SSSJm6XOmBQo0QikUwGpEiQTAiqKhACXPrxP4JO4KITrLjkjDKgEPA4\nUe4GOxklveMVtLkXcDjqCB3Lttl5qDN/TDyVGZ6lRCKRSE5RpEiQTAiaquBxacPbZetuMDPYVoay\ngJszqgPMnOZ0XZwod0N671uQSeJauooj7TFKPDouTWHbgV4iIZkZXoqnRCKRnKKMi0jo7OzkC1/4\nAqtXr+baa6/ly1/+Mh0dHQB0dXXx9a9/ndWrV3P11Vfzk5/8JH/exo0bue6661i9ejU333wz7e3t\nw5qTnPpoqhhW+iOQ799AynE5fP2vz+bvP+6UCE+mJ6aYkhVuBVVDKZ/JkY4YtRU+zpwRYtuBjvwx\niZRZlP4okUgkk41xEQlCCG655RbWr1/P2rVrmTFjBg888AAA3/rWtzjrrLNYv349zz33HH/9138N\ngGVZ3Hbbbdx+++2sX7+ehoaG/DlDzUkmB5qq4B6mKT4nEnIuB59bJ5BNH5wwd0O8G+EJIoSgpT1K\ndbmXRfVltLTH6OxxiijFk5lhxVxIJBLJqcq4iIRQKMSKFSvy/162bBnNzc0cOHCAXbt28bd/+7f5\nucpKpzDNli1bMAyDhoYGANasWcO6deuOOyeZHPjcOsHh1glw5URCIj+kCIFLUyasToId60Z4g/TE\nUkQTGaaXeVlUXwqQtybEU+awrSUSiURyKjLu2xzLsnj88ce57LLL2LNnD1VVVXz3u99l+/btVFRU\n8M1vfpN58+bR0tJCTU1N/ryysjIsy6Krq2vIuVAoNN5vSXICfHb1fGzbHtaxQvc4P6QSReMuXZ1Q\nS4Lir6Q17KypIuShbloJfq/OtgMdrFxaTSIlYxIkEsnkZty/we666y68Xi833XQTL730Eps2beIb\n3/gGDQ0NvPDCC/zDP/wDL7300rispby8ZFyucypQWemf6CUUMZL1JDNVNAF+PY2v13let4ZQlZN6\nb8M510xEUXQDoRb+XKKJMJ76RQjNGauvC1E1LcA5Z05j8942KipKSKZMykKeU+7eD8VkWut4Iu/L\nwMj7MjRT4f6Mq0i49957aWxs5OGHH0ZRFKqrq6murs67DVatWsVtt91GR0cH1dXVNDc358/t6OhA\nURRCodCQcyOhvT2CZQ1vNzuZqaz009raM9HLOGFsyxFznYcOECtflB/XVIXunsQJv7fh3Bezq5nY\nf38XhIr70lvQ516AbWWwYmGSwsvBpi4ArHSG1tYeZlf7eWVjExu2HSGRMrFNa9Lc+8n+ORkr5H0Z\nGHlfhuZUuz+KIk5oYzxuKZAPPvggW7Zs4aGHHsLlcnzRS5Yswev1snv3bgDeeecdgsEgpaWlLFmy\nhEQiwbvvvgvAE088wZVXXpk/b7A5ydRDuLwITwA7fKRo3NCVMXc3mE3bwbZRApUkX38MOxXDjjt/\n+MITpDvbkTIXX5GLS3h/l1ONsW9JZolEIplMjIslYffu3TzyyCPU19ezZs0aAOrq6njooYe4++67\n+fa3v00qlcLj8fCTn/wEIQRCCO677z7uuOMOkskktbW13H///QAoijLonGRqogSqsLqPFo0Zukpq\njAMXzaN7EJ4g7sv+nthT3yf5/u/R51wAgPAG6W5K4TU0dM0RAxVBD9NKPby38xjAsDM4JBKJ5FRk\nXL7B5s2bx86dOwecW7p0Kb/97W8HnFu+fDlr164d8Zxk6iGCVZiHtxSNGbpKZyQ5ptc1j+5BrZqL\nWlGPPv8i0ptfRPE6bi3FG6Q7GidYUpylsai+jD9vaAKG2ZtCIpFITlFkxUXJpEAJVmHHuorSIA2X\nOqbFlKxYN3ZPK2rVXABc590Imk7y3acAx90QjiT7pXIuzrocQLobJBLJ5EaKBMmkQAlOByhyObh0\ndUzLMptH9zjXzooExRvEdc51kHHiEITXiUkI9BEJC2aVkis2LVMgJRLJZEaKBMmkQAlWAWCFCyLB\n0NUxLaZktuwEVUetrM+PuZZegQhMA8OHUHW6oymCPqPoPJ9bp77aSX2SZZklEslkRm5zJJMCJZAV\nCV2FDAdjjIspmS07UKvmIlQ9PyZUHc8VX8bsPkZbV5xEyuwXkwBOXML+lh5ZllkikUxq5DeYZFIg\ndAPhDRVZEjyGimnZJFMmxij7/u1kFKv9EK5zP9FvTi2fyZ8PKDz2mzcABiwvffm5dZR4dMoCRr85\niUQimSxId4Nk0qAEi9MgQyXOA7hrDDIczJZdgI1aPX/A+cOtkfzPfm9/kRAsMVh9/szhtcKWSCSS\nUxQpEiSTBiU4HbuXSCj1j6FIaN0HQkGdNnvA+d6P/ppy76hfXyKRSE4FpLtBMmlQglXYiR7sZBRh\n+PKWhLGolWBFOxHeEEIbuFNlJJGhutzL928+H02VWlsikUxN5LebZNIgchkOWWtC3t3Qkxr1a9nR\nToRv8F6cevU6AAAbYklEQVQg0Xgan1uXAkEikUxp5DecZNKgBLK1ErLBix5DxdDVMXE32LFOFG/p\noPPRRBqfWxriJBLJ1EaKBMmkQQlUAiJvSRBCECpxjYlIsKKdCN8QIiGepsSjDzovkUgkUwEpEiST\nBqG5ECVlWN2FWgmhEoOuntEVCXY6Aan4kCIhksjgkyJBIpFMcaRIkEwqlOD04jRIvzHqgYt2tNO5\n1iAiIWNaJFOmdDdIJJIpjxQJkklFrlaCbdsAlJYYdEVS+X+PBlZWJAxmSYgmMgDSkiCRSKY8UiRI\nJhVKoApSMeykU8woVOIinbGIJTP9jt3b3M2/P70FyxqZgMhbEgYJXIzG04DTo0EikUimMlIkSCYV\nSshJg8wVVQpk+yZ0R/qnQW7e2847O46NOLDRih3PkpAVCR7pbpBIJFMbKRIkk4p8GmQ2eNFrOLv5\neKq/JSEcdYRDTyw9omvY0U5weRH6wH0XIllLgsxukEgkUx0pEiSTChGoAKHkgxfd2cZOiWT/bpDd\neZEw/GJLtm1jNu9ACVUPekw0no1JkO4GiUQyxZEiQTKpEIqG8FeQ2vQH4i/9FI/hmPzjA8Qk5CwJ\n4RGIBLNpK1ZnE65Flw16TN7dIEWCRCKZ4kiRIJl0GA3Xo/grMFt24MlaEgZyN+QsCeHo8N0Nqc3r\nEZ4g2pwVReO5tMdU2iQcS6EIgccY3fbUEolEcqohI68kkw597oew2g+R2rweI+duSBW7G2zb7hWT\nMDxLgtnZhHloM66GGxBq4U8jEk/znUffzMciAAS8umwDLZFIpjxSJEgmJ4YPLBO34oiDRB93QyJl\nkspYwPADF9ObXwBVR1/0kaLxv3zQTCSe5rqV9bh0Fdu2mVnlH4U3IZFIJKc2UiRIJiXC8AGgZuLo\nmkK8jyUhZ0WA4cUkWIke0rtfR5+3EsVdEACWZfOn95pYMDPEJy6aPUqrl0gkksmBjEmQTEqE4QXA\nTkXxuNR+loRcPIKmimG5G9LbXgYzjb50VdH4vpYw7eEElyyrHaWVSyQSyeRBigTJpES4HEuCnYzh\nNrRBLQk15b7jBi7aVob01j+izliKWlpTNNfcFgXgjJrAaC1dIpFIJg1SJEgmJTl3g52M4nFpg1oS\n6qaV0BMf2pJgx8LY8W60+nP7zbW0R9E1hYqAe5RWLpFIJJMHKRIkk5Kcu4FkFLdL7WdJ6I4mUYSg\nutxLKu2kLw6K6VgahObqN9XSHmN6mRdFkZkMEonk9EOKBMmkpGBJiOEx+lsSwtEUfp9OwOc8+IcK\nXrSzIgG1f3Gk5rYo1eXeUVq1RCKRTC6kSJBMTlweQGCnorgNtV8xpe5IiqDXRcB7fJFQsCQUi4RU\n2qS9O0F1uW9Uly6RSCSTBSkSJJMSIRRweQoxCX0DF2MpAiWuvCWhZ4jgxYIlodjdcKQjhg3SkiCR\nSE5bpEiQTFqE4ctmN6jEk31jElIEfS78Xsc6MGQaZGZgd0Nzu5PZUCMtCRKJ5DRFigTJpEUYXuxk\nFLdLI2NapLMVFnMlmQM+F/5huRucOdFHJBztiCOAaaWeMVm/RCKRnOpIkSCZtAjDh52K5Zs8JbJx\nCbFkhoxpE/QZGLqKoatDlmYeLHDxaEeMsoAbly4bOUkkktMTKRIkkxbh8kIyWmgXnY1L6I44loGA\nz3no+7360JaEzMCBi0c6Ykwvk1YEiURy+iJFgmTS4sQkOO4GKDR5ylVbDPoMAAI+Vz9LghVu5chv\n7iHyn1/GTvQ4g0qhlYlt2xztjFNVJoMWJRLJ6cu4NHjq7Ozkm9/8JgcPHsTlcjFr1izuvPNOysrK\nmD9/PmeeeSaK4uiV++67j/nz5wPwpz/9ifvuuw/TNFm8eDH33HMPHo/nuHOS04N84KLL+ezkMhy6\n8yLBiUfwe3Q6e5L589K7Xyfxyq/ysQhWpN2Z6GVJ6ImliSczUiRIJJLTmnGxJAghuOWWW1i/fj1r\n165lxowZPPDAA/n5J554gmeeeYZnnnkmLxCi0Sjf+973ePjhh3nxxRfx+Xz8/Oc/P+6c5DTC8IKV\nwavZABxoCQMFS0Iu/dHvc+XdDbZlknzrNyhltZSvutkZS0SA4sDFIx0xAKZLkSCRSE5jxkUkhEIh\nVqxYkf/3smXLaG5uHvKcV155hSVLllBfXw/AmjVr+MMf/nDcOcnpQ67JU11QcOaMEP9/e/ceXFV5\n7nH8u9a+5G5CQihJ4BjlEnJKW+KlKNRiMbUiCnbqJZ7BmTMVL4y01jrtEFHUMLampUwvZgwKg85U\nQy0qM9ACUw7lWC+AFFpALYSeikhSJuRGLiTZO3udPzbZScjaO+S2s/fO7/MPyVp73Z5JFk/e93nf\nd9PuE2zfe5KGlnYcpkFSvL+h7LJEf3eDZVl0nv4Iq7UB96yFuNL9izlZ7f6hjj0LF89cSBLUkiAi\nY1lYuht68vl8VFRUMH/+/MC2++67j87OTr7+9a/zve99D7fbTXV1NdnZ3SvyZWdnU11dDRByn4wd\nXVMzm97zPH7PV1i/7RN+v+efJMY5uSzJjWH411u4LNFFp8+itd2Lefw9iEuiM2smhlUDXGhJMEwM\ns3sUw7/rW3GYhhZ2EpExLexJwurVq0lMTGTJkiUA7Nmzh6ysLJqbm/nRj35EWVkZjz32WFjuJSMj\nOSzXiQSZmSmjfQvDrrVpPP8GUhMsErLSePL+69i47SO2/O8/yc5MCjxz9kT/Ms9Ow0P7v/7KAe90\n/rrlH6y+MwcA09uK5XT3ilFDi4fszCS+8IWxtUR0LP6cDAfFxZ7iElosxCesSUJpaSknT56kvLw8\nUKiYlZUFQHJyMnfddRcbN24MbN+3b1/g2KqqqsBnQ+0biNraZnw+a9DPEy0yM1OoqWka7dsYdp1t\n/paChjNnaU7wP9+i6y9nfIqbOJez+5k7/QWN//PGm9zg8/J+65X8X0Mdje3+1ihvaxOG6ewVo8+q\nz5GZlhCTcQsmVn9Ohkpxsae4hBZp8TFNY1B/GIdtCOTatWs5evQoZWVluN3+grLGxkba2toA8Hq9\n7Ny5k/z8fABuuOEGjhw5wqeffgr4ixsXLFjQ7z4ZOwIrQXa09No+Z2YWV+dlBr7vWuQp59xhmlzj\nuffuQgA++sxfsEh7K+faLfZ9fAYA34XhjypaFJGxLiwtCZWVlaxbt47c3FyKiooAmDRpEkuXLmXV\nqlUYhoHX66WgoIBHH30U8LcslJSU8NBDD+Hz+cjPz2flypX97pOxw3D7/xMPFB4GkT0+icVfSeTK\nUzW4C+7GnZNKarKbQ/9s5HL/GWjrNNnwh0+YMC6BlEQX3k4fX9BESiIyxoUlSZg2bRrHjh2z3bd1\n69agxxUWFlJYWDjgfTJGBJKE1qAf8TXX4fngdW5OiMNrGLimXY9hGHzpigz+euIMd1zIA7yWA2+n\njxfeOsKd86YAGv4oIqIZFyVqGWb3ctHBdJ7+CO+/DuA9/h6OSTMxk8YB8KUpGZw734ll+H8FPDi4\nbU4uzec9vLrjH4CGP4qIKEmQqNY1NXMwvpY6/xcOJ+4vdrc8/WfuOEzDwGv450bwWiZTcy7jvxfM\noMPrI87tCMzYKCIyVoV9CKTIcDLcoZMEq+ksRmIaSf+11t/ycEFSvIu8y9NpP+fAhb8lIclhcv0X\nJ3K2sY1zzR2BeRZERMYqJQkS1Yy4RKyOUDUJtRjJGb0ShC5XzZjA+Q8cJDv8NQkup38ypdvn5I7U\n7YqIRBV1N0hUM+KSIFR3Q9NZzJTxtvsmjEugw/LnyR4cuJz6dRAR6UlvRYlqRlxi0O4Gy+fDaq4N\nmiS4XY5AkuC1HDiVJIiI9KK3okQ3t3+5aMvqO3Om1doAvk6MZPskIc7loAN/F4PHUkuCiMjF9FaU\nqGbEJYHPC50dffb5ms8CYKZk2B7bsyXBgwOXQ78OIiI96a0oUc2ICz6hktXkTxKMIN0NcRd1N6gl\nQUSkN70VJaoF1m+wSxJaGwAwE8fZHhvndtCuwkURkaD0VpSoZrji/V94zvfZZ3na/V+44myPdbsc\ndNA1mZK6G0RELqa3okS3C0mC5Wnrs8vytoPTjWHY/5jHuRx4LH/hYqfhwDQ1eZKISE9KEiSqGW7/\nCk1WR9+WBDxt3S0NNtyu7u4Gn6l5xURELqYkQaJad3eDTUuCpx2c9l0N4K9J6CpctEzXiNyfiEg0\nU5Ig0S1EdwPedowg9QgAbqdJB11JgloSREQupiRBopoRqiahn5YEwzDwXVgFErUkiIj0oSRBopvD\nBabDvrvB2x6yJgGg0+FfDtpyqCVBRORiShIkqhmGAa74IIWL7RhOd8jjrQtJguFQS4KIyMWUJEjU\nM1zxQbob2gI1C8GccWTxbtt0zjqzRur2RESilpIEiXqGK8G2uwFvO0aImgQAnPH8vvW6fpMJEZGx\nSEmCRD93sJaE9qCzLXaJc/l/BZyabVFEpA+9GSXqGa54rI7eSYJl+cDbEXIIJBBYr0HrNoiI9KU3\no0Q9wxXft7vB6wEscIbuRnC7/NMyK0kQEelLb0aJfq4ErIsWeLK8/sWdDFfo0Q1utSSIiASlN6NE\nPcPdt7uhq2Whv3kSXM4LLQkOx4jcm4hINFOSIFHPcMWDtw3LsgLbuloSQs24CN2Fi2pJEBHpS29G\niX6uBLAs8HZ0b/N0dTf0V7job0FwKkkQEelDb0aJeoa7a/2G7roEy3NpLQlutSSIiASlN6NEvUDd\nQY+6hO7CxX5GN3QVLmqeBBGRPvRmlOhntxJkV+Fivy0JGgIpIhKM3owS9bqXi+7R3dBVn9BPTYKG\nQIqIBKc3o0Q9w50A0HslyMAQSLUkiIgMlt6MEvWMxDQArNaGwLZLHQLpUk2CiEhQejNK1DMSU8F0\nYDWd7d7oaQeHE8MMPUmS26mWBBGRYPRmlKhnGCZGUjq+5trANsvT3m8rAnRPpuRWkiAi0kdY3oz1\n9fU88MADfOtb3+L2229n+fLl1NXV9fpMcXExeXl5tLS0BLbt3r2bW265hW9+85v84Ac/4Pz585e0\nT8YeM2V87yTB29bv8EeAaZPTuPsbU5k2OW0kb09EJCqFJUkwDIOlS5eyc+dOtm7dyuTJk1mzZk1g\n/+7duzEMo9cxLS0tPPXUU5SXl/OnP/2JpKQkNmzY0O8+GZuM5AysHkkCnvZ+hz8COB0mt8z+D5yq\nSRAR6SMsb8a0tDRmz54d+H7WrFlUVVUB/laGF154geLi4l7HvPPOO8ycOZPc3FwAioqK2L59e7/7\nZGwykzOwWhqwOr3AhcLFfkY2iIhIaGH/88nn81FRUcH8+fMBKCkp4fvf/z4pKSm9PlddXU12dnbg\n++zsbKqrq/vdJ2OTmZwBWFgt9f4Nl9iSICIiwTnDfcHVq1eTmJjIkiVL+OMf/4jL5eLGG28M920A\nkJGRPCrXHQ2ZmSn9fyiKnW+eTDVwmbOVhMwUPrc8OJPT+33uWI/LQCke9hQXe4pLaLEQn7AmCaWl\npZw8eZLy8nJM02T//v3s3bs30KoAcNttt/Hyyy+TlZXFvn37AturqqrIysoCCLlvIGprm/H5rP4/\nGOUyM1OoqWka7dsYUb5O/4RK9Z+fojnxcjxt5/ElOUI+91iIy0AoHvYUF3uKS2iRFh/TNAb1h3HY\nuhvWrl3L0aNHKSsrw+12A/DMM8/wzjvvsHv3bnbv3g3Atm3bmDp1KjfccANHjhzh008/BWDTpk0s\nWLAAIOQ+GZuMpHSA7hEOnksb3SAiIsGFpSWhsrKSdevWkZubS1FREQCTJk2irKws6DHJycmUlJTw\n0EMP4fP5yM/PZ+XKlf3uk7HJcLoxElKxmvxJggoXRUSGLixJwrRp0zh27Fi/n7v4M4WFhRQWFtp+\nNtQ+GZuM5Ax8zbVYlqXCRRGRYaDB4RIzzBR/koDPC5ZPLQkiIkOkJEFiRteESlZgBUjVJIiIDIWS\nBIkZZvJ46PRgnavxb3C6R/eGRESinJIEiRn+CZXA1+CfzVMtCSIiQ6MkQWKGkXIhSai/kCSocFFE\nZEiUJEjM6GpJ6Kw/7d+gwkURkSFRkiCxw50Irni1JIiIDBMlCRIzDMPATB6P1XTWv0E1CSIiQ6Ik\nQWKKvy7Bvx6Hoe4GEZEhUZIgMaWrLgHU3SAiMlRKEiSmGD2SBBUuiogMjZIEiSmBlgTDAWZYV0IX\nEYk5ShIkpgSSBJcbwzBG92ZERKKckgSJKUbKeP+/GtkgIjJkShIkphiJqWA6QEWLIiJDpiRBYoph\nmBhJ6Rr+KCIyDFTZJTHHkT5ptG9BRCQmKEmQmBP/jQdH+xZERGKCkgSJOYY7YbRvQUQkJqgmQURE\nRGwpSRARERFbShJERETElpIEERERsaUkQURERGwpSRARERFbShJERETElpIEERERsaUkQURERGwp\nSRARERFbShJERETE1pheu8E0jdG+hbAZS886EIpLb4qHPcXFnuISWiTFZ7D3YliWZQ3zvYiIiEgM\nUHeDiIiI2FKSICIiIraUJIiIiIgtJQkiIiJiS0mCiIiI2FKSICIiIraUJIiIiIgtJQkiIiJiS0mC\niIiI2BrT0zJHmvr6en784x/z2Wef4Xa7ufzyyykpKSE9PZ2//e1vrFq1ivb2dnJycvj5z39ORkYG\nAI8//jj79u2jpqaGgwcPkpSUFDjn5s2befXVVzFNE4fDwRNPPME111xje/1Q5wm1b6SNRFzefPNN\nXnnlFXw+H5MnT+b5558nLS3N9vqDvcZYi4fP5+Pee+/l/PnzAGRmZvLss88yadKkEY8JRG5cAPLy\n8pg+fTqm6f+77Gc/+xl5eXkjHBG/SI3LwYMHefbZZwOfq62tJTMzk7fffntkA9JDpMZmoOcZUZZE\njPr6emvv3r2B759//nmruLjY6uzstAoLC60PP/zQsizLKisrs1asWBH43Pvvv2+dPXvWmj59utXc\n3BzYXldXZxUUFFg1NTWWZVnWrl27rAULFgS9frDz9LdvpA13XE6cOGF97Wtfs2prawPHPfXUU7bX\nHuw1RlIkx+PcuXOBr1955RXrkUceGYYnvjSRHJfR+L3pEslx6WnZsmXW+vXrh/awAxSpsRnIeUaa\nuhsiSFpaGrNnzw58P2vWLKqqqjh69ChxcXGBFoCioiJ27NgR+Nz1118fyD57siwLy7JoaWkBoKmp\niYkTJwa9frDz9LdvpA13XI4fP05+fj7p6ekAzJs3j61bt9pee7DXGEmRHI+UlJTA183NzYG/nMMh\nkuMymqIhLrW1tbz33nssXrx48A86CJEam4GcZ6QpSYhQPp+PiooK5s+fT3V1NdnZ2YF96enp+Hw+\nGhoaQp4jPT2dkpISvv3tb3PjjTeydu1ann766ZG+9RE1HHGZMWMGR44c4dSpU1iWxbZt22htbbU9\nbrDXCJdIjMcDDzzA3Llz2b59OytXrhyGpxy4SIzLfffdx+LFi/nFL35BR0fHMDzlwEViXAC2bNnC\n3LlzGT9+/BCfcPAiKTYDOc9IU5IQoVavXk1iYiJLliwZ9Dmam5t57bXX2Lx5M3v27GHFihUsX74c\nK4oX/hyOuFxxxRU8+eSTPPbYY9x9992kpqYC4HRGX4lOJMbj5Zdf5i9/+QsLFy7kxRdfHPR9DUWk\nxWXPnj289dZbvPbaa5w4cYKysrJB39dQRFpcurz11lt85zvfGfTxwyGSYhNJ76joeyuOAaWlpZw8\neZLy8nJM0yQrK4uqqqrA/rq6OkzT7LeI5d133yUlJYUrr7wSgFtvvZXi4mLq6+v53e9+F2jaKi4u\n5rrrrhu5BxomwxUXgIULF7Jw4UIADh8+zOuvv05ycjIvvvhir7gM5RojLZLjYZomd955JzfffDPP\nPPPMMDztpYvEuGRlZQGQnJzMXXfdxcaNG4fteS9VJMYF/MV7jY2NzJs3b7gedcAiMTbBzhNuShIi\nzNq1azl69CgvvfQSbrcbgJkzZ9LW1saBAwe45ppr2LRpE7fccku/55o0aRIff/wxtbW1ZGRksHfv\nXpKTkxk3bhzLli1j2bJlI/04w2Y44wJQU1NDZmYm7e3t/PrXv+a73/0uQJ+4+Hy+QV9jJEViPOrq\n6gAC/ag7duwIWwV/l0iMS2NjI3FxccTHx+P1etm5cyf5+fnD/OShRWJcurz55pssWrRo1FryIjU2\nwc4TboYVzW3PMaayspLbbruN3Nxc4uPjAf9/9GVlZRw8eJCnn36611CZrv675cuXc/jwYc6cOcOE\nCROYPn06GzZsAGDjxo288cYbuFwu3G43K1asCDoEMtR5Qu0baSMRl6VLl1JVVYXH4+HWW2/l0Ucf\nDVpkN9hrjLV4HDt2jOLiYjweDwA5OTmsXLmSyZMnj2g8ukRqXA4dOsSqVaswDAOv10tBQQFPPPFE\n2IYRR2pcANra2pg7dy5vvPEGU6ZMCUM0eovk2AzkPCNJSYKIiIjYUuGiiIiI2FKSICIiIraUJIiI\niIgtJQkiIiJiS0mCiIiI2FKSICIiIrY0mZKIDNr8+fM5e/YsDocDh8PB1KlTWbx4Mffcc0+/Y7o/\n//xzbrrpJj766KOonBJbZCzQb6aIDEl5eTlz5syhqamJ/fv389xzz3H48GF++tOfjvaticgQqbtB\nRIZFSkoKN910E7/85S95++23OX78OHv27OGOO+7gqquuYt68efzmN78JfL5rIZ1rr72WgoICDh06\nBMDmzZtZsGAB1157Lffffz+nT58elecRESUJIjLMvvzlLzNx4kQOHDhAQkICpaWlHDhwgHXr1lFR\nUcGuXbsA+O1vfwvAhx9+yKFDhygoKGDXrl2sW7eOF154gQ8++ICrr76axx9/fDQfR2RMU5IgIsNu\nwoQJNDY2Mnv2bPLy8jBNkxkzZrBw4UL2798f9LhNmzbx4IMPMmXKFJxOJw8//DCffPKJWhNERolq\nEkRk2J05c4bU1FT+/ve/s2bNGiorK/F4PHR0dIRcTa+qqoqf/OQnlJaWBrZZlsWZM2fIyckJx62L\nSA9KEkRkWHWtjnf11VfzyCOPsGTJEtavX09cXBzPPfcc9fX1ABiG0efYrKwsHn74YRYtWhTu2xYR\nG+puEJFh0dzczJ///Gd++MMfsmjRIvLy8mhpaSE1NZW4uDgOHz7Mtm3bAp9PT0/HNE1OnToV2FZU\nVMRLL71EZWUlAE1NTWzfvj3szyIifloqWkQGrec8CaZpMnXqVBYtWkRRUREOh4MdO3ZQWlpKQ0MD\nX/3qV8nJyeHcuXOsWbMGgF/96ldUVFTg9XpZv349s2bNYsuWLWzYsIHTp0+TkpLCnDlzNJxSZJQo\nSRARERFb6m4QERERW0oSRERExJaSBBEREbGlJEFERERsKUkQERERW0oSRERExJaSBBEREbGlJEFE\nRERsKUkQERERW/8PN0bxf4jfowQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97whG9Y5kqiQ",
        "colab_type": "code",
        "outputId": "445d8dd6-644a-48f9-a152-53ad1294b402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tpot.fitted_pipeline_.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9063961648776213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBmcXA_tMLlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}